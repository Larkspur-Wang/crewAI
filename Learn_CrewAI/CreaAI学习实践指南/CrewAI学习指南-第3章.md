# ç¬¬3ç« ï¼šåˆ›å»ºç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“é¡¹ç›®

> ğŸ› ï¸ åŠ¨æ‰‹æ—¶é—´åˆ°ï¼ä»é›¶å¼€å§‹æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªCrewAIé¡¹ç›®ï¼Œä½“éªŒå¤šæ™ºèƒ½ä½“åä½œçš„é­…åŠ›ã€‚

## ğŸ“‹ ç« èŠ‚å¤§çº²

æœ¬ç« å°†æ‰‹æŠŠæ‰‹æ•™ä½ ï¼š

1. **ğŸ—ï¸ é¡¹ç›®è§„åˆ’ä¸è®¾è®¡** - è®¾è®¡ä¸€ä¸ªå®ç”¨çš„AIé¡¹ç›®
2. **ğŸš€ é¡¹ç›®åˆ›å»ºä¸é…ç½®** - ä½¿ç”¨CLIåˆ›å»ºæ ‡å‡†é¡¹ç›®ç»“æ„
3. **ğŸ¤– Agentå›¢é˜Ÿè®¾è®¡** - åˆ›å»ºä¸“ä¸šçš„AIæ™ºèƒ½ä½“å›¢é˜Ÿ
4. **ğŸ“‹ Taskå·¥ä½œæµè®¾è®¡** - è®¾è®¡é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œæµç¨‹
5. **ğŸ° Crewåä½œé…ç½®** - ç»„å»ºåä½œæ— é—´çš„AIå›¢é˜Ÿ
6. **ğŸ”§ å·¥å…·é›†æˆå¼€å‘** - ä¸ºAgentæ·»åŠ å®ç”¨å·¥å…·
7. **ğŸƒâ€â™‚ï¸ è¿è¡Œè°ƒè¯•ä¼˜åŒ–** - æµ‹è¯•ã€è°ƒè¯•å’Œæ€§èƒ½ä¼˜åŒ–
8. **ğŸ“Š ç»“æœåˆ†ææ”¹è¿›** - åˆ†æç»“æœå¹¶æŒç»­æ”¹è¿›

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- âœ… ç‹¬ç«‹è®¾è®¡å’Œåˆ›å»ºå®Œæ•´çš„CrewAIé¡¹ç›®
- âœ… æŒæ¡æ ‡å‡†çš„é¡¹ç›®ç»„ç»‡ç»“æ„å’Œå¼€å‘æµç¨‹
- âœ… ç†Ÿç»ƒé…ç½®Agentã€Taskã€Crewçš„å„ç§å‚æ•°
- âœ… é›†æˆå·¥å…·æ‰©å±•Agentçš„èƒ½åŠ›
- âœ… å…·å¤‡è°ƒè¯•å’Œä¼˜åŒ–CrewAIåº”ç”¨çš„æŠ€èƒ½
- âœ… ç†è§£å®é™…ä¸šåŠ¡åœºæ™¯çš„AIè§£å†³æ–¹æ¡ˆè®¾è®¡

---

## 3.1 é¡¹ç›®è§„åˆ’ä¸è®¾è®¡ğŸ—ï¸

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šç­–åˆ’æ¸¸æˆ

åˆ›å»ºCrewAIé¡¹ç›®å°±åƒç­–åˆ’ä¸€æ¬¾æ¸¸æˆï¼š

- **ğŸ¯ æ¸¸æˆç›®æ ‡**ï¼šæ˜ç¡®é¡¹ç›®è¦è§£å†³ä»€ä¹ˆé—®é¢˜
- **ğŸ‘¥ è§’è‰²è®¾å®š**ï¼šè®¾è®¡ä¸åŒæŠ€èƒ½çš„AIè§’è‰²
- **ğŸ“‹ ä»»åŠ¡ç³»ç»Ÿ**ï¼šè§„åˆ’è§’è‰²è¦å®Œæˆçš„ä»»åŠ¡
- **ğŸª æ¸¸æˆæµç¨‹**ï¼šè®¾è®¡æ•´ä¸ªæ¸¸æˆçš„è¿›è¡Œæ–¹å¼
- **ğŸ› ï¸ é“å…·ç³»ç»Ÿ**ï¼šä¸ºè§’è‰²é…å¤‡å¿…è¦çš„å·¥å…·
- **ğŸ† æˆå°±ç³»ç»Ÿ**ï¼šå®šä¹‰æˆåŠŸçš„æ ‡å‡†

### ğŸ¯ é¡¹ç›®é€‰æ‹©ï¼šAIå†…å®¹åˆ›ä½œåŠ©æ‰‹

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª**AIå†…å®¹åˆ›ä½œåŠ©æ‰‹**é¡¹ç›®ï¼Œè¿™æ˜¯ä¸€ä¸ªå®ç”¨ä¸”æœ‰è¶£çš„åº”ç”¨åœºæ™¯ï¼š

**é¡¹ç›®èƒŒæ™¯**ï¼š
å¸®åŠ©å†…å®¹åˆ›ä½œè€…ï¼ˆåšä¸»ã€è¥é”€äººå‘˜ã€å­¦ç”Ÿç­‰ï¼‰å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„æ–‡ç« å†…å®¹ã€‚

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
1. ğŸ“š **ç ”ç©¶æ”¶é›†**ï¼šè‡ªåŠ¨æœç´¢å’Œæ•´ç†ç›¸å…³èµ„æ–™
2. ğŸ“ **å†…å®¹åˆ›ä½œ**ï¼šåŸºäºèµ„æ–™ç”Ÿæˆç»“æ„åŒ–æ–‡ç« 
3. âœ¨ **å†…å®¹ä¼˜åŒ–**ï¼šæ¶¦è‰²å’Œæ”¹è¿›æ–‡ç« è´¨é‡
4. ğŸ“Š **è´¨é‡è¯„ä¼°**ï¼šè¯„ä¼°å†…å®¹è´¨é‡å¹¶æä¾›æ”¹è¿›å»ºè®®

### ğŸ­ AIå›¢é˜Ÿè§’è‰²è®¾è®¡

```mermaid
graph TD
    A[å†…å®¹åˆ›ä½œå›¢é˜Ÿ] --> B[ğŸ” ç ”ç©¶ä¸“å®¶]
    A --> C[âœï¸ å†™ä½œä¸“å®¶]
    A --> D[âœ¨ ç¼–è¾‘ä¸“å®¶]
    A --> E[ğŸ“Š è´¨é‡è¯„ä¼°å¸ˆ]

    B --> B1[æœç´¢ç›¸å…³èµ„æ–™]
    B --> B2[æ•´ç†å…³é”®ä¿¡æ¯]
    B --> B3[æä¾›æ•°æ®æ”¯æŒ]

    C --> C1[æ’°å†™æ–‡ç« å¤§çº²]
    C --> C2[åˆ›ä½œæ–‡ç« å†…å®¹]
    C --> C3[ä¿æŒé€»è¾‘è¿è´¯]

    D --> D1[ä¼˜åŒ–æ–‡ç« ç»“æ„]
    D --> D2[æ”¹è¿›è¯­è¨€è¡¨è¾¾]
    D --> D3[å¢å¼ºå¯è¯»æ€§]

    E --> E1[è¯„ä¼°å†…å®¹è´¨é‡]
    E --> E2[æ£€æŸ¥äº‹å®å‡†ç¡®æ€§]
    E --> E3[æä¾›æ”¹è¿›å»ºè®®]
```

### ğŸ“‹ å·¥ä½œæµç¨‹è®¾è®¡

**Sequentialï¼ˆé¡ºåºï¼‰æ‰§è¡Œæµç¨‹**ï¼š

1. **ğŸ” ç ”ç©¶é˜¶æ®µ**ï¼šç ”ç©¶ä¸“å®¶æ”¶é›†ç›¸å…³èµ„æ–™
2. **âœï¸ åˆ›ä½œé˜¶æ®µ**ï¼šå†™ä½œä¸“å®¶åŸºäºèµ„æ–™åˆ›ä½œå†…å®¹
3. **âœ¨ ç¼–è¾‘é˜¶æ®µ**ï¼šç¼–è¾‘ä¸“å®¶ä¼˜åŒ–å†…å®¹è´¨é‡
4. **ğŸ“Š è¯„ä¼°é˜¶æ®µ**ï¼šè´¨é‡è¯„ä¼°å¸ˆè¯„ä¼°å¹¶æä¾›åé¦ˆ

### ğŸ› ï¸ å·¥å…·éœ€æ±‚åˆ†æ

ä¸ºäº†è®©AIå›¢é˜Ÿæ›´å¼ºå¤§ï¼Œæˆ‘ä»¬éœ€è¦é›†æˆä»¥ä¸‹å·¥å…·ï¼š

- **ğŸ” æœç´¢å·¥å…·**ï¼šç½‘ç»œæœç´¢è·å–æœ€æ–°ä¿¡æ¯
- **ğŸ“„ æ–‡ä»¶å·¥å…·**ï¼šè¯»å†™æ–‡ä»¶ä¿å­˜å†…å®¹
- **ğŸ§® è®¡ç®—å·¥å…·**ï¼šè¿›è¡Œæ•°æ®è®¡ç®—å’Œåˆ†æ
- **ğŸŒ ç½‘é¡µå·¥å…·**ï¼šæŠ“å–ç½‘é¡µå†…å®¹
- **ğŸ“Š åˆ†æå·¥å…·**ï¼šæ–‡æœ¬åˆ†æå’Œè´¨é‡è¯„ä¼°

---

## 3.2 é¡¹ç›®åˆ›å»ºä¸é…ç½®ğŸš€

### ğŸ¯ ä½¿ç”¨CLIåˆ›å»ºé¡¹ç›®

```bash
# åˆ›å»ºæ–°çš„CrewAIé¡¹ç›®
crewai create crew content_creator_ai
cd content_creator_ai

# æŸ¥çœ‹é¡¹ç›®ç»“æ„
tree  # Linux/macOS
dir /s  # Windows
```

**ç”Ÿæˆçš„é¡¹ç›®ç»“æ„**ï¼š
```
content_creator_ai/
â”œâ”€â”€ .env                    # ç¯å¢ƒå˜é‡é…ç½®
â”œâ”€â”€ .gitignore             # Gitå¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ pyproject.toml         # é¡¹ç›®ä¾èµ–é…ç½®
â”œâ”€â”€ README.md              # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ knowledge/             # çŸ¥è¯†åº“æ–‡ä»¶å¤¹ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ src/
    â””â”€â”€ content_creator_ai/
        â”œâ”€â”€ __init__.py    # PythonåŒ…åˆå§‹åŒ–
        â”œâ”€â”€ main.py        # ä¸»ç¨‹åºå…¥å£
        â”œâ”€â”€ crew.py        # Crewå®šä¹‰æ–‡ä»¶
        â”œâ”€â”€ tools/         # è‡ªå®šä¹‰å·¥å…·ç›®å½•
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â””â”€â”€ custom_tool.py
        â””â”€â”€ config/        # é…ç½®æ–‡ä»¶ç›®å½•
            â”œâ”€â”€ agents.yaml # Agenté…ç½®
            â””â”€â”€ tasks.yaml  # Taské…ç½®
```

### ğŸ”‘ ç¯å¢ƒé…ç½®

ç¼–è¾‘`.env`æ–‡ä»¶ï¼Œé…ç½®å¿…è¦çš„APIå¯†é’¥ï¼š

```bash
# .env - ç¯å¢ƒå˜é‡é…ç½®
# OpenAIé…ç½®ï¼ˆå¿…éœ€ï¼‰
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL_NAME=gpt-4o-mini

# æœç´¢åŠŸèƒ½é…ç½®ï¼ˆæ¨èï¼‰
SERPER_API_KEY=your-serper-dev-api-key-here

# å¯é€‰é…ç½®
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# è°ƒè¯•é…ç½®
CREWAI_VERBOSE=true
CREWAI_LOG_LEVEL=INFO
```

> ğŸ’¡ **è·å–APIå¯†é’¥**ï¼š
> - OpenAI API: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
> - Serper API: [serper.dev](https://serper.dev) (å…è´¹é¢åº¦ï¼š2500æ¬¡æœç´¢/æœˆ)

### ğŸ“¦ ä¾èµ–ç®¡ç†

ç¼–è¾‘`pyproject.toml`ï¼Œæ·»åŠ é¡¹ç›®ä¾èµ–ï¼š

```toml
[tool.poetry]
name = "content-creator-ai"
version = "0.1.0"
description = "AIå†…å®¹åˆ›ä½œåŠ©æ‰‹"
authors = ["Your Name <your.email@example.com>"]

[tool.poetry.dependencies]
python = ">=3.10,<=3.13"
crewai = {extras = ["tools"], version = "^0.130.0"}
python-dotenv = "^1.0.0"

# å¯é€‰ä¾èµ–
beautifulsoup4 = "^4.12.0"  # ç½‘é¡µè§£æ
requests = "^2.31.0"        # HTTPè¯·æ±‚
pandas = "^2.0.0"           # æ•°æ®å¤„ç†

[tool.poetry.group.dev.dependencies]
pytest = "^7.0.0"
black = "^23.0.0"
isort = "^5.12.0"
mypy = "^1.5.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
```

### ğŸ”§ å®‰è£…ä¾èµ–

```bash
# å®‰è£…é¡¹ç›®ä¾èµ–
crewai install

# æˆ–è€…ä½¿ç”¨pipï¼ˆå¦‚æœæ²¡æœ‰poetryï¼‰
pip install -e .
```

---

## 3.3 Agentå›¢é˜Ÿè®¾è®¡ğŸ¤–

### ğŸ­ Agenté…ç½®æ–‡ä»¶

ç¼–è¾‘`src/content_creator_ai/config/agents.yaml`ï¼š

```yaml
# config/agents.yaml - Agenté…ç½®æ–‡ä»¶
researcher:
  role: >
    èµ„æ·±ç ”ç©¶ä¸“å®¶
  goal: >
    æ·±å…¥ç ”ç©¶æŒ‡å®šä¸»é¢˜ï¼Œæ”¶é›†æœ€æ–°ã€æœ€å‡†ç¡®ã€æœ€ç›¸å…³çš„ä¿¡æ¯å’Œæ•°æ®ï¼Œ
    ä¸ºå†…å®¹åˆ›ä½œæä¾›åšå®çš„äº‹å®åŸºç¡€å’Œä¸°å¯Œçš„ç´ ææ”¯æŒ
  backstory: >
    ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„ä¸“ä¸šç ”ç©¶å‘˜ï¼Œæ›¾åœ¨çŸ¥åæ™ºåº“å’Œç ”ç©¶æœºæ„å·¥ä½œã€‚
    ä½ æ“…é•¿å¿«é€Ÿå®šä½æƒå¨ä¿¡æ¯æºï¼Œå–„äºä»æµ·é‡ä¿¡æ¯ä¸­æå–å…³é”®æ´å¯Ÿï¼Œ
    å¯¹æ•°æ®çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§æœ‰ç€æé«˜çš„è¦æ±‚ã€‚ä½ çš„ç ”ç©¶æŠ¥å‘Šæ€»æ˜¯é€»è¾‘æ¸…æ™°ã€
    æ•°æ®ç¿”å®ï¼Œä¸ºå†³ç­–æä¾›æœ‰åŠ›æ”¯æ’‘ã€‚ä½ ç†Ÿæ‚‰å„ç§ç ”ç©¶æ–¹æ³•å’Œå·¥å…·ï¼Œ
    èƒ½å¤Ÿä»å¤šä¸ªè§’åº¦å…¨é¢åˆ†æé—®é¢˜ã€‚
  verbose: true
  allow_delegation: false

writer:
  role: >
    åˆ›æ„å†™ä½œä¸“å®¶
  goal: >
    åŸºäºç ”ç©¶èµ„æ–™åˆ›ä½œå¼•äººå…¥èƒœã€ç»“æ„æ¸…æ™°ã€å†…å®¹ä¸°å¯Œçš„é«˜è´¨é‡æ–‡ç« ï¼Œ
    ç¡®ä¿å†…å®¹æ—¢æœ‰æ·±åº¦åˆæœ‰å¯è¯»æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¼ è¾¾æ ¸å¿ƒä¿¡æ¯
  backstory: >
    ä½ æ˜¯ä¸€ä½æ‰åæ¨ªæº¢çš„èµ„æ·±å†™ä½œä¸“å®¶ï¼Œæ‹¥æœ‰15å¹´çš„å†…å®¹åˆ›ä½œç»éªŒã€‚
    ä½ æ›¾ä¸ºå¤šå®¶çŸ¥ååª’ä½“å’Œä¼ä¸šæ’°å†™æ–‡ç« ï¼Œæ“…é•¿å°†å¤æ‚çš„æ¦‚å¿µè½¬åŒ–ä¸º
    é€šä¿—æ˜“æ‡‚çš„è¡¨è¾¾ã€‚ä½ çš„æ–‡ç« æ€»æ˜¯ç»“æ„ä¸¥è°¨ã€é€»è¾‘æ¸…æ™°ï¼ŒåŒæ—¶å¯Œæœ‰
    æ„ŸæŸ“åŠ›å’Œè¯´æœåŠ›ã€‚ä½ æ·±è°™ä¸åŒæ–‡ä½“çš„å†™ä½œæŠ€å·§ï¼Œèƒ½å¤Ÿæ ¹æ®ç›®æ ‡
    å—ä¼—è°ƒæ•´å†™ä½œé£æ ¼ï¼Œè®©æ¯ç¯‡æ–‡ç« éƒ½èƒ½ç²¾å‡†è§¦è¾¾è¯»è€…å†…å¿ƒã€‚
  verbose: true
  allow_delegation: false

editor:
  role: >
    ä¸“ä¸šå†…å®¹ç¼–è¾‘
  goal: >
    å…¨é¢ä¼˜åŒ–æ–‡ç« å†…å®¹ï¼Œæå‡è¯­è¨€è¡¨è¾¾è´¨é‡ï¼Œå®Œå–„æ–‡ç« ç»“æ„ï¼Œ
    ç¡®ä¿å†…å®¹çš„å‡†ç¡®æ€§ã€ä¸€è‡´æ€§å’Œä¸“ä¸šæ€§ï¼Œæ‰“é€ å®Œç¾çš„é˜…è¯»ä½“éªŒ
  backstory: >
    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ä¸“ä¸šç¼–è¾‘ï¼Œæ‹¥æœ‰12å¹´çš„å†…å®¹ç¼–è¾‘ç»éªŒã€‚
    ä½ æ›¾åœ¨é¡¶çº§å‡ºç‰ˆç¤¾å’Œåª’ä½“æœºæ„æ‹…ä»»ä¸»ç¼–ï¼Œå¯¹è¯­è¨€æ–‡å­—æœ‰ç€æ•é”çš„
    æ„ŸçŸ¥åŠ›å’Œæé«˜çš„æ ‡å‡†ã€‚ä½ æ“…é•¿å‘ç°æ–‡ç« ä¸­çš„é€»è¾‘æ¼æ´ã€è¯­è¨€é—®é¢˜
    å’Œç»“æ„ç¼ºé™·ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒä½œè€…åŸæ„çš„åŸºç¡€ä¸Šå¤§å¹…æå‡å†…å®¹è´¨é‡ã€‚
    ä½ çš„ç¼–è¾‘æ€»æ˜¯ç²¾å‡†åˆ°ä½ï¼Œè®©æ¯ç¯‡æ–‡ç« éƒ½èƒ½è¾¾åˆ°å‡ºç‰ˆçº§åˆ«çš„æ ‡å‡†ã€‚
  verbose: true
  allow_delegation: false

quality_assessor:
  role: >
    å†…å®¹è´¨é‡è¯„ä¼°å¸ˆ
  goal: >
    å®¢è§‚è¯„ä¼°å†…å®¹è´¨é‡ï¼Œä»å¤šä¸ªç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼Œ
    æä¾›å…·ä½“å¯è¡Œçš„æ”¹è¿›å»ºè®®ï¼Œç¡®ä¿å†…å®¹è¾¾åˆ°æœ€é«˜æ ‡å‡†
  backstory: >
    ä½ æ˜¯ä¸€ä½æƒå¨çš„å†…å®¹è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å†…å®¹å®¡æ ¸å’Œ
    è´¨é‡ç®¡ç†ç»éªŒã€‚ä½ æ›¾ä¸ºå¤šå®¶çŸ¥åä¼ä¸šå»ºç«‹å†…å®¹è´¨é‡æ ‡å‡†ä½“ç³»ï¼Œ
    å¯¹å†…å®¹çš„å„ä¸ªç»´åº¦éƒ½æœ‰æ·±å…¥çš„ç†è§£å’Œä¸¥æ ¼çš„æ ‡å‡†ã€‚ä½ èƒ½å¤Ÿä»
    å‡†ç¡®æ€§ã€å¯è¯»æ€§ã€é€»è¾‘æ€§ã€åˆ›æ–°æ€§ç­‰å¤šä¸ªè§’åº¦å…¨é¢è¯„ä¼°å†…å®¹ï¼Œ
    æä¾›çš„å»ºè®®æ€»æ˜¯ä¸­è‚¯è€Œå®ç”¨ï¼Œå¸®åŠ©å†…å®¹åˆ›ä½œè€…ä¸æ–­æå‡æ°´å¹³ã€‚
  verbose: true
  allow_delegation: false
```

### ğŸ¯ Agentå®ç°ä»£ç 

ç¼–è¾‘`src/content_creator_ai/crew.py`ï¼š

```python
# crew.py - Crewå®ç°æ–‡ä»¶
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool, FileWriterTool, FileReadTool

@CrewBase
class ContentCreatorAiCrew():
    """å†…å®¹åˆ›ä½œAIå›¢é˜Ÿ"""

    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    def __init__(self) -> None:
        # åˆå§‹åŒ–å·¥å…·
        self.search_tool = SerperDevTool()
        self.file_writer = FileWriterTool()
        self.file_reader = FileReadTool()

    @agent
    def researcher(self) -> Agent:
        """åˆ›å»ºç ”ç©¶ä¸“å®¶Agent"""
        return Agent(
            config=self.agents_config['researcher'],
            tools=[self.search_tool, self.file_writer],
            verbose=True,
            max_iter=5,
            memory=True
        )

    @agent
    def writer(self) -> Agent:
        """åˆ›å»ºå†™ä½œä¸“å®¶Agent"""
        return Agent(
            config=self.agents_config['writer'],
            tools=[self.file_reader, self.file_writer],
            verbose=True,
            max_iter=5,
            memory=True
        )

    @agent
    def editor(self) -> Agent:
        """åˆ›å»ºç¼–è¾‘ä¸“å®¶Agent"""
        return Agent(
            config=self.agents_config['editor'],
            tools=[self.file_reader, self.file_writer],
            verbose=True,
            max_iter=3,
            memory=True
        )

    @agent
    def quality_assessor(self) -> Agent:
        """åˆ›å»ºè´¨é‡è¯„ä¼°å¸ˆAgent"""
        return Agent(
            config=self.agents_config['quality_assessor'],
            tools=[self.file_reader],
            verbose=True,
            max_iter=3,
            memory=True
        )
```

---

## 3.4 Taskå·¥ä½œæµè®¾è®¡ğŸ“‹

### ğŸ“ Taské…ç½®æ–‡ä»¶

ç¼–è¾‘`src/content_creator_ai/config/tasks.yaml`ï¼š

```yaml
# config/tasks.yaml - Taské…ç½®æ–‡ä»¶
research_task:
  description: >
    æ·±å…¥ç ”ç©¶ä¸»é¢˜ï¼š{topic}

    è¯·æ‰§è¡Œä»¥ä¸‹ç ”ç©¶ä»»åŠ¡ï¼š
    1. ä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†å…³äº"{topic}"çš„æœ€æ–°ä¿¡æ¯å’Œæ•°æ®
    2. é‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š
       - åŸºæœ¬æ¦‚å¿µå’Œå®šä¹‰
       - æœ€æ–°å‘å±•è¶‹åŠ¿å’ŒåŠ¨æ€
       - å…³é”®æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
       - ä¸“å®¶è§‚ç‚¹å’Œæ¡ˆä¾‹åˆ†æ
       - ç›¸å…³æŠ€æœ¯æˆ–æ–¹æ³•ä»‹ç»
    3. æ•´ç†å’Œåˆ†ææ”¶é›†åˆ°çš„ä¿¡æ¯
    4. è¯†åˆ«æœ€æœ‰ä»·å€¼å’Œæœ€ç›¸å…³çš„å†…å®¹
    5. å°†ç ”ç©¶ç»“æœä¿å­˜åˆ°æ–‡ä»¶ä¸­

    ç ”ç©¶è¦æ±‚ï¼š
    - ç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§
    - ä»å¤šä¸ªè§’åº¦å…¨é¢åˆ†æä¸»é¢˜
    - æä¾›å…·ä½“çš„æ•°æ®å’Œæ¡ˆä¾‹æ”¯æŒ
    - æ ‡æ³¨ä¿¡æ¯æ¥æºå’Œå¯ä¿¡åº¦

  expected_output: >
    ä¸€ä»½ç»“æ„åŒ–çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
    1. ä¸»é¢˜æ¦‚è¿°å’Œæ ¸å¿ƒå®šä¹‰
    2. æœ€æ–°å‘å±•è¶‹åŠ¿å’Œé‡è¦åŠ¨æ€
    3. å…³é”®æ•°æ®ã€ç»Ÿè®¡ä¿¡æ¯å’Œå›¾è¡¨è¯´æ˜
    4. ä¸“å®¶è§‚ç‚¹å’Œæƒå¨åˆ†æ
    5. å…¸å‹æ¡ˆä¾‹å’Œå®é™…åº”ç”¨
    6. ç›¸å…³æŠ€æœ¯ã€æ–¹æ³•æˆ–å·¥å…·ä»‹ç»
    7. ä¿¡æ¯æ¥æºåˆ—è¡¨å’Œå¯ä¿¡åº¦è¯„ä¼°

    æŠ¥å‘Šåº”ä¿å­˜ä¸ºMarkdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°ï¼Œå†…å®¹è¯¦å®ï¼Œ
    ä¸ºåç»­çš„å†…å®¹åˆ›ä½œæä¾›å……åˆ†çš„ç´ ææ”¯æŒã€‚

  agent: researcher

writing_task:
  description: >
    åŸºäºç ”ç©¶æŠ¥å‘Šï¼Œåˆ›ä½œå…³äº"{topic}"çš„é«˜è´¨é‡æ–‡ç« 

    å†™ä½œè¦æ±‚ï¼š
    1. ä»”ç»†é˜…è¯»ç ”ç©¶ä¸“å®¶æä¾›çš„ç ”ç©¶æŠ¥å‘Š
    2. åˆ›ä½œä¸€ç¯‡å…³äº"{topic}"çš„æ·±åº¦æ–‡ç« 
    3. æ–‡ç« ç»“æ„è¦æ±‚ï¼š
       - å¼•äººå…¥èƒœçš„æ ‡é¢˜å’Œå¼€å¤´
       - æ¸…æ™°çš„æ–‡ç« å¤§çº²å’Œé€»è¾‘ç»“æ„
       - 3-5ä¸ªä¸»è¦ç« èŠ‚ï¼Œæ¯ç« èŠ‚800-1200å­—
       - å…·ä½“çš„æ¡ˆä¾‹å’Œæ•°æ®æ”¯æ’‘
       - æœ‰è§åœ°çš„åˆ†æå’Œè§‚ç‚¹
       - å®ç”¨çš„å»ºè®®æˆ–æ€»ç»“
    4. å†™ä½œé£æ ¼ï¼š
       - è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé¿å…è¿‡äºä¸“ä¸šçš„æœ¯è¯­
       - é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
       - å†…å®¹ä¸°å¯Œï¼Œæœ‰æ·±åº¦æœ‰å¹¿åº¦
       - é€‚åˆç›®æ ‡å—ä¼—ï¼š{target_audience}

    ç›®æ ‡å—ä¼—ï¼š{target_audience}
    æ–‡ç« é•¿åº¦ï¼š3000-5000å­—

  expected_output: >
    ä¸€ç¯‡å®Œæ•´çš„é«˜è´¨é‡æ–‡ç« ï¼ŒåŒ…å«ï¼š
    1. å¸å¼•äººçš„æ ‡é¢˜
    2. å¼•äººå…¥èƒœçš„å¼€å¤´æ®µè½
    3. æ¸…æ™°çš„æ–‡ç« ç»“æ„å’Œå¤§çº²
    4. 3-5ä¸ªä¸»è¦ç« èŠ‚ï¼Œå†…å®¹è¯¦å®
    5. å…·ä½“çš„æ¡ˆä¾‹ã€æ•°æ®å’Œå®ä¾‹
    6. æ·±å…¥çš„åˆ†æå’Œç‹¬åˆ°çš„è§è§£
    7. å®ç”¨çš„å»ºè®®æˆ–è¡ŒåŠ¨æŒ‡å—
    8. ç®€æ´æœ‰åŠ›çš„ç»“å°¾

    æ–‡ç« åº”ä¿å­˜ä¸ºMarkdownæ ¼å¼ï¼Œæ€»é•¿åº¦3000-5000å­—ï¼Œ
    è¯­è¨€æµç•…ï¼Œé€»è¾‘æ¸…æ™°ï¼Œå†…å®¹æœ‰ä»·å€¼ã€‚

  agent: writer
  context: [research_task]

editing_task:
  description: >
    å…¨é¢ç¼–è¾‘å’Œä¼˜åŒ–æ–‡ç« å†…å®¹

    ç¼–è¾‘ä»»åŠ¡ï¼š
    1. ä»”ç»†é˜…è¯»å†™ä½œä¸“å®¶åˆ›ä½œçš„æ–‡ç« 
    2. ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œå…¨é¢ç¼–è¾‘ï¼š

       ç»“æ„ä¼˜åŒ–ï¼š
       - æ£€æŸ¥æ–‡ç« æ•´ä½“ç»“æ„æ˜¯å¦åˆç†
       - ä¼˜åŒ–æ®µè½ç»„ç»‡å’Œé€»è¾‘æµç¨‹
       - ç¡®ä¿å„éƒ¨åˆ†å†…å®¹è¡”æ¥è‡ªç„¶

       è¯­è¨€æ”¹è¿›ï¼š
       - ä¼˜åŒ–è¯­è¨€è¡¨è¾¾ï¼Œæå‡å¯è¯»æ€§
       - ä¿®æ­£è¯­æ³•é”™è¯¯å’Œè¡¨è¾¾ä¸å½“
       - ç»Ÿä¸€æ–‡ç« é£æ ¼å’Œè¯­è°ƒ

       å†…å®¹å®Œå–„ï¼š
       - è¡¥å……å¿…è¦çš„ç»†èŠ‚å’Œè¯´æ˜
       - åˆ é™¤å†—ä½™å’Œé‡å¤å†…å®¹
       - ç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§å’Œé€»è¾‘ä¸€è‡´æ€§

       æ ¼å¼è§„èŒƒï¼š
       - ç»Ÿä¸€æ ‡é¢˜æ ¼å¼å’Œå±‚çº§
       - ä¼˜åŒ–åˆ—è¡¨å’Œæ®µè½æ ¼å¼
       - ç¡®ä¿Markdownæ ¼å¼æ­£ç¡®

    3. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒè§‚ç‚¹å’Œé£æ ¼
    4. å°†ç¼–è¾‘åçš„æ–‡ç« ä¿å­˜åˆ°æ–°æ–‡ä»¶

  expected_output: >
    ä¸€ç¯‡ç»è¿‡ä¸“ä¸šç¼–è¾‘çš„ä¼˜è´¨æ–‡ç« ï¼Œå…·å¤‡ï¼š
    1. å®Œç¾çš„ç»“æ„å’Œé€»è¾‘æµç¨‹
    2. æµç•…è‡ªç„¶çš„è¯­è¨€è¡¨è¾¾
    3. å‡†ç¡®æ— è¯¯çš„è¯­æ³•å’Œç”¨è¯
    4. ç»Ÿä¸€è§„èŒƒçš„æ ¼å¼å’Œé£æ ¼
    5. ä¸°å¯Œè€Œç²¾å‡†çš„å†…å®¹
    6. ä¼˜ç§€çš„å¯è¯»æ€§å’Œå¸å¼•åŠ›

    ç¼–è¾‘åçš„æ–‡ç« åº”è¯¥åœ¨ä¿æŒåŸæ„çš„åŸºç¡€ä¸Šï¼Œ
    æ˜¾è‘—æå‡æ•´ä½“è´¨é‡å’Œä¸“ä¸šæ°´å‡†ã€‚

  agent: editor
  context: [writing_task]

quality_assessment_task:
  description: >
    å¯¹æœ€ç»ˆæ–‡ç« è¿›è¡Œå…¨é¢è´¨é‡è¯„ä¼°

    è¯„ä¼°ä»»åŠ¡ï¼š
    1. ä»”ç»†é˜…è¯»ç¼–è¾‘åçš„æœ€ç»ˆæ–‡ç« 
    2. ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šè¯„ä¼°ï¼š

       å†…å®¹è´¨é‡ï¼ˆ30åˆ†ï¼‰ï¼š
       - ä¿¡æ¯å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§
       - å†…å®¹æ·±åº¦å’Œå¹¿åº¦
       - è§‚ç‚¹ç‹¬ç‰¹æ€§å’Œä»·å€¼

       ç»“æ„é€»è¾‘ï¼ˆ25åˆ†ï¼‰ï¼š
       - æ–‡ç« ç»“æ„åˆç†æ€§
       - é€»è¾‘æµç¨‹æ¸…æ™°åº¦
       - æ®µè½ç»„ç»‡æœ‰æ•ˆæ€§

       è¯­è¨€è¡¨è¾¾ï¼ˆ25åˆ†ï¼‰ï¼š
       - è¯­è¨€æµç•…æ€§å’Œå‡†ç¡®æ€§
       - è¡¨è¾¾æ¸…æ™°åº¦å’Œå¯è¯»æ€§
       - é£æ ¼ä¸€è‡´æ€§å’Œä¸“ä¸šæ€§

       å®ç”¨ä»·å€¼ï¼ˆ20åˆ†ï¼‰ï¼š
       - å¯¹ç›®æ ‡å—ä¼—çš„ä»·å€¼
       - å®ç”¨æ€§å’Œå¯æ“ä½œæ€§
       - å¯å‘æ€§å’ŒæŒ‡å¯¼æ„ä¹‰

    3. æä¾›å…·ä½“çš„è¯„åˆ†å’Œè¯¦ç»†åé¦ˆ
    4. ç»™å‡ºæ”¹è¿›å»ºè®®å’Œä¼˜åŒ–æ–¹å‘

  expected_output: >
    ä¸€ä»½è¯¦ç»†çš„è´¨é‡è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
    1. æ€»ä½“è¯„åˆ†ï¼ˆæ»¡åˆ†100åˆ†ï¼‰å’Œç­‰çº§è¯„å®š
    2. å„ç»´åº¦è¯¦ç»†è¯„åˆ†å’Œåˆ†æ
    3. æ–‡ç« ä¼˜ç‚¹å’Œäº®ç‚¹æ€»ç»“
    4. å­˜åœ¨é—®é¢˜å’Œä¸è¶³åˆ†æ
    5. å…·ä½“æ”¹è¿›å»ºè®®å’Œä¼˜åŒ–æ–¹å‘
    6. å¯¹ç›®æ ‡å—ä¼—é€‚ç”¨æ€§çš„è¯„ä¼°
    7. ä¸åŒç±»æ–‡ç« çš„å¯¹æ¯”åˆ†æ

    è¯„ä¼°æŠ¥å‘Šåº”å®¢è§‚å…¬æ­£ï¼Œå»ºè®®å…·ä½“å¯è¡Œï¼Œ
    ä¸ºå†…å®¹åˆ›ä½œæä¾›ä¸“ä¸šæŒ‡å¯¼ã€‚

  agent: quality_assessor
  context: [editing_task]
```

### ğŸ“‹ Taskå®ç°ä»£ç 

ç»§ç»­ç¼–è¾‘`src/content_creator_ai/crew.py`ï¼Œæ·»åŠ Taskå®šä¹‰ï¼š

```python
    @task
    def research_task(self) -> Task:
        """åˆ›å»ºç ”ç©¶ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['research_task'],
            agent=self.researcher,
            output_file='research_report.md'
        )

    @task
    def writing_task(self) -> Task:
        """åˆ›å»ºå†™ä½œä»»åŠ¡"""
        return Task(
            config=self.tasks_config['writing_task'],
            agent=self.writer,
            context=[self.research_task],
            output_file='article_draft.md'
        )

    @task
    def editing_task(self) -> Task:
        """åˆ›å»ºç¼–è¾‘ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['editing_task'],
            agent=self.editor,
            context=[self.writing_task],
            output_file='article_final.md'
        )

    @task
    def quality_assessment_task(self) -> Task:
        """åˆ›å»ºè´¨é‡è¯„ä¼°ä»»åŠ¡"""
        return Task(
            config=self.tasks_config['quality_assessment_task'],
            agent=self.quality_assessor,
            context=[self.editing_task],
            output_file='quality_report.md'
        )
```

---

## 3.5 Crewåä½œé…ç½®ğŸ°

### ğŸ¯ Crewå®ç°

ç»§ç»­ç¼–è¾‘`src/content_creator_ai/crew.py`ï¼Œæ·»åŠ Crewå®šä¹‰ï¼š

```python
    @crew
    def crew(self) -> Crew:
        """åˆ›å»ºå†…å®¹åˆ›ä½œAIå›¢é˜Ÿ"""
        return Crew(
            agents=self.agents,  # è‡ªåŠ¨ä»@agentè£…é¥°å™¨åˆ›å»º
            tasks=self.tasks,    # è‡ªåŠ¨ä»@taskè£…é¥°å™¨åˆ›å»º
            process=Process.sequential,  # é¡ºåºæ‰§è¡Œ
            verbose=True,
            memory=True,         # å¯ç”¨å›¢é˜Ÿè®°å¿†
            cache=True,          # å¯ç”¨ç¼“å­˜
            max_rpm=10,          # é™åˆ¶APIè°ƒç”¨é¢‘ç‡
            share_crew=False     # ä¸å…±äº«åˆ°CrewAIå¹³å°
        )
```

### ğŸ¯ ä¸»ç¨‹åºå…¥å£

ç¼–è¾‘`src/content_creator_ai/main.py`ï¼š

```python
#!/usr/bin/env python
# main.py - ä¸»ç¨‹åºå…¥å£
import sys
import os
from datetime import datetime
from content_creator_ai.crew import ContentCreatorAiCrew

def run():
    """è¿è¡Œå†…å®¹åˆ›ä½œAIå›¢é˜Ÿ"""
    print("ğŸš€ å¯åŠ¨AIå†…å®¹åˆ›ä½œåŠ©æ‰‹...")

    # è·å–ç”¨æˆ·è¾“å…¥
    topic = input("ğŸ“ è¯·è¾“å…¥è¦åˆ›ä½œçš„ä¸»é¢˜: ").strip()
    if not topic:
        topic = "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨"  # é»˜è®¤ä¸»é¢˜

    target_audience = input("ğŸ‘¥ è¯·è¾“å…¥ç›®æ ‡å—ä¼— (é»˜è®¤: æŠ€æœ¯çˆ±å¥½è€…): ").strip()
    if not target_audience:
        target_audience = "æŠ€æœ¯çˆ±å¥½è€…"

    # å‡†å¤‡è¾“å…¥æ•°æ®
    inputs = {
        'topic': topic,
        'target_audience': target_audience,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    print(f"\nğŸ“‹ åˆ›ä½œå‚æ•°:")
    print(f"   ä¸»é¢˜: {topic}")
    print(f"   å—ä¼—: {target_audience}")
    print(f"   æ—¶é—´: {inputs['timestamp']}")
    print("\nğŸ¤– AIå›¢é˜Ÿå¼€å§‹å·¥ä½œ...")

    try:
        # æ‰§è¡ŒCrew
        result = ContentCreatorAiCrew().crew().kickoff(inputs=inputs)

        print(f"\nğŸ‰ å†…å®¹åˆ›ä½œå®Œæˆï¼")
        print(f"ğŸ“„ æœ€ç»ˆç»“æœ: {result.raw}")

        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        output_files = [
            'research_report.md',
            'article_draft.md',
            'article_final.md',
            'quality_report.md'
        ]

        for file in output_files:
            if os.path.exists(file):
                print(f"   âœ… {file}")
            else:
                print(f"   âŒ {file} (æœªç”Ÿæˆ)")

        return result

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥")
        return None

def main():
    """ä¸»å‡½æ•°"""
    try:
        result = run()
        if result:
            print("\nâœ… é¡¹ç›®è¿è¡ŒæˆåŠŸï¼")
            print("ğŸ“– æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ")
        else:
            print("\nâŒ é¡¹ç›®è¿è¡Œå¤±è´¥")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## 3.6 å·¥å…·é›†æˆå¼€å‘ğŸ”§

### ğŸ› ï¸ è‡ªå®šä¹‰å·¥å…·å¼€å‘

åˆ›å»ºè‡ªå®šä¹‰å·¥å…·æ¥æ‰©å±•Agentèƒ½åŠ›ã€‚ç¼–è¾‘`src/content_creator_ai/tools/custom_tool.py`ï¼š

```python
# tools/custom_tool.py - è‡ªå®šä¹‰å·¥å…·
from crewai.tools import BaseTool
from typing import Type, Any
from pydantic import BaseModel, Field
import requests
from bs4 import BeautifulSoup
import re

class WebScrapingInput(BaseModel):
    """ç½‘é¡µæŠ“å–å·¥å…·è¾“å…¥æ¨¡å‹"""
    url: str = Field(description="è¦æŠ“å–çš„ç½‘é¡µURL")
    max_length: int = Field(default=5000, description="æœ€å¤§å†…å®¹é•¿åº¦")

class WebScrapingTool(BaseTool):
    name: str = "ç½‘é¡µå†…å®¹æŠ“å–å·¥å…·"
    description: str = "æŠ“å–æŒ‡å®šç½‘é¡µçš„æ–‡æœ¬å†…å®¹ï¼Œç”¨äºè·å–è¯¦ç»†ä¿¡æ¯"
    args_schema: Type[BaseModel] = WebScrapingInput

    def _run(self, url: str, max_length: int = 5000) -> str:
        """æ‰§è¡Œç½‘é¡µæŠ“å–"""
        try:
            # å‘é€HTTPè¯·æ±‚
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            # è§£æHTML
            soup = BeautifulSoup(response.content, 'html.parser')

            # ç§»é™¤è„šæœ¬å’Œæ ·å¼
            for script in soup(["script", "style"]):
                script.decompose()

            # æå–æ–‡æœ¬
            text = soup.get_text()

            # æ¸…ç†æ–‡æœ¬
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)

            # é™åˆ¶é•¿åº¦
            if len(text) > max_length:
                text = text[:max_length] + "..."

            return f"ç½‘é¡µå†…å®¹ ({url}):\n{text}"

        except Exception as e:
            return f"æŠ“å–ç½‘é¡µå¤±è´¥: {str(e)}"

class TextAnalysisInput(BaseModel):
    """æ–‡æœ¬åˆ†æå·¥å…·è¾“å…¥æ¨¡å‹"""
    text: str = Field(description="è¦åˆ†æçš„æ–‡æœ¬å†…å®¹")

class TextAnalysisTool(BaseTool):
    name: str = "æ–‡æœ¬åˆ†æå·¥å…·"
    description: str = "åˆ†ææ–‡æœ¬çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚å­—æ•°ã€æ®µè½æ•°ã€å…³é”®è¯ç­‰"
    args_schema: Type[BaseModel] = TextAnalysisInput

    def _run(self, text: str) -> str:
        """æ‰§è¡Œæ–‡æœ¬åˆ†æ"""
        try:
            # åŸºæœ¬ç»Ÿè®¡
            char_count = len(text)
            word_count = len(text.split())
            paragraph_count = len([p for p in text.split('\n\n') if p.strip()])
            sentence_count = len(re.findall(r'[.!?]+', text))

            # ç®€å•å…³é”®è¯æå–ï¼ˆåŸºäºè¯é¢‘ï¼‰
            words = re.findall(r'\b\w+\b', text.lower())
            word_freq = {}
            for word in words:
                if len(word) > 3:  # åªè€ƒè™‘é•¿åº¦å¤§äº3çš„è¯
                    word_freq[word] = word_freq.get(word, 0) + 1

            # è·å–å‰10ä¸ªé«˜é¢‘è¯
            top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]

            # ç”Ÿæˆåˆ†ææŠ¥å‘Š
            analysis = f"""
æ–‡æœ¬åˆ†ææŠ¥å‘Š:
- å­—ç¬¦æ•°: {char_count:,}
- è¯æ•°: {word_count:,}
- æ®µè½æ•°: {paragraph_count}
- å¥å­æ•°: {sentence_count}
- å¹³å‡å¥é•¿: {word_count/max(sentence_count, 1):.1f} è¯/å¥

é«˜é¢‘è¯æ±‡:
{chr(10).join([f"- {word}: {count}æ¬¡" for word, count in top_words])}

å¯è¯»æ€§è¯„ä¼°:
- è¯æ±‡ä¸°å¯Œåº¦: {len(set(words))/max(len(words), 1):.2%}
- å¹³å‡è¯é•¿: {sum(len(w) for w in words)/max(len(words), 1):.1f} å­—ç¬¦
"""
            return analysis.strip()

        except Exception as e:
            return f"æ–‡æœ¬åˆ†æå¤±è´¥: {str(e)}"
```

### ğŸ”§ å·¥å…·é›†æˆåˆ°Agent

æ›´æ–°`src/content_creator_ai/crew.py`ï¼Œé›†æˆè‡ªå®šä¹‰å·¥å…·ï¼š

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from .tools.custom_tool import WebScrapingTool, TextAnalysisTool

# åœ¨__init__æ–¹æ³•ä¸­åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·
def __init__(self) -> None:
    # åˆå§‹åŒ–å†…ç½®å·¥å…·
    self.search_tool = SerperDevTool()
    self.file_writer = FileWriterTool()
    self.file_reader = FileReadTool()

    # åˆå§‹åŒ–è‡ªå®šä¹‰å·¥å…·
    self.web_scraping_tool = WebScrapingTool()
    self.text_analysis_tool = TextAnalysisTool()

# æ›´æ–°Agentå®šä¹‰ï¼Œæ·»åŠ è‡ªå®šä¹‰å·¥å…·
@agent
def researcher(self) -> Agent:
    """åˆ›å»ºç ”ç©¶ä¸“å®¶Agent"""
    return Agent(
        config=self.agents_config['researcher'],
        tools=[
            self.search_tool,
            self.file_writer,
            self.web_scraping_tool  # æ·»åŠ ç½‘é¡µæŠ“å–å·¥å…·
        ],
        verbose=True,
        max_iter=5,
        memory=True
    )

@agent
def quality_assessor(self) -> Agent:
    """åˆ›å»ºè´¨é‡è¯„ä¼°å¸ˆAgent"""
    return Agent(
        config=self.agents_config['quality_assessor'],
        tools=[
            self.file_reader,
            self.text_analysis_tool  # æ·»åŠ æ–‡æœ¬åˆ†æå·¥å…·
        ],
        verbose=True,
        max_iter=3,
        memory=True
    )
```
---

## 3.7 è¿è¡Œè°ƒè¯•ä¼˜åŒ–ğŸƒâ€â™‚ï¸

### ğŸš€ è¿è¡Œé¡¹ç›®

ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œå®Œæ•´çš„é¡¹ç›®ï¼š

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd content_creator_ai

# ç¡®ä¿ç¯å¢ƒå˜é‡å·²é…ç½®
cat .env  # æ£€æŸ¥APIå¯†é’¥

# è¿è¡Œé¡¹ç›®
crewai run

# æˆ–è€…ç›´æ¥è¿è¡ŒPythonæ–‡ä»¶
python src/content_creator_ai/main.py
```

### ğŸŠ é¢„æœŸæ‰§è¡Œæµç¨‹

å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼Œä½ åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„æ‰§è¡Œè¿‡ç¨‹ï¼š

```
ğŸš€ å¯åŠ¨AIå†…å®¹åˆ›ä½œåŠ©æ‰‹...
ğŸ“ è¯·è¾“å…¥è¦åˆ›ä½œçš„ä¸»é¢˜: äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨
ğŸ‘¥ è¯·è¾“å…¥ç›®æ ‡å—ä¼— (é»˜è®¤: æŠ€æœ¯çˆ±å¥½è€…): åŒ»ç–—ä»ä¸šè€…

ğŸ“‹ åˆ›ä½œå‚æ•°:
   ä¸»é¢˜: äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨
   å—ä¼—: åŒ»ç–—ä»ä¸šè€…
   æ—¶é—´: 2025-06-23 15:30:00

ğŸ¤– AIå›¢é˜Ÿå¼€å§‹å·¥ä½œ...

[2025-06-23 15:30:01][DEBUG]: == Working Agent: èµ„æ·±ç ”ç©¶ä¸“å®¶
[2025-06-23 15:30:01][INFO]: == Starting Task: æ·±å…¥ç ”ç©¶ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨

[2025-06-23 15:30:15][DEBUG]: == [èµ„æ·±ç ”ç©¶ä¸“å®¶] Task output:
ç ”ç©¶æŠ¥å‘Šå·²å®Œæˆï¼ŒåŒ…å«æœ€æ–°çš„AIåŒ»ç–—è¯Šæ–­æŠ€æœ¯å‘å±•è¶‹åŠ¿...

[2025-06-23 15:30:16][DEBUG]: == Working Agent: åˆ›æ„å†™ä½œä¸“å®¶
[2025-06-23 15:30:16][INFO]: == Starting Task: åŸºäºç ”ç©¶æŠ¥å‘Šï¼Œåˆ›ä½œå…³äº"äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨"çš„é«˜è´¨é‡æ–‡ç« 

[2025-06-23 15:30:45][DEBUG]: == [åˆ›æ„å†™ä½œä¸“å®¶] Task output:
æ–‡ç« åˆç¨¿å·²å®Œæˆï¼ŒåŒ…å«5ä¸ªä¸»è¦ç« èŠ‚ï¼Œæ€»è®¡4200å­—...

[2025-06-23 15:30:46][DEBUG]: == Working Agent: ä¸“ä¸šå†…å®¹ç¼–è¾‘
[2025-06-23 15:30:46][INFO]: == Starting Task: å…¨é¢ç¼–è¾‘å’Œä¼˜åŒ–æ–‡ç« å†…å®¹

[2025-06-23 15:31:10][DEBUG]: == [ä¸“ä¸šå†…å®¹ç¼–è¾‘] Task output:
æ–‡ç« ç¼–è¾‘å®Œæˆï¼Œä¼˜åŒ–äº†ç»“æ„å’Œè¯­è¨€è¡¨è¾¾...

[2025-06-23 15:31:11][DEBUG]: == Working Agent: å†…å®¹è´¨é‡è¯„ä¼°å¸ˆ
[2025-06-23 15:31:11][INFO]: == Starting Task: å¯¹æœ€ç»ˆæ–‡ç« è¿›è¡Œå…¨é¢è´¨é‡è¯„ä¼°

[2025-06-23 15:31:25][DEBUG]: == [å†…å®¹è´¨é‡è¯„ä¼°å¸ˆ] Task output:
è´¨é‡è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†92åˆ†ï¼Œæ–‡ç« è´¨é‡ä¼˜ç§€...

ğŸ‰ å†…å®¹åˆ›ä½œå®Œæˆï¼
ğŸ“„ æœ€ç»ˆç»“æœ: è´¨é‡è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†92åˆ†ï¼Œæ–‡ç« è´¨é‡ä¼˜ç§€...

ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:
   âœ… research_report.md
   âœ… article_draft.md
   âœ… article_final.md
   âœ… quality_report.md

âœ… é¡¹ç›®è¿è¡ŒæˆåŠŸï¼
ğŸ“– æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶äº†è§£è¯¦ç»†ç»“æœ
```

### ğŸ” è°ƒè¯•æŠ€å·§

#### 1. å¸¸è§é—®é¢˜æ’æŸ¥

**é—®é¢˜1ï¼šAPIå¯†é’¥é”™è¯¯**
```bash
âŒ æ‰§è¡Œå‡ºé”™: Invalid API key provided

# è§£å†³æ–¹æ¡ˆï¼š
# 1. æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥
cat .env | grep OPENAI_API_KEY

# 2. ç¡®ä¿APIå¯†é’¥æ ¼å¼æ­£ç¡®
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**é—®é¢˜2ï¼šç½‘ç»œè¿æ¥é—®é¢˜**
```bash
âŒ æ‰§è¡Œå‡ºé”™: Connection timeout

# è§£å†³æ–¹æ¡ˆï¼š
# 1. æ£€æŸ¥ç½‘ç»œè¿æ¥
ping api.openai.com

# 2. æ£€æŸ¥ä»£ç†è®¾ç½®ï¼ˆå¦‚æœä½¿ç”¨ä»£ç†ï¼‰
export https_proxy=http://your-proxy:port
```

**é—®é¢˜3ï¼šä¾èµ–åŒ…ç¼ºå¤±**
```bash
âŒ ModuleNotFoundError: No module named 'crewai_tools'

# è§£å†³æ–¹æ¡ˆï¼š
pip install 'crewai[tools]'
```

#### 2. è°ƒè¯•æ¨¡å¼é…ç½®

åœ¨`.env`æ–‡ä»¶ä¸­å¯ç”¨è¯¦ç»†è°ƒè¯•ï¼š

```bash
# è°ƒè¯•é…ç½®
CREWAI_VERBOSE=true
CREWAI_LOG_LEVEL=DEBUG
OPENAI_LOG_LEVEL=debug

# æ€§èƒ½ç›‘æ§
CREWAI_TELEMETRY_OPT_OUT=false
```

#### 3. æ—¥å¿—åˆ†æ

åˆ›å»ºæ—¥å¿—åˆ†æè„šæœ¬`debug_helper.py`ï¼š

```python
# debug_helper.py - è°ƒè¯•è¾…åŠ©å·¥å…·
import re
import sys
from datetime import datetime

def analyze_logs(log_file="crewai.log"):
    """åˆ†æCrewAIæ‰§è¡Œæ—¥å¿—"""
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–å…³é”®ä¿¡æ¯
        agents = re.findall(r'Working Agent: (.+)', content)
        tasks = re.findall(r'Starting Task: (.+)', content)
        errors = re.findall(r'ERROR: (.+)', content)

        print("ğŸ“Š æ—¥å¿—åˆ†ææŠ¥å‘Š")
        print(f"ğŸ¤– æ‰§è¡Œçš„Agent: {len(set(agents))}")
        for agent in set(agents):
            print(f"   - {agent}")

        print(f"ğŸ“‹ æ‰§è¡Œçš„Task: {len(tasks)}")
        for i, task in enumerate(tasks, 1):
            print(f"   {i}. {task[:50]}...")

        if errors:
            print(f"âŒ å‘ç°é”™è¯¯: {len(errors)}")
            for error in errors:
                print(f"   - {error}")
        else:
            print("âœ… æœªå‘ç°é”™è¯¯")

    except FileNotFoundError:
        print("âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")

if __name__ == "__main__":
    analyze_logs()
```

### âš¡ æ€§èƒ½ä¼˜åŒ–

#### 1. Agentæ€§èƒ½ä¼˜åŒ–

```python
# ä¼˜åŒ–Agenté…ç½®
@agent
def optimized_researcher(self) -> Agent:
    """ä¼˜åŒ–çš„ç ”ç©¶ä¸“å®¶Agent"""
    return Agent(
        config=self.agents_config['researcher'],
        tools=[self.search_tool, self.file_writer],

        # æ€§èƒ½ä¼˜åŒ–é…ç½®
        max_iter=3,              # å‡å°‘è¿­ä»£æ¬¡æ•°
        max_execution_time=180,  # 3åˆ†é’Ÿè¶…æ—¶

        # LLMä¼˜åŒ–
        llm=ChatOpenAI(
            model="gpt-4o-mini",  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
            temperature=0.1,      # é™ä½éšæœºæ€§
            max_tokens=1500       # é™åˆ¶è¾“å‡ºé•¿åº¦
        ),

        verbose=False,           # ç”Ÿäº§ç¯å¢ƒå…³é—­è¯¦ç»†è¾“å‡º
        memory=False,            # ç®€å•ä»»åŠ¡å…³é—­è®°å¿†
    )
```

#### 2. å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–

```python
# åˆ›å»ºå¹¶è¡Œæ‰§è¡Œç‰ˆæœ¬
@crew
def parallel_crew(self) -> Crew:
    """å¹¶è¡Œæ‰§è¡Œçš„Crewï¼ˆé€‚åˆç‹¬ç«‹ä»»åŠ¡ï¼‰"""
    return Crew(
        agents=self.agents,
        tasks=[
            # å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡
            self.research_task,
            self.preliminary_analysis_task
        ],
        process=Process.sequential,  # å³ä½¿æ˜¯sequentialä¹Ÿä¼šå°½å¯èƒ½å¹¶è¡Œ
        max_rpm=20,                  # æé«˜APIè°ƒç”¨é¢‘ç‡
        cache=True,                  # å¯ç”¨ç¼“å­˜
        verbose=False
    )
```

#### 3. ç¼“å­˜ç­–ç•¥

```python
# å¯ç”¨æ™ºèƒ½ç¼“å­˜
import hashlib
import json
import os

class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†"""

    def __init__(self, cache_dir="cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

    def get_cache_key(self, inputs):
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = json.dumps(inputs, sort_keys=True)
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, inputs):
        """è·å–ç¼“å­˜"""
        key = self.get_cache_key(inputs)
        cache_file = os.path.join(self.cache_dir, f"{key}.json")

        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

    def set(self, inputs, result):
        """è®¾ç½®ç¼“å­˜"""
        key = self.get_cache_key(inputs)
        cache_file = os.path.join(self.cache_dir, f"{key}.json")

        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

# åœ¨main.pyä¸­ä½¿ç”¨ç¼“å­˜
cache = SmartCache()

def run_with_cache():
    """å¸¦ç¼“å­˜çš„è¿è¡Œå‡½æ•°"""
    inputs = get_user_inputs()

    # æ£€æŸ¥ç¼“å­˜
    cached_result = cache.get(inputs)
    if cached_result:
        print("ğŸ¯ ä½¿ç”¨ç¼“å­˜ç»“æœ")
        return cached_result

    # æ‰§è¡ŒCrew
    result = ContentCreatorAiCrew().crew().kickoff(inputs=inputs)

    # ä¿å­˜åˆ°ç¼“å­˜
    cache.set(inputs, result.raw)

    return result
```

---

## 3.8 ç»“æœåˆ†ææ”¹è¿›ğŸ“Š

### ğŸ“ˆ ç»“æœè´¨é‡è¯„ä¼°

#### 1. è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥

åˆ›å»ºè´¨é‡æ£€æŸ¥è„šæœ¬`quality_checker.py`ï¼š

```python
# quality_checker.py - è´¨é‡æ£€æŸ¥å·¥å…·
import os
import re
from typing import Dict, List

class ContentQualityChecker:
    """å†…å®¹è´¨é‡æ£€æŸ¥å™¨"""

    def __init__(self):
        self.quality_metrics = {}

    def check_file_quality(self, file_path: str) -> Dict:
        """æ£€æŸ¥æ–‡ä»¶è´¨é‡"""
        if not os.path.exists(file_path):
            return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        return {
            "file_size": len(content),
            "word_count": len(content.split()),
            "paragraph_count": len([p for p in content.split('\n\n') if p.strip()]),
            "has_title": bool(re.search(r'^#\s+.+', content, re.MULTILINE)),
            "has_structure": bool(re.search(r'^#{2,}\s+.+', content, re.MULTILINE)),
            "readability_score": self.calculate_readability(content)
        }

    def calculate_readability(self, text: str) -> float:
        """è®¡ç®—å¯è¯»æ€§åˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        sentences = len(re.findall(r'[.!?]+', text))
        words = len(text.split())

        if sentences == 0:
            return 0.0

        avg_sentence_length = words / sentences

        # ç®€åŒ–çš„å¯è¯»æ€§è¯„åˆ†ï¼ˆç†æƒ³å¥é•¿15-20è¯ï¼‰
        if 15 <= avg_sentence_length <= 20:
            return 1.0
        elif 10 <= avg_sentence_length <= 25:
            return 0.8
        elif 5 <= avg_sentence_length <= 30:
            return 0.6
        else:
            return 0.4

    def generate_quality_report(self) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        files_to_check = [
            'research_report.md',
            'article_draft.md',
            'article_final.md',
            'quality_report.md'
        ]

        report = "# å†…å®¹è´¨é‡æ£€æŸ¥æŠ¥å‘Š\n\n"

        for file_path in files_to_check:
            metrics = self.check_file_quality(file_path)

            if "error" in metrics:
                report += f"## {file_path}\nâŒ {metrics['error']}\n\n"
                continue

            report += f"## {file_path}\n"
            report += f"- æ–‡ä»¶å¤§å°: {metrics['file_size']:,} å­—ç¬¦\n"
            report += f"- è¯æ•°: {metrics['word_count']:,}\n"
            report += f"- æ®µè½æ•°: {metrics['paragraph_count']}\n"
            report += f"- æœ‰æ ‡é¢˜: {'âœ…' if metrics['has_title'] else 'âŒ'}\n"
            report += f"- æœ‰ç»“æ„: {'âœ…' if metrics['has_structure'] else 'âŒ'}\n"
            report += f"- å¯è¯»æ€§: {metrics['readability_score']:.1%}\n\n"

        return report

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    checker = ContentQualityChecker()
    report = checker.generate_quality_report()

    with open('quality_check_report.md', 'w', encoding='utf-8') as f:
        f.write(report)

    print("ğŸ“Š è´¨é‡æ£€æŸ¥å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° quality_check_report.md")
```

#### 2. ç”¨æˆ·åé¦ˆæ”¶é›†

åˆ›å»ºåé¦ˆæ”¶é›†è„šæœ¬`feedback_collector.py`ï¼š

```python
# feedback_collector.py - åé¦ˆæ”¶é›†å·¥å…·
import json
import os
from datetime import datetime
from typing import Dict

class FeedbackCollector:
    """ç”¨æˆ·åé¦ˆæ”¶é›†å™¨"""

    def __init__(self, feedback_file="feedback.json"):
        self.feedback_file = feedback_file
        self.feedback_data = self.load_feedback()

    def load_feedback(self) -> list:
        """åŠ è½½ç°æœ‰åé¦ˆ"""
        if os.path.exists(self.feedback_file):
            with open(self.feedback_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

    def save_feedback(self):
        """ä¿å­˜åé¦ˆæ•°æ®"""
        with open(self.feedback_file, 'w', encoding='utf-8') as f:
            json.dump(self.feedback_data, f, ensure_ascii=False, indent=2)

    def collect_feedback(self, topic: str, result_files: List[str]) -> Dict:
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        print("\nğŸ“ è¯·å¯¹æœ¬æ¬¡å†…å®¹åˆ›ä½œè¿›è¡Œè¯„ä»·ï¼š")

        # æ•´ä½“æ»¡æ„åº¦
        while True:
            try:
                overall_rating = int(input("æ•´ä½“æ»¡æ„åº¦ (1-5åˆ†): "))
                if 1 <= overall_rating <= 5:
                    break
                print("è¯·è¾“å…¥1-5ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")

        # å„ç»´åº¦è¯„åˆ†
        dimensions = {
            "research_quality": "ç ”ç©¶è´¨é‡",
            "writing_quality": "å†™ä½œè´¨é‡",
            "content_accuracy": "å†…å®¹å‡†ç¡®æ€§",
            "usefulness": "å®ç”¨æ€§"
        }

        ratings = {}
        for key, name in dimensions.items():
            while True:
                try:
                    rating = int(input(f"{name} (1-5åˆ†): "))
                    if 1 <= rating <= 5:
                        ratings[key] = rating
                        break
                    print("è¯·è¾“å…¥1-5ä¹‹é—´çš„æ•°å­—")
                except ValueError:
                    print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")

        # æ–‡å­—åé¦ˆ
        comments = input("å…¶ä»–å»ºè®®æˆ–æ„è§ (å¯é€‰): ").strip()

        # ä¿å­˜åé¦ˆ
        feedback = {
            "timestamp": datetime.now().isoformat(),
            "topic": topic,
            "overall_rating": overall_rating,
            "dimension_ratings": ratings,
            "comments": comments,
            "result_files": result_files
        }

        self.feedback_data.append(feedback)
        self.save_feedback()

        print("âœ… åé¦ˆå·²ä¿å­˜ï¼Œæ„Ÿè°¢æ‚¨çš„è¯„ä»·ï¼")
        return feedback

    def analyze_feedback(self) -> str:
        """åˆ†æåé¦ˆè¶‹åŠ¿"""
        if not self.feedback_data:
            return "æš‚æ— åé¦ˆæ•°æ®"

        # è®¡ç®—å¹³å‡åˆ†
        total_feedback = len(self.feedback_data)
        avg_overall = sum(f["overall_rating"] for f in self.feedback_data) / total_feedback

        # å„ç»´åº¦å¹³å‡åˆ†
        dimensions = ["research_quality", "writing_quality", "content_accuracy", "usefulness"]
        avg_dimensions = {}

        for dim in dimensions:
            scores = [f["dimension_ratings"].get(dim, 0) for f in self.feedback_data]
            avg_dimensions[dim] = sum(scores) / len(scores) if scores else 0

        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = f"""# ç”¨æˆ·åé¦ˆåˆ†ææŠ¥å‘Š

## æ€»ä½“ç»Ÿè®¡
- åé¦ˆæ•°é‡: {total_feedback}
- å¹³å‡æ»¡æ„åº¦: {avg_overall:.1f}/5.0

## å„ç»´åº¦è¯„åˆ†
- ç ”ç©¶è´¨é‡: {avg_dimensions['research_quality']:.1f}/5.0
- å†™ä½œè´¨é‡: {avg_dimensions['writing_quality']:.1f}/5.0
- å†…å®¹å‡†ç¡®æ€§: {avg_dimensions['content_accuracy']:.1f}/5.0
- å®ç”¨æ€§: {avg_dimensions['usefulness']:.1f}/5.0

## æ”¹è¿›å»ºè®®
"""

        # æ‰¾å‡ºè¯„åˆ†æœ€ä½çš„ç»´åº¦
        lowest_dim = min(avg_dimensions.items(), key=lambda x: x[1])
        report += f"- é‡ç‚¹æ”¹è¿›: {lowest_dim[0]} (å½“å‰è¯„åˆ†: {lowest_dim[1]:.1f})\n"

        # æœ€è¿‘çš„è¯„è®º
        recent_comments = [f["comments"] for f in self.feedback_data[-5:] if f["comments"]]
        if recent_comments:
            report += "\n## æœ€è¿‘ç”¨æˆ·è¯„è®º\n"
            for comment in recent_comments:
                report += f"- {comment}\n"

        return report

# é›†æˆåˆ°main.py
def main_with_feedback():
    """å¸¦åé¦ˆæ”¶é›†çš„ä¸»å‡½æ•°"""
    collector = FeedbackCollector()

    # è¿è¡Œå†…å®¹åˆ›ä½œ
    result = run()

    if result:
        # æ”¶é›†åé¦ˆ
        output_files = ['research_report.md', 'article_final.md', 'quality_report.md']
        feedback = collector.collect_feedback(
            topic=inputs.get('topic', ''),
            result_files=output_files
        )

        # ç”Ÿæˆåé¦ˆåˆ†æ
        analysis = collector.analyze_feedback()
        with open('feedback_analysis.md', 'w', encoding='utf-8') as f:
            f.write(analysis)
```
### ğŸ”„ æŒç»­æ”¹è¿›ç­–ç•¥

#### 1. ç‰ˆæœ¬è¿­ä»£ç®¡ç†

åˆ›å»ºç‰ˆæœ¬ç®¡ç†è„šæœ¬`version_manager.py`ï¼š

```python
# version_manager.py - ç‰ˆæœ¬ç®¡ç†å·¥å…·
import json
import os
import shutil
from datetime import datetime
from typing import Dict, List

class VersionManager:
    """é¡¹ç›®ç‰ˆæœ¬ç®¡ç†å™¨"""

    def __init__(self, project_dir="."):
        self.project_dir = project_dir
        self.versions_dir = os.path.join(project_dir, "versions")
        self.version_file = os.path.join(project_dir, "version_history.json")

        os.makedirs(self.versions_dir, exist_ok=True)
        self.version_history = self.load_version_history()

    def load_version_history(self) -> List[Dict]:
        """åŠ è½½ç‰ˆæœ¬å†å²"""
        if os.path.exists(self.version_file):
            with open(self.version_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

    def save_version_history(self):
        """ä¿å­˜ç‰ˆæœ¬å†å²"""
        with open(self.version_file, 'w', encoding='utf-8') as f:
            json.dump(self.version_history, f, ensure_ascii=False, indent=2)

    def create_version(self, description: str, changes: List[str]) -> str:
        """åˆ›å»ºæ–°ç‰ˆæœ¬"""
        version_num = len(self.version_history) + 1
        version_id = f"v{version_num:03d}"
        timestamp = datetime.now().isoformat()

        # åˆ›å»ºç‰ˆæœ¬ç›®å½•
        version_dir = os.path.join(self.versions_dir, version_id)
        os.makedirs(version_dir, exist_ok=True)

        # å¤‡ä»½å…³é”®æ–‡ä»¶
        files_to_backup = [
            "src/content_creator_ai/crew.py",
            "src/content_creator_ai/config/agents.yaml",
            "src/content_creator_ai/config/tasks.yaml",
            "src/content_creator_ai/main.py"
        ]

        for file_path in files_to_backup:
            if os.path.exists(file_path):
                dest_path = os.path.join(version_dir, os.path.basename(file_path))
                shutil.copy2(file_path, dest_path)

        # è®°å½•ç‰ˆæœ¬ä¿¡æ¯
        version_info = {
            "version_id": version_id,
            "timestamp": timestamp,
            "description": description,
            "changes": changes,
            "files_backed_up": files_to_backup
        }

        self.version_history.append(version_info)
        self.save_version_history()

        print(f"âœ… ç‰ˆæœ¬ {version_id} åˆ›å»ºæˆåŠŸ")
        return version_id

    def list_versions(self):
        """åˆ—å‡ºæ‰€æœ‰ç‰ˆæœ¬"""
        print("ğŸ“‹ ç‰ˆæœ¬å†å²:")
        for version in self.version_history:
            print(f"  {version['version_id']} - {version['timestamp'][:10]}")
            print(f"    æè¿°: {version['description']}")
            print(f"    å˜æ›´: {len(version['changes'])} é¡¹")
            print()

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    vm = VersionManager()

    # åˆ›å»ºç‰ˆæœ¬
    vm.create_version(
        description="åˆå§‹ç‰ˆæœ¬ - åŸºç¡€å†…å®¹åˆ›ä½œåŠŸèƒ½",
        changes=[
            "å®ç°äº†4ä¸ªæ ¸å¿ƒAgent",
            "æ·»åŠ äº†é¡ºåºæ‰§è¡Œæµç¨‹",
            "é›†æˆäº†æœç´¢å’Œæ–‡ä»¶å·¥å…·",
            "å®Œæˆäº†åŸºæœ¬çš„è´¨é‡è¯„ä¼°"
        ]
    )

    # åˆ—å‡ºç‰ˆæœ¬
    vm.list_versions()
```

#### 2. A/Bæµ‹è¯•æ¡†æ¶

```python
# ab_testing.py - A/Bæµ‹è¯•æ¡†æ¶
import random
import json
import os
from typing import Dict, Any

class ABTestManager:
    """A/Bæµ‹è¯•ç®¡ç†å™¨"""

    def __init__(self):
        self.test_configs = {}
        self.test_results = {}
        self.load_test_data()

    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        if os.path.exists("ab_test_results.json"):
            with open("ab_test_results.json", 'r', encoding='utf-8') as f:
                self.test_results = json.load(f)

    def save_test_data(self):
        """ä¿å­˜æµ‹è¯•æ•°æ®"""
        with open("ab_test_results.json", 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)

    def create_test(self, test_name: str, variant_a: Dict, variant_b: Dict):
        """åˆ›å»ºA/Bæµ‹è¯•"""
        self.test_configs[test_name] = {
            "variant_a": variant_a,
            "variant_b": variant_b,
            "results": {"a": [], "b": []}
        }

    def get_variant(self, test_name: str, user_id: str = None) -> str:
        """è·å–ç”¨æˆ·åº”è¯¥ä½¿ç”¨çš„å˜ä½“"""
        if user_id:
            # åŸºäºç”¨æˆ·IDçš„ä¸€è‡´æ€§åˆ†é…
            hash_value = hash(user_id) % 100
            return "a" if hash_value < 50 else "b"
        else:
            # éšæœºåˆ†é…
            return random.choice(["a", "b"])

    def record_result(self, test_name: str, variant: str, metrics: Dict):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        if test_name not in self.test_results:
            self.test_results[test_name] = {"a": [], "b": []}

        self.test_results[test_name][variant].append(metrics)
        self.save_test_data()

    def analyze_test(self, test_name: str) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if test_name not in self.test_results:
            return {"error": "æµ‹è¯•ä¸å­˜åœ¨"}

        results_a = self.test_results[test_name]["a"]
        results_b = self.test_results[test_name]["b"]

        if not results_a or not results_b:
            return {"error": "æ•°æ®ä¸è¶³"}

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        def avg_metric(results, metric):
            values = [r.get(metric, 0) for r in results]
            return sum(values) / len(values) if values else 0

        analysis = {
            "sample_size": {"a": len(results_a), "b": len(results_b)},
            "quality_score": {
                "a": avg_metric(results_a, "quality_score"),
                "b": avg_metric(results_b, "quality_score")
            },
            "execution_time": {
                "a": avg_metric(results_a, "execution_time"),
                "b": avg_metric(results_b, "execution_time")
            },
            "user_satisfaction": {
                "a": avg_metric(results_a, "user_satisfaction"),
                "b": avg_metric(results_b, "user_satisfaction")
            }
        }

        # ç¡®å®šè·èƒœè€…
        quality_winner = "a" if analysis["quality_score"]["a"] > analysis["quality_score"]["b"] else "b"
        speed_winner = "a" if analysis["execution_time"]["a"] < analysis["execution_time"]["b"] else "b"
        satisfaction_winner = "a" if analysis["user_satisfaction"]["a"] > analysis["user_satisfaction"]["b"] else "b"

        analysis["winners"] = {
            "quality": quality_winner,
            "speed": speed_winner,
            "satisfaction": satisfaction_winner
        }

        return analysis

# é›†æˆåˆ°ä¸»ç¨‹åº
def run_with_ab_test():
    """å¸¦A/Bæµ‹è¯•çš„è¿è¡Œå‡½æ•°"""
    ab_manager = ABTestManager()

    # åˆ›å»ºæµ‹è¯•ï¼šä¸åŒçš„Agenté…ç½®
    ab_manager.create_test(
        "agent_optimization",
        variant_a={"max_iter": 5, "temperature": 0.7},
        variant_b={"max_iter": 3, "temperature": 0.1}
    )

    # è·å–ç”¨æˆ·å˜ä½“
    variant = ab_manager.get_variant("agent_optimization")

    # æ ¹æ®å˜ä½“è¿è¡Œä¸åŒé…ç½®
    if variant == "a":
        print("ğŸ…°ï¸ ä½¿ç”¨å˜ä½“Aé…ç½®")
        # ä½¿ç”¨é…ç½®A
    else:
        print("ğŸ…±ï¸ ä½¿ç”¨å˜ä½“Bé…ç½®")
        # ä½¿ç”¨é…ç½®B

    # è¿è¡Œå¹¶è®°å½•ç»“æœ
    start_time = time.time()
    result = run_crew_with_config(variant)
    execution_time = time.time() - start_time

    # è®°å½•æµ‹è¯•ç»“æœ
    ab_manager.record_result(
        "agent_optimization",
        variant,
        {
            "quality_score": extract_quality_score(result),
            "execution_time": execution_time,
            "user_satisfaction": get_user_rating()
        }
    )
```

---

## 3.9 æœ¬ç« å°ç»“ğŸ“š

æ­å–œä½ ï¼ğŸ‰ ä½ å·²ç»æˆåŠŸåˆ›å»ºäº†ç¬¬ä¸€ä¸ªå®Œæ•´çš„CrewAIé¡¹ç›®ï¼

### âœ… æœ¬ç« æˆå°±è§£é”

- **ğŸ—ï¸ é¡¹ç›®æ¶æ„å¸ˆ**ï¼šè®¾è®¡äº†å®Œæ•´çš„AIå†…å®¹åˆ›ä½œç³»ç»Ÿ
- **ğŸ¤– Agentè®­ç»ƒå¸ˆ**ï¼šåˆ›å»ºäº†4ä¸ªä¸“ä¸šçš„AIæ™ºèƒ½ä½“
- **ğŸ“‹ ä»»åŠ¡è®¾è®¡å¸ˆ**ï¼šè®¾è®¡äº†é«˜æ•ˆçš„å·¥ä½œæµç¨‹
- **ğŸ”§ å·¥å…·å¼€å‘è€…**ï¼šé›†æˆå¹¶å¼€å‘äº†è‡ªå®šä¹‰å·¥å…·
- **ğŸ° å›¢é˜ŸæŒ‡æŒ¥å®˜**ï¼šç»„å»ºäº†åä½œæ— é—´çš„AIå›¢é˜Ÿ
- **ğŸ” è°ƒè¯•ä¸“å®¶**ï¼šæŒæ¡äº†è°ƒè¯•å’Œä¼˜åŒ–æŠ€èƒ½
- **ğŸ“Š è´¨é‡ç®¡ç†å¸ˆ**ï¼šå»ºç«‹äº†è´¨é‡è¯„ä¼°ä½“ç³»

### ğŸ“– æ ¸å¿ƒçŸ¥è¯†å›é¡¾

1. **ğŸ—ï¸ é¡¹ç›®è§„åˆ’**ï¼š
   - æ˜ç¡®é¡¹ç›®ç›®æ ‡å’ŒåŠŸèƒ½éœ€æ±‚
   - è®¾è®¡åˆç†çš„AIå›¢é˜Ÿè§’è‰²åˆ†å·¥
   - è§„åˆ’é«˜æ•ˆçš„å·¥ä½œæµç¨‹

2. **ğŸ¤– Agentè®¾è®¡**ï¼š
   - ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶å®šä¹‰Agent
   - ä¸ºä¸åŒAgenté…ç½®ä¸“é—¨çš„å·¥å…·
   - ä¼˜åŒ–Agentæ€§èƒ½å’Œè¡Œä¸ºå‚æ•°

3. **ğŸ“‹ Taskå·¥ä½œæµ**ï¼š
   - è®¾è®¡æ¸…æ™°çš„ä»»åŠ¡æè¿°å’ŒæœŸæœ›è¾“å‡º
   - å»ºç«‹ä»»åŠ¡é—´çš„ä¾èµ–å…³ç³»
   - å®ç°ç»“æ„åŒ–è¾“å‡ºå’Œè´¨é‡éªŒè¯

4. **ğŸ”§ å·¥å…·é›†æˆ**ï¼š
   - ä½¿ç”¨å†…ç½®å·¥å…·æ‰©å±•Agentèƒ½åŠ›
   - å¼€å‘è‡ªå®šä¹‰å·¥å…·æ»¡è¶³ç‰¹æ®Šéœ€æ±‚
   - åˆç†åˆ†é…å·¥å…·ç»™ä¸åŒAgent

5. **ğŸ° Crewåä½œ**ï¼š
   - é…ç½®Sequentialæ‰§è¡Œæµç¨‹
   - å¯ç”¨è®°å¿†å’Œç¼“å­˜åŠŸèƒ½
   - è®¾ç½®æ€§èƒ½å’Œå®‰å…¨å‚æ•°

6. **ğŸ” è°ƒè¯•ä¼˜åŒ–**ï¼š
   - æŒæ¡å¸¸è§é—®é¢˜çš„æ’æŸ¥æ–¹æ³•
   - å®ç°æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—åˆ†æ
   - åº”ç”¨ç¼“å­˜å’Œå¹¶è¡Œä¼˜åŒ–ç­–ç•¥

7. **ğŸ“Š è´¨é‡ç®¡ç†**ï¼š
   - å»ºç«‹è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥æœºåˆ¶
   - æ”¶é›†å’Œåˆ†æç”¨æˆ·åé¦ˆ
   - å®ç°ç‰ˆæœ¬ç®¡ç†å’ŒA/Bæµ‹è¯•

### ğŸ¯ å®é™…åº”ç”¨ä»·å€¼

é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œä½ åˆ›å»ºçš„AIå†…å®¹åˆ›ä½œåŠ©æ‰‹å…·æœ‰ä»¥ä¸‹å®ç”¨ä»·å€¼ï¼š

- **ğŸ“š ç ”ç©¶æ•ˆç‡**ï¼šè‡ªåŠ¨æœç´¢å’Œæ•´ç†ç›¸å…³èµ„æ–™ï¼ŒèŠ‚çœå¤§é‡æ—¶é—´
- **âœï¸ åˆ›ä½œè´¨é‡**ï¼šåŸºäºå……åˆ†ç ”ç©¶ç”Ÿæˆé«˜è´¨é‡æ–‡ç« å†…å®¹
- **âœ¨ ä¸“ä¸šç¼–è¾‘**ï¼šè‡ªåŠ¨ä¼˜åŒ–è¯­è¨€è¡¨è¾¾å’Œæ–‡ç« ç»“æ„
- **ğŸ“Š è´¨é‡ä¿è¯**ï¼šå¤šç»´åº¦è¯„ä¼°ç¡®ä¿å†…å®¹è´¨é‡
- **ğŸ”„ æŒç»­æ”¹è¿›**ï¼šé€šè¿‡åé¦ˆå’Œæµ‹è¯•ä¸æ–­ä¼˜åŒ–ç³»ç»Ÿ

### ğŸš€ ä¸‹ä¸€æ­¥é¢„å‘Š

åœ¨ç¬¬4ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢ç´¢å¤šæ™ºèƒ½ä½“åä½œçš„é«˜çº§æ¨¡å¼ï¼Œå­¦ä¹ ï¼š

- ğŸ¤ **Hierarchicalåä½œæ¨¡å¼**ï¼šManager Agentç»Ÿç­¹ç®¡ç†
- âš¡ **å¹¶è¡Œæ‰§è¡Œç­–ç•¥**ï¼šæå‡ç³»ç»Ÿæ‰§è¡Œæ•ˆç‡
- ğŸ”€ **åŠ¨æ€ä»»åŠ¡åˆ†é…**ï¼šæ ¹æ®Agentèƒ½åŠ›æ™ºèƒ½åˆ†é…
- ğŸ¯ **å¤æ‚ä¸šåŠ¡åœºæ™¯**ï¼šå¤„ç†æ›´å¤æ‚çš„å®é™…åº”ç”¨

### ğŸ® å®è·µç»ƒä¹ 

åœ¨è¿›å…¥ä¸‹ä¸€ç« ä¹‹å‰ï¼Œè¯•è¯•è¿™äº›ç»ƒä¹ æ¥å·©å›ºå­¦ä¹ ï¼š

#### ç»ƒä¹ 1ï¼šæ‰©å±•åŠŸèƒ½ ğŸš€
ä¸ºä½ çš„å†…å®¹åˆ›ä½œåŠ©æ‰‹æ·»åŠ æ–°åŠŸèƒ½ï¼š
- æ·»åŠ å›¾ç‰‡ç”ŸæˆAgent
- é›†æˆç¤¾äº¤åª’ä½“å‘å¸ƒåŠŸèƒ½
- å®ç°å¤šè¯­è¨€å†…å®¹åˆ›ä½œ

#### ç»ƒä¹ 2ï¼šæ€§èƒ½ä¼˜åŒ– âš¡
ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼š
- å®ç°æ™ºèƒ½ç¼“å­˜ç­–ç•¥
- æ·»åŠ å¹¶è¡Œæ‰§è¡Œæ”¯æŒ
- ä¼˜åŒ–APIè°ƒç”¨é¢‘ç‡

#### ç»ƒä¹ 3ï¼šè´¨é‡æå‡ ğŸ“Š
æå‡å†…å®¹è´¨é‡ï¼š
- æ·»åŠ äº‹å®æ ¸æŸ¥Agent
- å®ç°SEOä¼˜åŒ–åŠŸèƒ½
- é›†æˆæŠ„è¢­æ£€æµ‹å·¥å…·

#### ç»ƒä¹ 4ï¼šç”¨æˆ·ä½“éªŒ ğŸ¨
æ”¹å–„ç”¨æˆ·ä½“éªŒï¼š
- æ·»åŠ Webç•Œé¢
- å®ç°å®æ—¶è¿›åº¦æ˜¾ç¤º
- æ”¯æŒæ‰¹é‡å¤„ç†åŠŸèƒ½

---

**ğŸ‰ å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬å‰å¾€ [ç¬¬4ç« ï¼šå¤šæ™ºèƒ½ä½“åä½œå®æˆ˜](./CrewAIå­¦ä¹ æŒ‡å—-ç¬¬4ç« .md)ï¼Œæ¢ç´¢æ›´é«˜çº§çš„åä½œæ¨¡å¼ï¼**