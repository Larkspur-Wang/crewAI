# ç¬¬5ç« ï¼šå·¥å…·é›†æˆä¸è‡ªå®šä¹‰å¼€å‘

> ğŸ”§ ç»™AIè£…ä¸Šç¿…è†€ï¼å­¦ä¼šä½¿ç”¨å’Œå¼€å‘å„ç§å·¥å…·ï¼Œè®©æ™ºèƒ½ä½“æ‹¥æœ‰è¶…èƒ½åŠ›ã€‚

## ğŸ“‹ ç« èŠ‚å¤§çº²

æœ¬ç« å°†å…¨é¢ä»‹ç»ï¼š

1. **ğŸ› ï¸ CrewAIå†…ç½®å·¥å…·è¯¦è§£** - æŒæ¡å¼ºå¤§çš„å†…ç½®å·¥å…·åº“
2. **ğŸŒ ç¬¬ä¸‰æ–¹å·¥å…·é›†æˆæ–¹æ³•** - è¿æ¥å¤–éƒ¨æœåŠ¡å’ŒAPI
3. **ğŸ”§ è‡ªå®šä¹‰å·¥å…·å¼€å‘å®æˆ˜** - ä¸ºç‰¹å®šéœ€æ±‚å¼€å‘ä¸“é—¨å·¥å…·
4. **ğŸ¯ å·¥å…·é“¾è®¾è®¡å’Œä¼˜åŒ–** - æ„å»ºé«˜æ•ˆçš„å·¥å…·ä½¿ç”¨ç­–ç•¥
5. **ğŸ›¡ï¸ å·¥å…·å®‰å…¨å’Œæƒé™ç®¡ç†** - ç¡®ä¿å·¥å…·ä½¿ç”¨çš„å®‰å…¨æ€§
6. **ğŸ“Š å·¥å…·æ€§èƒ½ç›‘æ§** - ç›‘æ§å’Œä¼˜åŒ–å·¥å…·æ€§èƒ½
7. **ğŸš€ é«˜çº§å·¥å…·å¼€å‘æŠ€å·§** - æŒæ¡å·¥å…·å¼€å‘çš„æœ€ä½³å®è·µ
8. **ğŸª å®æˆ˜æ¡ˆä¾‹åˆ†æ** - é€šè¿‡å®é™…æ¡ˆä¾‹å­¦ä¹ å·¥å…·åº”ç”¨

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š
- âœ… ç†Ÿç»ƒä½¿ç”¨CrewAIæä¾›çš„æ‰€æœ‰å†…ç½®å·¥å…·
- âœ… æŒæ¡ç¬¬ä¸‰æ–¹å·¥å…·é›†æˆçš„æ–¹æ³•å’Œæœ€ä½³å®è·µ
- âœ… ç‹¬ç«‹å¼€å‘æ»¡è¶³ç‰¹å®šéœ€æ±‚çš„è‡ªå®šä¹‰å·¥å…·
- âœ… è®¾è®¡é«˜æ•ˆã€å®‰å…¨çš„å·¥å…·é“¾æ¶æ„
- âœ… å®ç°å·¥å…·çš„æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
- âœ… å…·å¤‡è§£å†³å¤æ‚å·¥å…·é›†æˆé—®é¢˜çš„èƒ½åŠ›

---

## 5.1 CrewAIå†…ç½®å·¥å…·è¯¦è§£ğŸ› ï¸

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šè£…å¤‡ç³»ç»Ÿ

CrewAIçš„å·¥å…·ç³»ç»Ÿå°±åƒRPGæ¸¸æˆä¸­çš„è£…å¤‡ç³»ç»Ÿï¼š

- **âš”ï¸ æ­¦å™¨è£…å¤‡**ï¼šæ”»å‡»å‹å·¥å…·ï¼ˆæœç´¢ã€åˆ†æï¼‰
- **ğŸ›¡ï¸ é˜²å…·è£…å¤‡**ï¼šé˜²æŠ¤å‹å·¥å…·ï¼ˆéªŒè¯ã€å®‰å…¨ï¼‰
- **ğŸ’ é¥°å“è£…å¤‡**ï¼šè¾…åŠ©å‹å·¥å…·ï¼ˆæ–‡ä»¶ã€é€šä¿¡ï¼‰
- **ğŸ§ª æ¶ˆè€—å“**ï¼šä¸€æ¬¡æ€§å·¥å…·ï¼ˆè®¡ç®—ã€è½¬æ¢ï¼‰

æ¯ä¸ªAgentå¯ä»¥è£…å¤‡ä¸åŒçš„å·¥å…·ç»„åˆï¼Œå½¢æˆç‹¬ç‰¹çš„èƒ½åŠ›é…ç½®ã€‚

### ğŸ“Š å†…ç½®å·¥å…·åˆ†ç±»ä½“ç³»

```mermaid
graph TD
    A[CrewAIå†…ç½®å·¥å…·] --> B[ğŸ” ä¿¡æ¯è·å–å·¥å…·]
    A --> C[ğŸ“„ æ–‡ä»¶æ“ä½œå·¥å…·]
    A --> D[ğŸŒ ç½‘ç»œæœåŠ¡å·¥å…·]
    A --> E[ğŸ’» ä»£ç æ‰§è¡Œå·¥å…·]
    A --> F[ğŸ¨ å†…å®¹åˆ›ä½œå·¥å…·]
    A --> G[ğŸ¤ åä½œé€šä¿¡å·¥å…·]
    A --> H[â˜ï¸ äº‘æœåŠ¡å·¥å…·]
    A --> I[ğŸ§  AI/MLå·¥å…·]

    B --> B1[SerperDevTool - æœç´¢å¼•æ“]
    B --> B2[WebsiteSearchTool - ç½‘ç«™æœç´¢]
    B --> B3[ScrapeWebsiteTool - ç½‘é¡µæŠ“å–]

    C --> C1[FileReadTool - æ–‡ä»¶è¯»å–]
    C --> C2[FileWriterTool - æ–‡ä»¶å†™å…¥]
    C --> C3[DirectoryReadTool - ç›®å½•è¯»å–]
    C --> C4[CSVSearchTool - CSVæœç´¢]

    D --> D1[BrowserTool - æµè§ˆå™¨æ“ä½œ]
    D --> D2[YoutubeChannelSearchTool - YouTubeæœç´¢]
    D --> D3[YoutubeVideoSearchTool - è§†é¢‘æœç´¢]

    E --> E1[CodeInterpreterTool - ä»£ç è§£é‡Šå™¨]
    E --> E2[PythonCodeTool - Pythonæ‰§è¡Œ]

    F --> F1[DallETool - å›¾åƒç”Ÿæˆ]
    F --> F2[VisionTool - å›¾åƒåˆ†æ]

    G --> G1[DelegateWorkTool - ä»»åŠ¡å§”æ´¾]
    G --> G2[AskQuestionTool - è¯¢é—®åŒäº‹]

    H --> H1[S3ReaderTool - S3è¯»å–]
    H --> H2[S3WriterTool - S3å†™å…¥]
    H --> H3[BedrockInvokeAgentTool - Bedrockè°ƒç”¨]

    I --> I1[EmbeddingSearchTool - å‘é‡æœç´¢]
    I --> I2[RAGTool - æ£€ç´¢å¢å¼ºç”Ÿæˆ]
```

### ğŸ” ä¿¡æ¯è·å–å·¥å…·è¯¦è§£

#### 1. SerperDevTool - å¼ºå¤§çš„æœç´¢å¼•æ“

```python
# ğŸ” SerperDevTool - æœ€å¸¸ç”¨çš„æœç´¢å·¥å…·
from crewai_tools import SerperDevTool

# åŸºç¡€ä½¿ç”¨
search_tool = SerperDevTool()

# é«˜çº§é…ç½®
advanced_search_tool = SerperDevTool(
    search_url="https://google.serper.dev/search",
    n_results=10,           # è¿”å›ç»“æœæ•°é‡
    country="cn",           # æœç´¢åœ°åŒº
    locale="zh-cn",         # è¯­è¨€è®¾ç½®
    time_range="y",         # æ—¶é—´èŒƒå›´ï¼šd(å¤©), w(å‘¨), m(æœˆ), y(å¹´)
    search_type="search"    # æœç´¢ç±»å‹ï¼šsearch, images, videos, news
)

# åœ¨Agentä¸­ä½¿ç”¨
research_agent = Agent(
    role="ç ”ç©¶ä¸“å®¶",
    goal="æ”¶é›†æœ€æ–°çš„è¡Œä¸šä¿¡æ¯",
    backstory="ä¸“ä¸šçš„ä¿¡æ¯æ”¶é›†ä¸“å®¶...",
    tools=[advanced_search_tool],
    verbose=True
)

# æœç´¢ç¤ºä¾‹
search_result = search_tool.run("CrewAIå¤šæ™ºèƒ½ä½“æ¡†æ¶æœ€æ–°å‘å±•")
print(search_result)
```

#### 2. WebsiteSearchTool - ç½‘ç«™å†…å®¹æœç´¢

```python
# ğŸŒ WebsiteSearchTool - åœ¨ç‰¹å®šç½‘ç«™å†…æœç´¢
from crewai_tools import WebsiteSearchTool

# æœç´¢ç‰¹å®šç½‘ç«™
website_search = WebsiteSearchTool(
    website="https://docs.crewai.com",
    max_results=5,
    search_depth=3  # æœç´¢æ·±åº¦
)

# ä½¿ç”¨ç¤ºä¾‹
docs_agent = Agent(
    role="æ–‡æ¡£ä¸“å®¶",
    goal="ä»å®˜æ–¹æ–‡æ¡£ä¸­æ‰¾åˆ°å‡†ç¡®ä¿¡æ¯",
    backstory="ç†Ÿæ‚‰æŠ€æœ¯æ–‡æ¡£çš„ä¸“å®¶...",
    tools=[website_search],
    verbose=True
)
```

#### 3. ScrapeWebsiteTool - ç½‘é¡µå†…å®¹æŠ“å–

```python
# ğŸ“„ ScrapeWebsiteTool - æŠ“å–ç½‘é¡µå®Œæ•´å†…å®¹
from crewai_tools import ScrapeWebsiteTool

# åŸºç¡€ç½‘é¡µæŠ“å–
scrape_tool = ScrapeWebsiteTool()

# é«˜çº§é…ç½®
advanced_scrape_tool = ScrapeWebsiteTool(
    website_url="https://example.com",
    css_selector=".content",  # CSSé€‰æ‹©å™¨
    max_length=5000,          # æœ€å¤§å†…å®¹é•¿åº¦
    include_links=True        # åŒ…å«é“¾æ¥
)

# ä½¿ç”¨ç¤ºä¾‹
content_agent = Agent(
    role="å†…å®¹åˆ†æå¸ˆ",
    goal="åˆ†æç½‘é¡µå†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯",
    backstory="ä¸“ä¸šçš„å†…å®¹åˆ†æä¸“å®¶...",
    tools=[advanced_scrape_tool],
    verbose=True
)
```

### ğŸ“„ æ–‡ä»¶æ“ä½œå·¥å…·è¯¦è§£

#### 1. FileReadTool - æ–‡ä»¶è¯»å–å·¥å…·

```python
# ğŸ“– FileReadTool - è¯»å–å„ç§æ ¼å¼æ–‡ä»¶
from crewai_tools import FileReadTool

# åŸºç¡€æ–‡ä»¶è¯»å–
file_reader = FileReadTool()

# æŒ‡å®šæ–‡ä»¶ç±»å‹çš„è¯»å–å™¨
text_reader = FileReadTool(
    file_path="documents/report.txt",
    encoding="utf-8"
)

json_reader = FileReadTool(
    file_path="data/config.json"
)

# åœ¨Agentä¸­ä½¿ç”¨
data_analyst = Agent(
    role="æ•°æ®åˆ†æå¸ˆ",
    goal="åˆ†ææ–‡ä»¶ä¸­çš„æ•°æ®",
    backstory="ç»éªŒä¸°å¯Œçš„æ•°æ®åˆ†æä¸“å®¶...",
    tools=[file_reader, text_reader, json_reader],
    verbose=True
)
```

#### 2. FileWriterTool - æ–‡ä»¶å†™å…¥å·¥å…·

```python
# âœï¸ FileWriterTool - å†™å…¥æ–‡ä»¶
from crewai_tools import FileWriterTool

# åŸºç¡€æ–‡ä»¶å†™å…¥
file_writer = FileWriterTool()

# é…ç½®å†™å…¥é€‰é¡¹
configured_writer = FileWriterTool(
    directory="output",      # è¾“å‡ºç›®å½•
    filename="report.md",    # æ–‡ä»¶å
    overwrite=True          # æ˜¯å¦è¦†ç›–
)

# ä½¿ç”¨ç¤ºä¾‹
report_agent = Agent(
    role="æŠ¥å‘Šæ’°å†™å‘˜",
    goal="ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š",
    backstory="ä¸“ä¸šçš„æŠ¥å‘Šå†™ä½œä¸“å®¶...",
    tools=[file_writer],
    verbose=True
)
```

#### 3. CSVSearchTool - CSVæ•°æ®æœç´¢

```python
# ğŸ“Š CSVSearchTool - åœ¨CSVæ–‡ä»¶ä¸­æœç´¢æ•°æ®
from crewai_tools import CSVSearchTool

# CSVæœç´¢å·¥å…·
csv_search = CSVSearchTool(
    csv_file_path="data/sales_data.csv",
    encoding="utf-8",
    delimiter=","
)

# é«˜çº§CSVæœç´¢
advanced_csv_search = CSVSearchTool(
    csv_file_path="data/large_dataset.csv",
    search_columns=["name", "category", "description"],  # æŒ‡å®šæœç´¢åˆ—
    case_sensitive=False,                                # ä¸åŒºåˆ†å¤§å°å†™
    max_results=20                                       # æœ€å¤§ç»“æœæ•°
)

# ä½¿ç”¨ç¤ºä¾‹
data_researcher = Agent(
    role="æ•°æ®ç ”ç©¶å‘˜",
    goal="ä»CSVæ•°æ®ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯",
    backstory="ä¸“ä¸šçš„æ•°æ®æŒ–æ˜ä¸“å®¶...",
    tools=[csv_search, advanced_csv_search],
    verbose=True
)
```

### ğŸ’» ä»£ç æ‰§è¡Œå·¥å…·è¯¦è§£

#### 1. CodeInterpreterTool - ä»£ç è§£é‡Šå™¨

```python
# ğŸ’» CodeInterpreterTool - å¼ºå¤§çš„ä»£ç æ‰§è¡Œå·¥å…·
from crewai_tools import CodeInterpreterTool

# åŸºç¡€ä»£ç è§£é‡Šå™¨
code_interpreter = CodeInterpreterTool()

# å®‰å…¨æ¨¡å¼é…ç½®
safe_interpreter = CodeInterpreterTool(
    unsafe_mode=False,       # å®‰å…¨æ¨¡å¼
    timeout=30,              # æ‰§è¡Œè¶…æ—¶
    max_memory_mb=512        # å†…å­˜é™åˆ¶
)

# é«˜çº§é…ç½®
advanced_interpreter = CodeInterpreterTool(
    unsafe_mode=True,        # å…è®¸æ›´å¤šæ“ä½œ
    workspace_dir="workspace", # å·¥ä½œç›®å½•
    allowed_imports=[        # å…è®¸çš„å¯¼å…¥æ¨¡å—
        "pandas", "numpy", "matplotlib", "seaborn"
    ]
)

# ä½¿ç”¨ç¤ºä¾‹
data_scientist = Agent(
    role="æ•°æ®ç§‘å­¦å®¶",
    goal="æ‰§è¡Œæ•°æ®åˆ†æå’Œå¯è§†åŒ–",
    backstory="ç²¾é€šPythonæ•°æ®åˆ†æçš„ä¸“å®¶...",
    tools=[advanced_interpreter],
    verbose=True
)
```

#### 2. ä»£ç æ‰§è¡Œæœ€ä½³å®è·µ

```python
# ğŸ¯ ä»£ç æ‰§è¡Œå·¥å…·çš„æœ€ä½³å®è·µ
class SafeCodeExecutor:
    """å®‰å…¨çš„ä»£ç æ‰§è¡Œå™¨"""

    def __init__(self):
        self.interpreter = CodeInterpreterTool(
            unsafe_mode=False,
            timeout=60,
            max_memory_mb=1024
        )
        self.allowed_operations = [
            "data_analysis", "visualization", "calculation"
        ]

    def execute_data_analysis(self, code: str, data_path: str):
        """æ‰§è¡Œæ•°æ®åˆ†æä»£ç """
        safe_code = f"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# è¯»å–æ•°æ®
data = pd.read_csv('{data_path}')

# ç”¨æˆ·ä»£ç 
{code}

# ä¿å­˜ç»“æœ
plt.savefig('analysis_result.png')
plt.close()
"""
        return self.interpreter.run(safe_code)

    def execute_calculation(self, formula: str, variables: dict):
        """æ‰§è¡Œæ•°å­¦è®¡ç®—"""
        safe_code = f"""
import math
import numpy as np

# è®¾ç½®å˜é‡
{chr(10).join([f"{k} = {v}" for k, v in variables.items()])}

# æ‰§è¡Œè®¡ç®—
result = {formula}
print(f"è®¡ç®—ç»“æœ: {{result}}")
"""
        return self.interpreter.run(safe_code)

# ä½¿ç”¨å®‰å…¨æ‰§è¡Œå™¨
safe_executor = SafeCodeExecutor()

calculation_agent = Agent(
    role="è®¡ç®—ä¸“å®¶",
    goal="æ‰§è¡Œå®‰å…¨çš„æ•°å­¦è®¡ç®—å’Œæ•°æ®åˆ†æ",
    backstory="ä¸“ä¸šçš„è®¡ç®—å’Œåˆ†æä¸“å®¶...",
    tools=[safe_executor.interpreter],
    verbose=True
)
```
### ğŸ¨ å†…å®¹åˆ›ä½œå·¥å…·è¯¦è§£

#### 1. DallETool - AIå›¾åƒç”Ÿæˆ

```python
# ğŸ¨ DallETool - DALL-Eå›¾åƒç”Ÿæˆå·¥å…·
from crewai_tools import DallETool

# åŸºç¡€å›¾åƒç”Ÿæˆ
dalle_tool = DallETool()

# é«˜çº§é…ç½®
advanced_dalle = DallETool(
    model="dall-e-3",        # æ¨¡å‹ç‰ˆæœ¬
    size="1024x1024",        # å›¾åƒå°ºå¯¸
    quality="hd",            # å›¾åƒè´¨é‡
    style="vivid"            # å›¾åƒé£æ ¼
)

# ä½¿ç”¨ç¤ºä¾‹
creative_agent = Agent(
    role="åˆ›æ„è®¾è®¡å¸ˆ",
    goal="ç”Ÿæˆé«˜è´¨é‡çš„åˆ›æ„å›¾åƒ",
    backstory="å¯Œæœ‰åˆ›æ„çš„è§†è§‰è®¾è®¡ä¸“å®¶...",
    tools=[advanced_dalle],
    verbose=True
)
```

#### 2. VisionTool - å›¾åƒåˆ†æå·¥å…·

```python
# ğŸ‘ï¸ VisionTool - å›¾åƒç†è§£å’Œåˆ†æ
from crewai_tools import VisionTool

# å›¾åƒåˆ†æå·¥å…·
vision_tool = VisionTool()

# é…ç½®åˆ†æé€‰é¡¹
detailed_vision = VisionTool(
    max_tokens=1000,         # æœ€å¤§åˆ†æé•¿åº¦
    detail_level="high",     # åˆ†æè¯¦ç»†ç¨‹åº¦
    include_objects=True,    # åŒ…å«ç‰©ä½“è¯†åˆ«
    include_text=True        # åŒ…å«æ–‡å­—è¯†åˆ«
)

# ä½¿ç”¨ç¤ºä¾‹
image_analyst = Agent(
    role="å›¾åƒåˆ†æå¸ˆ",
    goal="æ·±å…¥åˆ†æå›¾åƒå†…å®¹å¹¶æä¾›è¯¦ç»†æè¿°",
    backstory="ä¸“ä¸šçš„è®¡ç®—æœºè§†è§‰ä¸“å®¶...",
    tools=[detailed_vision],
    verbose=True
)
```

### ğŸ¤ åä½œé€šä¿¡å·¥å…·è¯¦è§£

#### 1. DelegateWorkTool - ä»»åŠ¡å§”æ´¾å·¥å…·

```python
# ğŸ¤ DelegateWorkTool - æ™ºèƒ½ä»»åŠ¡å§”æ´¾
from crewai.tools import DelegateWorkTool

# ä»»åŠ¡å§”æ´¾å·¥å…·ï¼ˆé€šå¸¸ç”±Crewè‡ªåŠ¨é…ç½®ï¼‰
class SmartDelegationAgent(Agent):
    """æ™ºèƒ½å§”æ´¾Agent"""

    def __init__(self, team_agents):
        super().__init__(
            role="é¡¹ç›®åè°ƒå‘˜",
            goal="æ™ºèƒ½åˆ†é…ä»»åŠ¡ç»™æœ€åˆé€‚çš„å›¢é˜Ÿæˆå‘˜",
            backstory="ç»éªŒä¸°å¯Œçš„é¡¹ç›®ç®¡ç†ä¸“å®¶...",
            allow_delegation=True,  # å¯ç”¨å§”æ´¾åŠŸèƒ½
            verbose=True
        )
        self.team_agents = team_agents

    def delegate_task_intelligently(self, task_description, task_complexity):
        """æ™ºèƒ½å§”æ´¾ä»»åŠ¡"""
        # åˆ†æä»»åŠ¡ç±»å‹
        if "æ•°æ®" in task_description or "åˆ†æ" in task_description:
            best_agent = self.find_agent_by_role("æ•°æ®åˆ†æå¸ˆ")
        elif "è®¾è®¡" in task_description or "åˆ›æ„" in task_description:
            best_agent = self.find_agent_by_role("è®¾è®¡å¸ˆ")
        elif "ä»£ç " in task_description or "å¼€å‘" in task_description:
            best_agent = self.find_agent_by_role("å¼€å‘å·¥ç¨‹å¸ˆ")
        else:
            best_agent = self.find_most_available_agent()

        return f"å°†ä»»åŠ¡å§”æ´¾ç»™: {best_agent.role}"

    def find_agent_by_role(self, role):
        """æ ¹æ®è§’è‰²æ‰¾åˆ°Agent"""
        for agent in self.team_agents:
            if role in agent.role:
                return agent
        return self.team_agents[0]  # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª

    def find_most_available_agent(self):
        """æ‰¾åˆ°æœ€ç©ºé—²çš„Agent"""
        # è¿™é‡Œå¯ä»¥å®ç°è´Ÿè½½å‡è¡¡é€»è¾‘
        return self.team_agents[0]
```

#### 2. AskQuestionTool - è¯¢é—®åŒäº‹å·¥å…·

```python
# â“ AskQuestionTool - æ™ºèƒ½è¯¢é—®å·¥å…·
from crewai.tools import AskQuestionTool

class CollaborativeAgent(Agent):
    """åä½œå‹Agent"""

    def __init__(self, name, role, team_agents):
        super().__init__(
            role=role,
            goal=f"ä½œä¸º{role}ï¼Œä¸å›¢é˜Ÿåä½œå®Œæˆä»»åŠ¡",
            backstory=f"ç»éªŒä¸°å¯Œçš„{role}ï¼Œå–„äºå›¢é˜Ÿåä½œ...",
            verbose=True
        )
        self.name = name
        self.team_agents = team_agents

    def ask_expert_opinion(self, question, expert_role):
        """å‘ä¸“å®¶è¯¢é—®æ„è§"""
        expert = self.find_expert(expert_role)
        if expert:
            return f"å‘{expert.role}è¯¢é—®: {question}"
        return "æœªæ‰¾åˆ°ç›¸å…³ä¸“å®¶"

    def find_expert(self, role):
        """æ‰¾åˆ°ç‰¹å®šè§’è‰²çš„ä¸“å®¶"""
        for agent in self.team_agents:
            if role.lower() in agent.role.lower():
                return agent
        return None

    def collaborative_decision(self, decision_topic):
        """åä½œå†³ç­–"""
        opinions = []
        for agent in self.team_agents:
            if agent != self:
                opinion = f"{agent.role}çš„è§‚ç‚¹: åŸºäºæˆ‘çš„ä¸“ä¸šç»éªŒ..."
                opinions.append(opinion)

        return {
            "topic": decision_topic,
            "team_opinions": opinions,
            "consensus": "åŸºäºå›¢é˜Ÿè®¨è®ºçš„å…±è¯†..."
        }
```

---

## 5.2 ç¬¬ä¸‰æ–¹å·¥å…·é›†æˆæ–¹æ³•ğŸŒ

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šæ’ä»¶ç³»ç»Ÿ

ç¬¬ä¸‰æ–¹å·¥å…·é›†æˆå°±åƒæ¸¸æˆçš„æ’ä»¶ç³»ç»Ÿï¼š

- **ğŸ”Œ å®˜æ–¹æ’ä»¶**ï¼šCrewAI Toolsç”Ÿæ€ç³»ç»Ÿ
- **ğŸ› ï¸ ç¤¾åŒºæ’ä»¶**ï¼šLangChain Tools
- **âš™ï¸ è‡ªåˆ¶æ’ä»¶**ï¼šè‡ªå®šä¹‰APIé›†æˆ
- **ğŸ”§ å·¥å…·é“¾**ï¼šå¤šä¸ªæ’ä»¶çš„ç»„åˆä½¿ç”¨

### ğŸ“Š ç¬¬ä¸‰æ–¹å·¥å…·ç”Ÿæ€ç³»ç»Ÿ

```mermaid
graph TD
    A[ç¬¬ä¸‰æ–¹å·¥å…·ç”Ÿæ€] --> B[ğŸ¢ ä¼ä¸šæœåŠ¡å·¥å…·]
    A --> C[ğŸŒ WebæœåŠ¡å·¥å…·]
    A --> D[ğŸ“Š æ•°æ®æœåŠ¡å·¥å…·]
    A --> E[ğŸ¤– AIæœåŠ¡å·¥å…·]
    A --> F[â˜ï¸ äº‘å¹³å°å·¥å…·]

    B --> B1[Slack, Teams, Discord]
    B --> B2[Jira, Asana, Trello]
    B --> B3[Salesforce, HubSpot]

    C --> C1[REST API, GraphQL]
    C --> C2[WebSocket, SSE]
    C --> C3[OAuth, JWTè®¤è¯]

    D --> D1[MySQL, PostgreSQL]
    D --> D2[MongoDB, Redis]
    D --> D3[Elasticsearch, InfluxDB]

    E --> E1[OpenAI, Anthropic]
    E --> E2[Hugging Face, Cohere]
    E --> E3[Google AI, Azure AI]

    F --> F1[AWS, Azure, GCP]
    F --> F2[Docker, Kubernetes]
    F --> F3[Serverless Functions]
```

### ğŸ”Œ LangChainå·¥å…·é›†æˆ

#### 1. é›†æˆLangChainå·¥å…·

```python
# ğŸ”— é›†æˆLangChainå·¥å…·åˆ°CrewAI
from langchain.tools import Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from crewai import Agent

# åˆ›å»ºLangChainå·¥å…·
ddg_search = DuckDuckGoSearchRun()
wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())

# åŒ…è£…ä¸ºCrewAIå…¼å®¹çš„å·¥å…·
def create_langchain_tool_wrapper(langchain_tool, name, description):
    """å°†LangChainå·¥å…·åŒ…è£…ä¸ºCrewAIå·¥å…·"""
    from crewai.tools import BaseTool
    from pydantic import BaseModel, Field
    from typing import Type

    class ToolInput(BaseModel):
        query: str = Field(description="æŸ¥è¯¢å†…å®¹")

    class WrappedTool(BaseTool):
        name: str = name
        description: str = description
        args_schema: Type[BaseModel] = ToolInput

        def _run(self, query: str) -> str:
            return langchain_tool.run(query)

    return WrappedTool()

# åˆ›å»ºåŒ…è£…åçš„å·¥å…·
ddg_tool = create_langchain_tool_wrapper(
    ddg_search,
    "DuckDuckGoæœç´¢",
    "ä½¿ç”¨DuckDuckGoæœç´¢å¼•æ“æœç´¢ä¿¡æ¯"
)

wiki_tool = create_langchain_tool_wrapper(
    wikipedia,
    "ç»´åŸºç™¾ç§‘æŸ¥è¯¢",
    "åœ¨ç»´åŸºç™¾ç§‘ä¸­æŸ¥è¯¢ç›¸å…³ä¿¡æ¯"
)

# åœ¨Agentä¸­ä½¿ç”¨
research_agent = Agent(
    role="ç ”ç©¶ä¸“å®¶",
    goal="ä½¿ç”¨å¤šç§æœç´¢å¼•æ“æ”¶é›†ä¿¡æ¯",
    backstory="ä¸“ä¸šçš„ä¿¡æ¯æ”¶é›†å’ŒéªŒè¯ä¸“å®¶...",
    tools=[ddg_tool, wiki_tool],
    verbose=True
)
```

#### 2. æ•°æ®åº“å·¥å…·é›†æˆ

```python
# ğŸ—„ï¸ æ•°æ®åº“å·¥å…·é›†æˆ
import sqlite3
import psycopg2
from typing import Type
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class DatabaseQueryInput(BaseModel):
    """æ•°æ®åº“æŸ¥è¯¢è¾“å…¥"""
    query: str = Field(description="SQLæŸ¥è¯¢è¯­å¥")
    database: str = Field(description="æ•°æ®åº“åç§°", default="default")

class SQLiteTool(BaseTool):
    """SQLiteæ•°æ®åº“å·¥å…·"""
    name: str = "SQLiteæŸ¥è¯¢å·¥å…·"
    description: str = "æ‰§è¡ŒSQLiteæ•°æ®åº“æŸ¥è¯¢"
    args_schema: Type[BaseModel] = DatabaseQueryInput

    def __init__(self, db_path: str):
        super().__init__()
        self.db_path = db_path

    def _run(self, query: str, database: str = "default") -> str:
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(query)

            if query.strip().upper().startswith('SELECT'):
                results = cursor.fetchall()
                columns = [description[0] for description in cursor.description]

                # æ ¼å¼åŒ–ç»“æœ
                formatted_results = []
                for row in results:
                    row_dict = dict(zip(columns, row))
                    formatted_results.append(row_dict)

                return f"æŸ¥è¯¢ç»“æœ: {formatted_results}"
            else:
                conn.commit()
                return f"æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œå½±å“è¡Œæ•°: {cursor.rowcount}"

        except Exception as e:
            return f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}"
        finally:
            conn.close()

class PostgreSQLTool(BaseTool):
    """PostgreSQLæ•°æ®åº“å·¥å…·"""
    name: str = "PostgreSQLæŸ¥è¯¢å·¥å…·"
    description: str = "æ‰§è¡ŒPostgreSQLæ•°æ®åº“æŸ¥è¯¢"
    args_schema: Type[BaseModel] = DatabaseQueryInput

    def __init__(self, connection_string: str):
        super().__init__()
        self.connection_string = connection_string

    def _run(self, query: str, database: str = "default") -> str:
        try:
            conn = psycopg2.connect(self.connection_string)
            cursor = conn.cursor()
            cursor.execute(query)

            if query.strip().upper().startswith('SELECT'):
                results = cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]

                formatted_results = []
                for row in results:
                    row_dict = dict(zip(columns, row))
                    formatted_results.append(row_dict)

                return f"æŸ¥è¯¢ç»“æœ: {formatted_results}"
            else:
                conn.commit()
                return f"æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œå½±å“è¡Œæ•°: {cursor.rowcount}"

        except Exception as e:
            return f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}"
        finally:
            conn.close()

# ä½¿ç”¨æ•°æ®åº“å·¥å…·
sqlite_tool = SQLiteTool("data/company.db")
postgres_tool = PostgreSQLTool("postgresql://user:password@localhost/dbname")

data_analyst = Agent(
    role="æ•°æ®åˆ†æå¸ˆ",
    goal="ä»æ•°æ®åº“ä¸­æå–å’Œåˆ†ææ•°æ®",
    backstory="ä¸“ä¸šçš„æ•°æ®åº“æŸ¥è¯¢å’Œåˆ†æä¸“å®¶...",
    tools=[sqlite_tool, postgres_tool],
    verbose=True
)
```

#### 3. APIæœåŠ¡é›†æˆ

```python
# ğŸŒ REST APIæœåŠ¡é›†æˆ
import requests
import json
from typing import Type, Optional, Dict, Any
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class APIRequestInput(BaseModel):
    """APIè¯·æ±‚è¾“å…¥"""
    endpoint: str = Field(description="APIç«¯ç‚¹è·¯å¾„")
    method: str = Field(description="HTTPæ–¹æ³•", default="GET")
    params: Optional[Dict[str, Any]] = Field(description="æŸ¥è¯¢å‚æ•°", default=None)
    data: Optional[Dict[str, Any]] = Field(description="è¯·æ±‚æ•°æ®", default=None)

class RESTAPITool(BaseTool):
    """é€šç”¨REST APIå·¥å…·"""
    name: str = "REST APIå·¥å…·"
    description: str = "è°ƒç”¨REST APIæœåŠ¡"
    args_schema: Type[BaseModel] = APIRequestInput

    def __init__(self, base_url: str, headers: Optional[Dict[str, str]] = None):
        super().__init__()
        self.base_url = base_url.rstrip('/')
        self.headers = headers or {}

    def _run(self, endpoint: str, method: str = "GET",
             params: Optional[Dict[str, Any]] = None,
             data: Optional[Dict[str, Any]] = None) -> str:
        try:
            url = f"{self.base_url}/{endpoint.lstrip('/')}"

            response = requests.request(
                method=method.upper(),
                url=url,
                headers=self.headers,
                params=params,
                json=data,
                timeout=30
            )

            response.raise_for_status()

            try:
                result = response.json()
                return json.dumps(result, ensure_ascii=False, indent=2)
            except json.JSONDecodeError:
                return response.text

        except requests.exceptions.RequestException as e:
            return f"APIè¯·æ±‚é”™è¯¯: {str(e)}"

# ç‰¹å®šæœåŠ¡çš„APIå·¥å…·
class WeatherAPITool(BaseTool):
    """å¤©æ°”APIå·¥å…·"""
    name: str = "å¤©æ°”æŸ¥è¯¢å·¥å…·"
    description: str = "æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"
    args_schema: Type[BaseModel] = BaseModel

    def __init__(self, api_key: str):
        super().__init__()
        self.api_key = api_key
        self.base_url = "http://api.openweathermap.org/data/2.5"

    def _run(self, city: str) -> str:
        try:
            url = f"{self.base_url}/weather"
            params = {
                "q": city,
                "appid": self.api_key,
                "units": "metric",
                "lang": "zh_cn"
            }

            response = requests.get(url, params=params, timeout=10)
            response.raise_for_status()

            data = response.json()

            weather_info = {
                "åŸå¸‚": data["name"],
                "æ¸©åº¦": f"{data['main']['temp']}Â°C",
                "ä½“æ„Ÿæ¸©åº¦": f"{data['main']['feels_like']}Â°C",
                "æ¹¿åº¦": f"{data['main']['humidity']}%",
                "å¤©æ°”": data["weather"][0]["description"],
                "é£é€Ÿ": f"{data['wind']['speed']} m/s"
            }

            return json.dumps(weather_info, ensure_ascii=False, indent=2)

        except Exception as e:
            return f"å¤©æ°”æŸ¥è¯¢å¤±è´¥: {str(e)}"

# ä½¿ç”¨APIå·¥å…·
weather_tool = WeatherAPITool(api_key="your_openweather_api_key")
generic_api_tool = RESTAPITool(
    base_url="https://api.example.com",
    headers={"Authorization": "Bearer your_token"}
)

api_agent = Agent(
    role="APIé›†æˆä¸“å®¶",
    goal="è°ƒç”¨å„ç§å¤–éƒ¨APIæœåŠ¡è·å–æ•°æ®",
    backstory="ä¸“ä¸šçš„APIé›†æˆå’Œæ•°æ®è·å–ä¸“å®¶...",
    tools=[weather_tool, generic_api_tool],
    verbose=True
)
```

---

## 5.3 è‡ªå®šä¹‰å·¥å…·å¼€å‘å®æˆ˜ğŸ”§

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šè£…å¤‡é”»é€ ç³»ç»Ÿ

è‡ªå®šä¹‰å·¥å…·å¼€å‘å°±åƒæ¸¸æˆä¸­çš„è£…å¤‡é”»é€ ï¼š

- **âš’ï¸ åŸºç¡€é”»é€ **ï¼šç»§æ‰¿BaseToolåˆ›å»ºç®€å•å·¥å…·
- **ğŸ”¥ é«˜çº§é”»é€ **ï¼šå¤æ‚é€»è¾‘å’ŒçŠ¶æ€ç®¡ç†
- **ğŸ’ ä¼ è¯´é”»é€ **ï¼šé›†æˆå¤šç§æŠ€æœ¯çš„å¤åˆå·¥å…·
- **ğŸŒŸ ç¥å™¨é”»é€ **ï¼šå…·æœ‰å­¦ä¹ èƒ½åŠ›çš„æ™ºèƒ½å·¥å…·

### ğŸ“Š è‡ªå®šä¹‰å·¥å…·å¼€å‘æµç¨‹

```mermaid
graph TD
    A[éœ€æ±‚åˆ†æ] --> B[å·¥å…·è®¾è®¡]
    B --> C[åŸºç¡€å®ç°]
    C --> D[åŠŸèƒ½æµ‹è¯•]
    D --> E[æ€§èƒ½ä¼˜åŒ–]
    E --> F[å®‰å…¨åŠ å›º]
    F --> G[æ–‡æ¡£ç¼–å†™]
    G --> H[éƒ¨ç½²å‘å¸ƒ]

    B --> B1[å®šä¹‰è¾“å…¥è¾“å‡º]
    B --> B2[è®¾è®¡é”™è¯¯å¤„ç†]
    B --> B3[è§„åˆ’æ‰©å±•æ€§]

    C --> C1[ç»§æ‰¿BaseTool]
    C --> C2[å®ç°_runæ–¹æ³•]
    C --> C3[å®šä¹‰å‚æ•°æ¨¡å‹]

    D --> D1[å•å…ƒæµ‹è¯•]
    D --> D2[é›†æˆæµ‹è¯•]
    D --> D3[è¾¹ç•Œæµ‹è¯•]

    E --> E1[ç¼“å­˜æœºåˆ¶]
    E --> E2[å¼‚æ­¥å¤„ç†]
    E --> E3[èµ„æºç®¡ç†]
```

### ğŸ› ï¸ åŸºç¡€å·¥å…·å¼€å‘

#### 1. ç®€å•è®¡ç®—å·¥å…·

```python
# ğŸ§® åŸºç¡€è®¡ç®—å·¥å…·å¼€å‘
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Type
import math

class CalculatorInput(BaseModel):
    """è®¡ç®—å™¨è¾“å…¥æ¨¡å‹"""
    expression: str = Field(description="æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ï¼š2+3*4")
    precision: int = Field(description="å°æ•°ç‚¹ç²¾åº¦", default=2)

class AdvancedCalculatorTool(BaseTool):
    """é«˜çº§è®¡ç®—å™¨å·¥å…·"""
    name: str = "é«˜çº§è®¡ç®—å™¨"
    description: str = "æ‰§è¡Œå¤æ‚æ•°å­¦è®¡ç®—ï¼Œæ”¯æŒåŸºç¡€è¿ç®—ã€ä¸‰è§’å‡½æ•°ã€å¯¹æ•°ç­‰"
    args_schema: Type[BaseModel] = CalculatorInput

    def _run(self, expression: str, precision: int = 2) -> str:
        """æ‰§è¡Œæ•°å­¦è®¡ç®—"""
        try:
            # å®‰å…¨çš„æ•°å­¦å‡½æ•°æ˜ å°„
            safe_dict = {
                "__builtins__": {},
                "abs": abs, "round": round, "min": min, "max": max,
                "sum": sum, "pow": pow,
                # æ•°å­¦å‡½æ•°
                "sin": math.sin, "cos": math.cos, "tan": math.tan,
                "asin": math.asin, "acos": math.acos, "atan": math.atan,
                "sinh": math.sinh, "cosh": math.cosh, "tanh": math.tanh,
                "log": math.log, "log10": math.log10, "log2": math.log2,
                "exp": math.exp, "sqrt": math.sqrt,
                "pi": math.pi, "e": math.e,
                "degrees": math.degrees, "radians": math.radians,
                "factorial": math.factorial,
                "gcd": math.gcd, "lcm": math.lcm if hasattr(math, 'lcm') else lambda a, b: abs(a*b) // math.gcd(a, b)
            }

            # é¢„å¤„ç†è¡¨è¾¾å¼
            expression = expression.replace("^", "**")  # æ”¯æŒ^ä½œä¸ºå¹‚è¿ç®—

            # æ‰§è¡Œè®¡ç®—
            result = eval(expression, safe_dict)

            # æ ¼å¼åŒ–ç»“æœ
            if isinstance(result, float):
                result = round(result, precision)

            return f"è®¡ç®—ç»“æœ: {result}"

        except ZeroDivisionError:
            return "é”™è¯¯: é™¤é›¶é”™è¯¯"
        except ValueError as e:
            return f"é”™è¯¯: æ•°å€¼é”™è¯¯ - {str(e)}"
        except SyntaxError:
            return "é”™è¯¯: è¡¨è¾¾å¼è¯­æ³•é”™è¯¯"
        except Exception as e:
            return f"é”™è¯¯: è®¡ç®—å¤±è´¥ - {str(e)}"

# ä½¿ç”¨ç¤ºä¾‹
calculator_tool = AdvancedCalculatorTool()

math_agent = Agent(
    role="æ•°å­¦è®¡ç®—ä¸“å®¶",
    goal="æ‰§è¡Œå„ç§æ•°å­¦è®¡ç®—ä»»åŠ¡",
    backstory="ç²¾é€šæ•°å­¦è®¡ç®—çš„ä¸“ä¸šåŠ©æ‰‹...",
    tools=[calculator_tool],
    verbose=True
)
```

#### 2. æ–‡æœ¬å¤„ç†å·¥å…·

```python
# ğŸ“ æ–‡æœ¬å¤„ç†å·¥å…·å¼€å‘
import re
import jieba
from collections import Counter
from typing import Type, List, Dict
import json

class TextProcessorInput(BaseModel):
    """æ–‡æœ¬å¤„ç†è¾“å…¥æ¨¡å‹"""
    text: str = Field(description="è¦å¤„ç†çš„æ–‡æœ¬")
    operation: str = Field(description="å¤„ç†æ“ä½œï¼šword_count, sentiment, keywords, summary")
    language: str = Field(description="æ–‡æœ¬è¯­è¨€", default="zh")

class TextProcessorTool(BaseTool):
    """æ™ºèƒ½æ–‡æœ¬å¤„ç†å·¥å…·"""
    name: str = "æ–‡æœ¬å¤„ç†å·¥å…·"
    description: str = "æä¾›æ–‡æœ¬åˆ†æã€å…³é”®è¯æå–ã€æƒ…æ„Ÿåˆ†æç­‰åŠŸèƒ½"
    args_schema: Type[BaseModel] = TextProcessorInput

    def __init__(self):
        super().__init__()
        # åˆå§‹åŒ–ä¸­æ–‡åˆ†è¯
        jieba.initialize()

        # åœç”¨è¯åˆ—è¡¨
        self.stop_words = {
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº',
            'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»',
            'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'
        }

    def _run(self, text: str, operation: str, language: str = "zh") -> str:
        """æ‰§è¡Œæ–‡æœ¬å¤„ç†æ“ä½œ"""
        try:
            if operation == "word_count":
                return self._word_count(text, language)
            elif operation == "sentiment":
                return self._sentiment_analysis(text)
            elif operation == "keywords":
                return self._extract_keywords(text, language)
            elif operation == "summary":
                return self._text_summary(text)
            else:
                return f"ä¸æ”¯æŒçš„æ“ä½œ: {operation}"

        except Exception as e:
            return f"æ–‡æœ¬å¤„ç†é”™è¯¯: {str(e)}"

    def _word_count(self, text: str, language: str) -> str:
        """è¯é¢‘ç»Ÿè®¡"""
        if language == "zh":
            words = jieba.lcut(text)
            words = [w for w in words if w not in self.stop_words and len(w) > 1]
        else:
            words = re.findall(r'\b\w+\b', text.lower())

        word_count = Counter(words)
        total_words = len(words)
        unique_words = len(word_count)

        top_words = word_count.most_common(10)

        result = {
            "æ€»è¯æ•°": total_words,
            "å”¯ä¸€è¯æ•°": unique_words,
            "è¯æ±‡ä¸°å¯Œåº¦": round(unique_words / total_words, 3) if total_words > 0 else 0,
            "é«˜é¢‘è¯æ±‡": dict(top_words)
        }

        return f"è¯é¢‘ç»Ÿè®¡ç»“æœ:\n{json.dumps(result, ensure_ascii=False, indent=2)}"

    def _sentiment_analysis(self, text: str) -> str:
        """ç®€å•æƒ…æ„Ÿåˆ†æ"""
        positive_words = ['å¥½', 'æ£’', 'ä¼˜ç§€', 'å–œæ¬¢', 'æ»¡æ„', 'å¼€å¿ƒ', 'é«˜å…´', 'èµ']
        negative_words = ['å', 'å·®', 'ç³Ÿç³•', 'è®¨åŒ', 'ä¸æ»¡', 'éš¾è¿‡', 'ç”Ÿæ°”', 'å¤±æœ›']

        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        if positive_count > negative_count:
            sentiment = "ç§¯æ"
            confidence = positive_count / (positive_count + negative_count)
        elif negative_count > positive_count:
            sentiment = "æ¶ˆæ"
            confidence = negative_count / (positive_count + negative_count)
        else:
            sentiment = "ä¸­æ€§"
            confidence = 0.5

        return f"æƒ…æ„Ÿåˆ†æç»“æœ: {sentiment} (ç½®ä¿¡åº¦: {confidence:.2f})"

    def _extract_keywords(self, text: str, language: str) -> str:
        """å…³é”®è¯æå–"""
        if language == "zh":
            words = jieba.lcut(text)
            words = [w for w in words if w not in self.stop_words and len(w) > 1]
        else:
            words = re.findall(r'\b\w+\b', text.lower())

        word_freq = Counter(words)
        keywords = word_freq.most_common(5)

        return f"å…³é”®è¯: {', '.join([word for word, freq in keywords])}"

    def _text_summary(self, text: str) -> str:
        """æ–‡æœ¬æ‘˜è¦ï¼ˆç®€å•å®ç°ï¼‰"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        if len(sentences) <= 2:
            return f"æ‘˜è¦: {text}"

        # ç®€å•é€‰æ‹©å‰ä¸¤å¥ä½œä¸ºæ‘˜è¦
        summary = 'ã€‚'.join(sentences[:2]) + 'ã€‚'
        return f"æ‘˜è¦: {summary}"

# ä½¿ç”¨ç¤ºä¾‹
text_processor = TextProcessorTool()

text_agent = Agent(
    role="æ–‡æœ¬åˆ†æä¸“å®¶",
    goal="åˆ†æå’Œå¤„ç†å„ç§æ–‡æœ¬å†…å®¹",
    backstory="ä¸“ä¸šçš„è‡ªç„¶è¯­è¨€å¤„ç†ä¸“å®¶...",
    tools=[text_processor],
    verbose=True
)
```

### ğŸ”¥ é«˜çº§å·¥å…·å¼€å‘

#### 1. å¸¦çŠ¶æ€ç®¡ç†çš„å·¥å…·

```python
# ğŸ”„ å¸¦çŠ¶æ€ç®¡ç†çš„é«˜çº§å·¥å…·
import json
import os
from datetime import datetime
from typing import Type, Dict, Any, Optional

class StatefulToolInput(BaseModel):
    """çŠ¶æ€å·¥å…·è¾“å…¥æ¨¡å‹"""
    action: str = Field(description="æ“ä½œç±»å‹ï¼šsave, load, update, delete, list")
    key: str = Field(description="æ•°æ®é”®å", default="")
    value: Any = Field(description="æ•°æ®å€¼", default=None)
    namespace: str = Field(description="å‘½åç©ºé—´", default="default")

class StatefulDataTool(BaseTool):
    """å¸¦çŠ¶æ€ç®¡ç†çš„æ•°æ®å·¥å…·"""
    name: str = "çŠ¶æ€æ•°æ®å·¥å…·"
    description: str = "ç®¡ç†æŒä¹…åŒ–æ•°æ®çŠ¶æ€ï¼Œæ”¯æŒä¿å­˜ã€åŠ è½½ã€æ›´æ–°æ•°æ®"
    args_schema: Type[BaseModel] = StatefulToolInput

    def __init__(self, storage_path: str = "tool_data"):
        super().__init__()
        self.storage_path = storage_path
        os.makedirs(storage_path, exist_ok=True)
        self._memory_cache = {}

    def _get_file_path(self, namespace: str) -> str:
        """è·å–å­˜å‚¨æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.storage_path, f"{namespace}.json")

    def _load_namespace(self, namespace: str) -> Dict[str, Any]:
        """åŠ è½½å‘½åç©ºé—´æ•°æ®"""
        if namespace in self._memory_cache:
            return self._memory_cache[namespace]

        file_path = self._get_file_path(namespace)
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self._memory_cache[namespace] = data
                return data
            except Exception:
                pass

        self._memory_cache[namespace] = {}
        return {}

    def _save_namespace(self, namespace: str, data: Dict[str, Any]) -> bool:
        """ä¿å­˜å‘½åç©ºé—´æ•°æ®"""
        try:
            file_path = self._get_file_path(namespace)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            self._memory_cache[namespace] = data
            return True
        except Exception:
            return False

    def _run(self, action: str, key: str = "", value: Any = None, namespace: str = "default") -> str:
        """æ‰§è¡ŒçŠ¶æ€æ“ä½œ"""
        try:
            data = self._load_namespace(namespace)

            if action == "save":
                if not key:
                    return "é”™è¯¯: ä¿å­˜æ“ä½œéœ€è¦æŒ‡å®škey"
                data[key] = {
                    "value": value,
                    "timestamp": datetime.now().isoformat(),
                    "type": type(value).__name__
                }
                if self._save_namespace(namespace, data):
                    return f"æˆåŠŸä¿å­˜: {key} = {value}"
                else:
                    return "ä¿å­˜å¤±è´¥"

            elif action == "load":
                if not key:
                    return "é”™è¯¯: åŠ è½½æ“ä½œéœ€è¦æŒ‡å®škey"
                if key in data:
                    item = data[key]
                    return f"åŠ è½½æˆåŠŸ: {key} = {item['value']} (ä¿å­˜æ—¶é—´: {item['timestamp']})"
                else:
                    return f"æœªæ‰¾åˆ°æ•°æ®: {key}"

            elif action == "update":
                if not key:
                    return "é”™è¯¯: æ›´æ–°æ“ä½œéœ€è¦æŒ‡å®škey"
                if key in data:
                    data[key]["value"] = value
                    data[key]["timestamp"] = datetime.now().isoformat()
                    if self._save_namespace(namespace, data):
                        return f"æˆåŠŸæ›´æ–°: {key} = {value}"
                    else:
                        return "æ›´æ–°å¤±è´¥"
                else:
                    return f"æœªæ‰¾åˆ°æ•°æ®: {key}"

            elif action == "delete":
                if not key:
                    return "é”™è¯¯: åˆ é™¤æ“ä½œéœ€è¦æŒ‡å®škey"
                if key in data:
                    del data[key]
                    if self._save_namespace(namespace, data):
                        return f"æˆåŠŸåˆ é™¤: {key}"
                    else:
                        return "åˆ é™¤å¤±è´¥"
                else:
                    return f"æœªæ‰¾åˆ°æ•°æ®: {key}"

            elif action == "list":
                if not data:
                    return f"å‘½åç©ºé—´ '{namespace}' ä¸­æ²¡æœ‰æ•°æ®"

                result = f"å‘½åç©ºé—´ '{namespace}' ä¸­çš„æ•°æ®:\n"
                for k, v in data.items():
                    result += f"- {k}: {v['value']} ({v['type']}, {v['timestamp']})\n"
                return result

            else:
                return f"ä¸æ”¯æŒçš„æ“ä½œ: {action}"

        except Exception as e:
            return f"æ“ä½œå¤±è´¥: {str(e)}"

# ä½¿ç”¨ç¤ºä¾‹
stateful_tool = StatefulDataTool()

memory_agent = Agent(
    role="æ•°æ®ç®¡ç†ä¸“å®¶",
    goal="ç®¡ç†å’Œç»´æŠ¤æŒä¹…åŒ–æ•°æ®çŠ¶æ€",
    backstory="ä¸“ä¸šçš„æ•°æ®ç®¡ç†å’ŒçŠ¶æ€ç»´æŠ¤ä¸“å®¶...",
    tools=[stateful_tool],
    verbose=True
)
```

#### 2. å¼‚æ­¥å¤„ç†å·¥å…·

```python
# âš¡ å¼‚æ­¥å¤„ç†å·¥å…·
import asyncio
import aiohttp
import time
from concurrent.futures import ThreadPoolExecutor
from typing import Type, List, Dict, Any

class AsyncTaskInput(BaseModel):
    """å¼‚æ­¥ä»»åŠ¡è¾“å…¥æ¨¡å‹"""
    task_type: str = Field(description="ä»»åŠ¡ç±»å‹ï¼šbatch_request, parallel_process, background_task")
    urls: List[str] = Field(description="URLåˆ—è¡¨", default=[])
    data: List[Dict[str, Any]] = Field(description="æ•°æ®åˆ—è¡¨", default=[])
    timeout: int = Field(description="è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰", default=30)

class AsyncProcessingTool(BaseTool):
    """å¼‚æ­¥å¤„ç†å·¥å…·"""
    name: str = "å¼‚æ­¥å¤„ç†å·¥å…·"
    description: str = "æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡ï¼Œæ”¯æŒæ‰¹é‡è¯·æ±‚ã€å¹¶è¡Œå¤„ç†ç­‰"
    args_schema: Type[BaseModel] = AsyncTaskInput

    def __init__(self, max_workers: int = 10):
        super().__init__()
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)

    async def _batch_http_requests(self, urls: List[str], timeout: int) -> List[Dict[str, Any]]:
        """æ‰¹é‡HTTPè¯·æ±‚"""
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
            tasks = []
            for url in urls:
                tasks.append(self._single_request(session, url))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            formatted_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    formatted_results.append({
                        "url": urls[i],
                        "status": "error",
                        "error": str(result)
                    })
                else:
                    formatted_results.append(result)

            return formatted_results

    async def _single_request(self, session: aiohttp.ClientSession, url: str) -> Dict[str, Any]:
        """å•ä¸ªHTTPè¯·æ±‚"""
        try:
            async with session.get(url) as response:
                content = await response.text()
                return {
                    "url": url,
                    "status": "success",
                    "status_code": response.status,
                    "content_length": len(content),
                    "headers": dict(response.headers)
                }
        except Exception as e:
            return {
                "url": url,
                "status": "error",
                "error": str(e)
            }

    def _parallel_data_processing(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¹¶è¡Œæ•°æ®å¤„ç†"""
        def process_item(item):
            # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
            time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            processed_item = item.copy()
            processed_item['processed'] = True
            processed_item['process_time'] = time.time()
            return processed_item

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        futures = [self.executor.submit(process_item, item) for item in data]
        results = [future.result() for future in futures]

        return results

    def _run(self, task_type: str, urls: List[str] = None, data: List[Dict[str, Any]] = None, timeout: int = 30) -> str:
        """æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡"""
        try:
            start_time = time.time()

            if task_type == "batch_request":
                if not urls:
                    return "é”™è¯¯: æ‰¹é‡è¯·æ±‚éœ€è¦æä¾›URLåˆ—è¡¨"

                # è¿è¡Œå¼‚æ­¥æ‰¹é‡è¯·æ±‚
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    results = loop.run_until_complete(self._batch_http_requests(urls, timeout))
                finally:
                    loop.close()

                success_count = sum(1 for r in results if r.get('status') == 'success')
                error_count = len(results) - success_count

                return f"æ‰¹é‡è¯·æ±‚å®Œæˆ:\næˆåŠŸ: {success_count}\nå¤±è´¥: {error_count}\nè€—æ—¶: {time.time() - start_time:.2f}ç§’"

            elif task_type == "parallel_process":
                if not data:
                    return "é”™è¯¯: å¹¶è¡Œå¤„ç†éœ€è¦æä¾›æ•°æ®åˆ—è¡¨"

                results = self._parallel_data_processing(data)

                return f"å¹¶è¡Œå¤„ç†å®Œæˆ:\nå¤„ç†é¡¹ç›®æ•°: {len(results)}\nè€—æ—¶: {time.time() - start_time:.2f}ç§’"

            elif task_type == "background_task":
                # æäº¤åå°ä»»åŠ¡
                future = self.executor.submit(self._background_task, data or [])
                return f"åå°ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {id(future)}"

            else:
                return f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}"

        except Exception as e:
            return f"å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}"

    def _background_task(self, data: List[Dict[str, Any]]) -> str:
        """åå°ä»»åŠ¡å¤„ç†"""
        time.sleep(5)  # æ¨¡æ‹Ÿé•¿æ—¶é—´å¤„ç†
        return f"åå°ä»»åŠ¡å®Œæˆï¼Œå¤„ç†äº† {len(data)} ä¸ªé¡¹ç›®"

# ä½¿ç”¨ç¤ºä¾‹
async_tool = AsyncProcessingTool(max_workers=5)

async_agent = Agent(
    role="å¼‚æ­¥å¤„ç†ä¸“å®¶",
    goal="æ‰§è¡Œé«˜æ•ˆçš„å¼‚æ­¥å’Œå¹¶è¡Œä»»åŠ¡",
    backstory="ä¸“ä¸šçš„å¼‚æ­¥ç¼–ç¨‹å’Œæ€§èƒ½ä¼˜åŒ–ä¸“å®¶...",
    tools=[async_tool],
    verbose=True
)
```

---

## 5.4 å·¥å…·é“¾è®¾è®¡å’Œä¼˜åŒ–ğŸ¯

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šæŠ€èƒ½ç»„åˆç³»ç»Ÿ

å·¥å…·é“¾è®¾è®¡å°±åƒæ¸¸æˆä¸­çš„æŠ€èƒ½ç»„åˆï¼š

- **âš¡ è¿å‡»æŠ€èƒ½**ï¼šå·¥å…·çš„é¡ºåºè°ƒç”¨
- **ğŸ”„ å¾ªç¯æŠ€èƒ½**ï¼šå·¥å…·çš„å¾ªç¯ä½¿ç”¨
- **ğŸŒŸ ç»ˆææŠ€èƒ½**ï¼šå¤šå·¥å…·ååŒä½œæˆ˜
- **ğŸ¯ ç²¾å‡†æŠ€èƒ½**ï¼šé’ˆå¯¹ç‰¹å®šåœºæ™¯çš„å·¥å…·ç»„åˆ

### ğŸ“Š å·¥å…·é“¾è®¾è®¡åŸåˆ™

```mermaid
graph TD
    A[å·¥å…·é“¾è®¾è®¡åŸåˆ™] --> B[ğŸ¯ å•ä¸€èŒè´£]
    A --> C[ğŸ”— æ¾è€¦åˆ]
    A --> D[âš¡ é«˜æ€§èƒ½]
    A --> E[ğŸ›¡ï¸ å®¹é”™æ€§]
    A --> F[ğŸ“ˆ å¯æ‰©å±•]

    B --> B1[æ¯ä¸ªå·¥å…·ä¸“æ³¨ä¸€ä¸ªåŠŸèƒ½]
    B --> B2[é¿å…åŠŸèƒ½é‡å ]
    B --> B3[æ¸…æ™°çš„è¾“å…¥è¾“å‡º]

    C --> C1[å·¥å…·é—´ç‹¬ç«‹è¿è¡Œ]
    C --> C2[æ ‡å‡†åŒ–æ¥å£]
    C --> C3[æœ€å°ä¾èµ–]

    D --> D1[ç¼“å­˜æœºåˆ¶]
    D --> D2[å¼‚æ­¥å¤„ç†]
    D --> D3[èµ„æºå¤ç”¨]

    E --> E1[ä¼˜é›…é™çº§]
    E --> E2[é”™è¯¯æ¢å¤]
    E --> E3[è¶…æ—¶å¤„ç†]

    F --> F1[æ’ä»¶åŒ–æ¶æ„]
    F --> F2[é…ç½®é©±åŠ¨]
    F --> F3[ç‰ˆæœ¬å…¼å®¹]
```

### ğŸ”— å·¥å…·é“¾ç»„åˆæ¨¡å¼

#### 1. ç®¡é“æ¨¡å¼ï¼ˆPipeline Patternï¼‰

```python
# ğŸ”„ ç®¡é“æ¨¡å¼å·¥å…·é“¾
from typing import List, Any, Callable
from crewai.tools import BaseTool
from pydantic import BaseModel, Field

class PipelineInput(BaseModel):
    """ç®¡é“è¾“å…¥æ¨¡å‹"""
    data: Any = Field(description="è¾“å…¥æ•°æ®")
    pipeline_name: str = Field(description="ç®¡é“åç§°", default="default")

class ToolPipeline(BaseTool):
    """å·¥å…·ç®¡é“"""
    name: str = "å·¥å…·ç®¡é“"
    description: str = "æŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªå·¥å…·ï¼Œå‰ä¸€ä¸ªå·¥å…·çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªå·¥å…·çš„è¾“å…¥"
    args_schema: Type[BaseModel] = PipelineInput

    def __init__(self, tools: List[BaseTool], name: str = "default"):
        super().__init__()
        self.tools = tools
        self.pipeline_name = name
        self.execution_log = []

    def _run(self, data: Any, pipeline_name: str = "default") -> str:
        """æ‰§è¡Œç®¡é“"""
        try:
            current_data = data
            self.execution_log = []

            for i, tool in enumerate(self.tools):
                step_start = time.time()

                try:
                    # æ‰§è¡Œå·¥å…·
                    if hasattr(tool, '_run'):
                        result = tool._run(current_data)
                    else:
                        result = tool.run(current_data)

                    # è®°å½•æ‰§è¡Œæ—¥å¿—
                    step_log = {
                        "step": i + 1,
                        "tool": tool.name,
                        "input": str(current_data)[:100],  # é™åˆ¶æ—¥å¿—é•¿åº¦
                        "output": str(result)[:100],
                        "duration": time.time() - step_start,
                        "status": "success"
                    }
                    self.execution_log.append(step_log)

                    # æ›´æ–°æ•°æ®
                    current_data = result

                except Exception as e:
                    step_log = {
                        "step": i + 1,
                        "tool": tool.name,
                        "input": str(current_data)[:100],
                        "error": str(e),
                        "duration": time.time() - step_start,
                        "status": "error"
                    }
                    self.execution_log.append(step_log)

                    # é”™è¯¯å¤„ç†ï¼šå¯ä»¥é€‰æ‹©ä¸­æ–­æˆ–ç»§ç»­
                    return f"ç®¡é“æ‰§è¡Œå¤±è´¥åœ¨æ­¥éª¤ {i+1}: {str(e)}"

            # è¿”å›æœ€ç»ˆç»“æœå’Œæ‰§è¡Œæ—¥å¿—
            return f"ç®¡é“æ‰§è¡Œå®Œæˆ:\næœ€ç»ˆç»“æœ: {current_data}\næ‰§è¡Œæ—¥å¿—: {json.dumps(self.execution_log, ensure_ascii=False, indent=2)}"

        except Exception as e:
            return f"ç®¡é“æ‰§è¡Œé”™è¯¯: {str(e)}"

# åˆ›å»ºå…·ä½“çš„ç®¡é“å·¥å…·
class DataProcessingPipeline:
    """æ•°æ®å¤„ç†ç®¡é“"""

    def __init__(self):
        # åˆ›å»ºç®¡é“ä¸­çš„å·¥å…·
        self.text_processor = TextProcessorTool()
        self.calculator = AdvancedCalculatorTool()

        # åˆ›å»ºç®¡é“
        self.pipeline = ToolPipeline([
            self.text_processor,
            self.calculator
        ], name="æ•°æ®å¤„ç†ç®¡é“")

    def create_content_analysis_pipeline(self) -> ToolPipeline:
        """åˆ›å»ºå†…å®¹åˆ†æç®¡é“"""
        tools = [
            TextProcessorTool(),  # æ–‡æœ¬å¤„ç†
            # å¯ä»¥æ·»åŠ æ›´å¤šå·¥å…·
        ]
        return ToolPipeline(tools, name="å†…å®¹åˆ†æç®¡é“")

# ä½¿ç”¨ç¤ºä¾‹
data_pipeline = DataProcessingPipeline()

pipeline_agent = Agent(
    role="ç®¡é“å¤„ç†ä¸“å®¶",
    goal="ä½¿ç”¨å·¥å…·ç®¡é“é«˜æ•ˆå¤„ç†å¤æ‚ä»»åŠ¡",
    backstory="ä¸“ä¸šçš„æµç¨‹è®¾è®¡å’Œè‡ªåŠ¨åŒ–ä¸“å®¶...",
    tools=[data_pipeline.pipeline],
    verbose=True
)
```

#### 2. åˆ†æ”¯æ¨¡å¼ï¼ˆBranch Patternï¼‰

```python
# ğŸŒ³ åˆ†æ”¯æ¨¡å¼å·¥å…·é“¾
class BranchInput(BaseModel):
    """åˆ†æ”¯è¾“å…¥æ¨¡å‹"""
    data: Any = Field(description="è¾“å…¥æ•°æ®")
    condition: str = Field(description="åˆ†æ”¯æ¡ä»¶")
    branch_type: str = Field(description="åˆ†æ”¯ç±»å‹", default="conditional")

class ConditionalToolBranch(BaseTool):
    """æ¡ä»¶åˆ†æ”¯å·¥å…·"""
    name: str = "æ¡ä»¶åˆ†æ”¯å·¥å…·"
    description: str = "æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„å·¥å…·æ‰§è¡Œè·¯å¾„"
    args_schema: Type[BaseModel] = BranchInput

    def __init__(self, branches: Dict[str, List[BaseTool]]):
        super().__init__()
        self.branches = branches
        self.default_branch = "default"

    def _run(self, data: Any, condition: str, branch_type: str = "conditional") -> str:
        """æ‰§è¡Œåˆ†æ”¯é€»è¾‘"""
        try:
            # æ ¹æ®æ¡ä»¶é€‰æ‹©åˆ†æ”¯
            selected_branch = self._evaluate_condition(condition, data)

            if selected_branch not in self.branches:
                selected_branch = self.default_branch

            if selected_branch not in self.branches:
                return f"é”™è¯¯: æœªæ‰¾åˆ°åˆ†æ”¯ '{selected_branch}'"

            # æ‰§è¡Œé€‰ä¸­åˆ†æ”¯çš„å·¥å…·
            tools = self.branches[selected_branch]
            results = []

            for tool in tools:
                try:
                    if hasattr(tool, '_run'):
                        result = tool._run(data)
                    else:
                        result = tool.run(data)
                    results.append(f"{tool.name}: {result}")
                except Exception as e:
                    results.append(f"{tool.name}: é”™è¯¯ - {str(e)}")

            return f"åˆ†æ”¯ '{selected_branch}' æ‰§è¡Œç»“æœ:\n" + "\n".join(results)

        except Exception as e:
            return f"åˆ†æ”¯æ‰§è¡Œé”™è¯¯: {str(e)}"

    def _evaluate_condition(self, condition: str, data: Any) -> str:
        """è¯„ä¼°æ¡ä»¶"""
        # ç®€å•çš„æ¡ä»¶è¯„ä¼°é€»è¾‘
        if "æ–‡æœ¬" in str(data) or "text" in condition.lower():
            return "text_processing"
        elif "æ•°å­—" in str(data) or "number" in condition.lower():
            return "number_processing"
        elif "æ•°æ®" in str(data) or "data" in condition.lower():
            return "data_processing"
        else:
            return "default"

# åˆ›å»ºåˆ†æ”¯å·¥å…·
text_tools = [TextProcessorTool()]
number_tools = [AdvancedCalculatorTool()]
data_tools = [StatefulDataTool()]

branch_tool = ConditionalToolBranch({
    "text_processing": text_tools,
    "number_processing": number_tools,
    "data_processing": data_tools,
    "default": text_tools + number_tools
})

branch_agent = Agent(
    role="æ™ºèƒ½åˆ†æ”¯ä¸“å®¶",
    goal="æ ¹æ®æ•°æ®ç±»å‹æ™ºèƒ½é€‰æ‹©å¤„ç†å·¥å…·",
    backstory="ä¸“ä¸šçš„æ™ºèƒ½å†³ç­–å’Œè·¯å¾„é€‰æ‹©ä¸“å®¶...",
    tools=[branch_tool],
    verbose=True
)
```

---

## 5.5 å·¥å…·å®‰å…¨å’Œæƒé™ç®¡ç†ğŸ›¡ï¸

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šæƒé™ç³»ç»Ÿ

å·¥å…·å®‰å…¨ç®¡ç†å°±åƒæ¸¸æˆä¸­çš„æƒé™ç³»ç»Ÿï¼š

- **ğŸ” è®¿é—®æ§åˆ¶**ï¼šè°å¯ä»¥ä½¿ç”¨ä»€ä¹ˆå·¥å…·
- **ğŸ›¡ï¸ å®‰å…¨æ²™ç®±**ï¼šé™åˆ¶å·¥å…·çš„æ‰§è¡Œç¯å¢ƒ
- **ğŸ“Š å®¡è®¡æ—¥å¿—**ï¼šè®°å½•æ‰€æœ‰å·¥å…·ä½¿ç”¨æƒ…å†µ
- **âš ï¸ é£é™©è¯„ä¼°**ï¼šè¯„ä¼°å·¥å…·æ“ä½œçš„é£é™©ç­‰çº§

### ğŸ“Š å®‰å…¨æ¶æ„è®¾è®¡

```mermaid
graph TD
    A[å·¥å…·å®‰å…¨æ¶æ„] --> B[ğŸ” èº«ä»½è®¤è¯]
    A --> C[ğŸ›¡ï¸ æƒé™æ§åˆ¶]
    A --> D[ğŸ° å®‰å…¨æ²™ç®±]
    A --> E[ğŸ“Š å®¡è®¡ç›‘æ§]
    A --> F[âš ï¸ é£é™©ç®¡ç†]

    B --> B1[ç”¨æˆ·èº«ä»½éªŒè¯]
    B --> B2[Agentèº«ä»½éªŒè¯]
    B --> B3[APIå¯†é’¥ç®¡ç†]

    C --> C1[åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶]
    C --> C2[èµ„æºçº§æƒé™]
    C --> C3[æ“ä½œçº§æƒé™]

    D --> D1[æ‰§è¡Œç¯å¢ƒéš”ç¦»]
    D --> D2[èµ„æºä½¿ç”¨é™åˆ¶]
    D --> D3[ç½‘ç»œè®¿é—®æ§åˆ¶]

    E --> E1[æ“ä½œæ—¥å¿—è®°å½•]
    E --> E2[æ€§èƒ½ç›‘æ§]
    E --> E3[å¼‚å¸¸æ£€æµ‹]

    F --> F1[é£é™©ç­‰çº§è¯„ä¼°]
    F --> F2[è‡ªåŠ¨é£é™©å“åº”]
    F --> F3[å®‰å…¨ç­–ç•¥æ›´æ–°]
```

### ğŸ” æƒé™æ§åˆ¶ç³»ç»Ÿ

#### 1. åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼ˆRBACï¼‰

```python
# ğŸ” åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ç³»ç»Ÿ
from enum import Enum
from typing import Set, Dict, List, Optional
import hashlib
import time
from dataclasses import dataclass

class Permission(Enum):
    """æƒé™æšä¸¾"""
    READ_FILE = "read_file"
    WRITE_FILE = "write_file"
    EXECUTE_CODE = "execute_code"
    NETWORK_ACCESS = "network_access"
    DATABASE_ACCESS = "database_access"
    SYSTEM_ADMIN = "system_admin"
    API_CALL = "api_call"
    DATA_EXPORT = "data_export"

class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class Role:
    """è§’è‰²å®šä¹‰"""
    name: str
    permissions: Set[Permission]
    risk_level: RiskLevel
    description: str

@dataclass
class User:
    """ç”¨æˆ·å®šä¹‰"""
    username: str
    roles: Set[str]
    api_key: str
    created_at: float
    last_active: float

class SecurityManager:
    """å®‰å…¨ç®¡ç†å™¨"""

    def __init__(self):
        self.roles: Dict[str, Role] = {}
        self.users: Dict[str, User] = {}
        self.audit_log: List[Dict] = []
        self._init_default_roles()

    def _init_default_roles(self):
        """åˆå§‹åŒ–é»˜è®¤è§’è‰²"""
        self.roles = {
            "guest": Role(
                name="guest",
                permissions={Permission.READ_FILE},
                risk_level=RiskLevel.LOW,
                description="è®¿å®¢ç”¨æˆ·ï¼Œåªèƒ½è¯»å–æ–‡ä»¶"
            ),
            "user": Role(
                name="user",
                permissions={Permission.READ_FILE, Permission.WRITE_FILE, Permission.API_CALL},
                risk_level=RiskLevel.MEDIUM,
                description="æ™®é€šç”¨æˆ·ï¼Œå¯ä»¥è¯»å†™æ–‡ä»¶å’Œè°ƒç”¨API"
            ),
            "developer": Role(
                name="developer",
                permissions={
                    Permission.READ_FILE, Permission.WRITE_FILE,
                    Permission.EXECUTE_CODE, Permission.API_CALL,
                    Permission.NETWORK_ACCESS
                },
                risk_level=RiskLevel.HIGH,
                description="å¼€å‘è€…ï¼Œå¯ä»¥æ‰§è¡Œä»£ç å’Œç½‘ç»œè®¿é—®"
            ),
            "admin": Role(
                name="admin",
                permissions=set(Permission),  # æ‰€æœ‰æƒé™
                risk_level=RiskLevel.CRITICAL,
                description="ç®¡ç†å‘˜ï¼Œæ‹¥æœ‰æ‰€æœ‰æƒé™"
            )
        }

    def create_user(self, username: str, roles: List[str]) -> str:
        """åˆ›å»ºç”¨æˆ·"""
        api_key = self._generate_api_key(username)
        user = User(
            username=username,
            roles=set(roles),
            api_key=api_key,
            created_at=time.time(),
            last_active=time.time()
        )
        self.users[username] = user

        self._log_audit("CREATE_USER", username, {"roles": roles})
        return api_key

    def _generate_api_key(self, username: str) -> str:
        """ç”ŸæˆAPIå¯†é’¥"""
        timestamp = str(time.time())
        raw_key = f"{username}:{timestamp}:secret_salt"
        return hashlib.sha256(raw_key.encode()).hexdigest()

    def authenticate(self, api_key: str) -> Optional[User]:
        """è®¤è¯ç”¨æˆ·"""
        for user in self.users.values():
            if user.api_key == api_key:
                user.last_active = time.time()
                return user
        return None

    def check_permission(self, user: User, permission: Permission) -> bool:
        """æ£€æŸ¥æƒé™"""
        for role_name in user.roles:
            if role_name in self.roles:
                role = self.roles[role_name]
                if permission in role.permissions:
                    return True
        return False

    def get_user_risk_level(self, user: User) -> RiskLevel:
        """è·å–ç”¨æˆ·é£é™©ç­‰çº§"""
        max_risk = RiskLevel.LOW
        for role_name in user.roles:
            if role_name in self.roles:
                role = self.roles[role_name]
                if role.risk_level.value > max_risk.value:
                    max_risk = role.risk_level
        return max_risk

    def _log_audit(self, action: str, username: str, details: Dict):
        """è®°å½•å®¡è®¡æ—¥å¿—"""
        log_entry = {
            "timestamp": time.time(),
            "action": action,
            "username": username,
            "details": details
        }
        self.audit_log.append(log_entry)

# å…¨å±€å®‰å…¨ç®¡ç†å™¨å®ä¾‹
security_manager = SecurityManager()
```

#### 2. å®‰å…¨å·¥å…·åŒ…è£…å™¨

```python
# ğŸ›¡ï¸ å®‰å…¨å·¥å…·åŒ…è£…å™¨
class SecureToolWrapper(BaseTool):
    """å®‰å…¨å·¥å…·åŒ…è£…å™¨"""

    def __init__(self, wrapped_tool: BaseTool, required_permission: Permission,
                 risk_level: RiskLevel = RiskLevel.MEDIUM):
        super().__init__()
        self.wrapped_tool = wrapped_tool
        self.required_permission = required_permission
        self.risk_level = risk_level
        self.name = f"Secure_{wrapped_tool.name}"
        self.description = f"å®‰å…¨åŒ…è£…çš„{wrapped_tool.description}"
        self.args_schema = wrapped_tool.args_schema

    def _run(self, *args, **kwargs) -> str:
        """å®‰å…¨æ‰§è¡Œå·¥å…·"""
        # è·å–å½“å‰ç”¨æˆ·ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»ä¸Šä¸‹æ–‡è·å–ï¼‰
        api_key = kwargs.pop('api_key', None)
        if not api_key:
            return "é”™è¯¯: éœ€è¦æä¾›APIå¯†é’¥"

        user = security_manager.authenticate(api_key)
        if not user:
            return "é”™è¯¯: èº«ä»½è®¤è¯å¤±è´¥"

        # æ£€æŸ¥æƒé™
        if not security_manager.check_permission(user, self.required_permission):
            security_manager._log_audit("PERMISSION_DENIED", user.username, {
                "tool": self.wrapped_tool.name,
                "permission": self.required_permission.value
            })
            return f"é”™è¯¯: æƒé™ä¸è¶³ï¼Œéœ€è¦ {self.required_permission.value} æƒé™"

        # é£é™©è¯„ä¼°
        user_risk = security_manager.get_user_risk_level(user)
        if self.risk_level.value > user_risk.value:
            security_manager._log_audit("RISK_BLOCKED", user.username, {
                "tool": self.wrapped_tool.name,
                "required_risk": self.risk_level.value,
                "user_risk": user_risk.value
            })
            return f"é”™è¯¯: é£é™©ç­‰çº§ä¸è¶³ï¼Œéœ€è¦ {self.risk_level.name} ç­‰çº§"

        # è®°å½•å·¥å…·ä½¿ç”¨
        security_manager._log_audit("TOOL_USAGE", user.username, {
            "tool": self.wrapped_tool.name,
            "args": str(args)[:200],  # é™åˆ¶æ—¥å¿—é•¿åº¦
            "kwargs": str(kwargs)[:200]
        })

        try:
            # æ‰§è¡ŒåŸå§‹å·¥å…·
            result = self.wrapped_tool._run(*args, **kwargs)

            security_manager._log_audit("TOOL_SUCCESS", user.username, {
                "tool": self.wrapped_tool.name,
                "result_length": len(str(result))
            })

            return result

        except Exception as e:
            security_manager._log_audit("TOOL_ERROR", user.username, {
                "tool": self.wrapped_tool.name,
                "error": str(e)
            })
            return f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"

# åˆ›å»ºå®‰å…¨å·¥å…·
def create_secure_tool(tool: BaseTool, permission: Permission,
                      risk_level: RiskLevel = RiskLevel.MEDIUM) -> SecureToolWrapper:
    """åˆ›å»ºå®‰å…¨å·¥å…·"""
    return SecureToolWrapper(tool, permission, risk_level)

# ä½¿ç”¨ç¤ºä¾‹
calculator_tool = AdvancedCalculatorTool()
secure_calculator = create_secure_tool(
    calculator_tool,
    Permission.EXECUTE_CODE,
    RiskLevel.MEDIUM
)

text_processor = TextProcessorTool()
secure_text_processor = create_secure_tool(
    text_processor,
    Permission.READ_FILE,
    RiskLevel.LOW
)

# åˆ›å»ºç”¨æˆ·
admin_key = security_manager.create_user("admin", ["admin"])
user_key = security_manager.create_user("john", ["user"])
guest_key = security_manager.create_user("guest", ["guest"])

# å®‰å…¨Agent
secure_agent = Agent(
    role="å®‰å…¨è®¡ç®—ä¸“å®¶",
    goal="åœ¨å®‰å…¨ç¯å¢ƒä¸­æ‰§è¡Œè®¡ç®—ä»»åŠ¡",
    backstory="ä¸“ä¸šçš„å®‰å…¨è®¡ç®—ä¸“å®¶ï¼Œä¸¥æ ¼éµå®ˆå®‰å…¨è§„èŒƒ...",
    tools=[secure_calculator, secure_text_processor],
    verbose=True
)
```

---

## 5.6 å·¥å…·æ€§èƒ½ç›‘æ§ğŸ“Š

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šæ€§èƒ½ä»ªè¡¨ç›˜

å·¥å…·æ€§èƒ½ç›‘æ§å°±åƒæ¸¸æˆä¸­çš„æ€§èƒ½ä»ªè¡¨ç›˜ï¼š

- **âš¡ é€Ÿåº¦è¡¨**ï¼šå·¥å…·æ‰§è¡Œæ—¶é—´ç›‘æ§
- **ğŸ’¾ å†…å­˜è¡¨**ï¼šèµ„æºä½¿ç”¨æƒ…å†µç›‘æ§
- **ğŸ“Š æˆåŠŸç‡è¡¨**ï¼šå·¥å…·æ‰§è¡ŒæˆåŠŸç‡ç»Ÿè®¡
- **ğŸ”¥ çƒ­åº¦è¡¨**ï¼šå·¥å…·ä½¿ç”¨é¢‘ç‡åˆ†æ

### ğŸ“Š æ€§èƒ½ç›‘æ§æ¶æ„

```mermaid
graph TD
    A[æ€§èƒ½ç›‘æ§ç³»ç»Ÿ] --> B[ğŸ“Š æŒ‡æ ‡æ”¶é›†]
    A --> C[ğŸ“ˆ æ•°æ®åˆ†æ]
    A --> D[âš ï¸ å‘Šè­¦ç³»ç»Ÿ]
    A --> E[ğŸ“‹ æŠ¥å‘Šç”Ÿæˆ]

    B --> B1[æ‰§è¡Œæ—¶é—´]
    B --> B2[å†…å­˜ä½¿ç”¨]
    B --> B3[æˆåŠŸç‡]
    B --> B4[é”™è¯¯ç‡]
    B --> B5[å¹¶å‘æ•°]

    C --> C1[è¶‹åŠ¿åˆ†æ]
    C --> C2[å¼‚å¸¸æ£€æµ‹]
    C --> C3[æ€§èƒ½åŸºçº¿]
    C --> C4[ç“¶é¢ˆè¯†åˆ«]

    D --> D1[é˜ˆå€¼å‘Šè­¦]
    D --> D2[å¼‚å¸¸å‘Šè­¦]
    D --> D3[å®¹é‡å‘Šè­¦]

    E --> E1[å®æ—¶ä»ªè¡¨ç›˜]
    E --> E2[å®šæœŸæŠ¥å‘Š]
    E --> E3[æ€§èƒ½ä¼˜åŒ–å»ºè®®]
```

### ğŸ“ˆ æ€§èƒ½ç›‘æ§å®ç°

#### 1. æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨

```python
# ğŸ“Š æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
import psutil
import threading
from collections import defaultdict, deque
from dataclasses import dataclass, field
from typing import Dict, List, Optional
import statistics

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    tool_name: str
    execution_time: float
    memory_usage: float
    cpu_usage: float
    success: bool
    error_message: Optional[str] = None
    timestamp: float = field(default_factory=time.time)
    input_size: int = 0
    output_size: int = 0

class PerformanceCollector:
    """æ€§èƒ½æ”¶é›†å™¨"""

    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.metrics_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=max_history))
        self.real_time_stats: Dict[str, Dict] = defaultdict(dict)
        self._lock = threading.Lock()

    def record_metric(self, metric: PerformanceMetrics):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        with self._lock:
            self.metrics_history[metric.tool_name].append(metric)
            self._update_real_time_stats(metric)

    def _update_real_time_stats(self, metric: PerformanceMetrics):
        """æ›´æ–°å®æ—¶ç»Ÿè®¡"""
        tool_name = metric.tool_name

        if tool_name not in self.real_time_stats:
            self.real_time_stats[tool_name] = {
                "total_calls": 0,
                "success_calls": 0,
                "total_time": 0,
                "avg_time": 0,
                "min_time": float('inf'),
                "max_time": 0,
                "avg_memory": 0,
                "error_rate": 0
            }

        stats = self.real_time_stats[tool_name]
        stats["total_calls"] += 1

        if metric.success:
            stats["success_calls"] += 1

        stats["total_time"] += metric.execution_time
        stats["avg_time"] = stats["total_time"] / stats["total_calls"]
        stats["min_time"] = min(stats["min_time"], metric.execution_time)
        stats["max_time"] = max(stats["max_time"], metric.execution_time)

        # è®¡ç®—å¹³å‡å†…å­˜ä½¿ç”¨
        recent_metrics = list(self.metrics_history[tool_name])[-10:]  # æœ€è¿‘10æ¬¡
        if recent_metrics:
            stats["avg_memory"] = statistics.mean([m.memory_usage for m in recent_metrics])

        stats["error_rate"] = 1 - (stats["success_calls"] / stats["total_calls"])

    def get_tool_stats(self, tool_name: str) -> Dict:
        """è·å–å·¥å…·ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return self.real_time_stats.get(tool_name, {})

    def get_all_stats(self) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰å·¥å…·ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return dict(self.real_time_stats)

    def get_performance_report(self, tool_name: Optional[str] = None) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if tool_name:
            stats = self.get_tool_stats(tool_name)
            if not stats:
                return f"å·¥å…· '{tool_name}' æ²¡æœ‰æ€§èƒ½æ•°æ®"

            return self._format_tool_report(tool_name, stats)
        else:
            all_stats = self.get_all_stats()
            if not all_stats:
                return "æ²¡æœ‰æ€§èƒ½æ•°æ®"

            report = "=== æ€§èƒ½ç›‘æ§æŠ¥å‘Š ===\n\n"
            for tool_name, stats in all_stats.items():
                report += self._format_tool_report(tool_name, stats) + "\n"

            return report

    def _format_tool_report(self, tool_name: str, stats: Dict) -> str:
        """æ ¼å¼åŒ–å·¥å…·æŠ¥å‘Š"""
        return f"""
å·¥å…·: {tool_name}
- æ€»è°ƒç”¨æ¬¡æ•°: {stats.get('total_calls', 0)}
- æˆåŠŸæ¬¡æ•°: {stats.get('success_calls', 0)}
- æˆåŠŸç‡: {(1 - stats.get('error_rate', 0)) * 100:.1f}%
- å¹³å‡æ‰§è¡Œæ—¶é—´: {stats.get('avg_time', 0):.3f}ç§’
- æœ€å¿«æ‰§è¡Œæ—¶é—´: {stats.get('min_time', 0):.3f}ç§’
- æœ€æ…¢æ‰§è¡Œæ—¶é—´: {stats.get('max_time', 0):.3f}ç§’
- å¹³å‡å†…å­˜ä½¿ç”¨: {stats.get('avg_memory', 0):.2f}MB
"""

# å…¨å±€æ€§èƒ½æ”¶é›†å™¨
performance_collector = PerformanceCollector()
```

#### 2. æ€§èƒ½ç›‘æ§è£…é¥°å™¨

```python
# ğŸ” æ€§èƒ½ç›‘æ§è£…é¥°å™¨
import functools
import tracemalloc

class PerformanceMonitorTool(BaseTool):
    """æ€§èƒ½ç›‘æ§å·¥å…·åŒ…è£…å™¨"""

    def __init__(self, wrapped_tool: BaseTool, enable_memory_profiling: bool = True):
        super().__init__()
        self.wrapped_tool = wrapped_tool
        self.enable_memory_profiling = enable_memory_profiling
        self.name = f"Monitored_{wrapped_tool.name}"
        self.description = f"æ€§èƒ½ç›‘æ§çš„{wrapped_tool.description}"
        self.args_schema = wrapped_tool.args_schema

    def _run(self, *args, **kwargs) -> str:
        """ç›‘æ§æ‰§è¡Œå·¥å…·"""
        start_time = time.time()
        start_memory = 0

        # å¼€å§‹å†…å­˜ç›‘æ§
        if self.enable_memory_profiling:
            tracemalloc.start()
            process = psutil.Process()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB

        success = False
        error_message = None
        result = None

        try:
            # æ‰§è¡ŒåŸå§‹å·¥å…·
            result = self.wrapped_tool._run(*args, **kwargs)
            success = True

        except Exception as e:
            error_message = str(e)
            result = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {error_message}"

        finally:
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            execution_time = time.time() - start_time

            memory_usage = 0
            if self.enable_memory_profiling:
                try:
                    current_memory = process.memory_info().rss / 1024 / 1024
                    memory_usage = current_memory - start_memory
                    tracemalloc.stop()
                except:
                    memory_usage = 0

            # è®¡ç®—è¾“å…¥è¾“å‡ºå¤§å°
            input_size = len(str(args) + str(kwargs))
            output_size = len(str(result)) if result else 0

            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            metric = PerformanceMetrics(
                tool_name=self.wrapped_tool.name,
                execution_time=execution_time,
                memory_usage=memory_usage,
                cpu_usage=psutil.cpu_percent(),
                success=success,
                error_message=error_message,
                input_size=input_size,
                output_size=output_size
            )

            performance_collector.record_metric(metric)

        return result

def monitor_performance(tool: BaseTool, enable_memory_profiling: bool = True) -> PerformanceMonitorTool:
    """ä¸ºå·¥å…·æ·»åŠ æ€§èƒ½ç›‘æ§"""
    return PerformanceMonitorTool(tool, enable_memory_profiling)

# æ€§èƒ½æŠ¥å‘Šå·¥å…·
class PerformanceReportTool(BaseTool):
    """æ€§èƒ½æŠ¥å‘Šå·¥å…·"""
    name: str = "æ€§èƒ½æŠ¥å‘Šå·¥å…·"
    description: str = "ç”Ÿæˆå·¥å…·æ€§èƒ½ç›‘æ§æŠ¥å‘Š"
    args_schema: Type[BaseModel] = BaseModel

    def _run(self, tool_name: str = None) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        return performance_collector.get_performance_report(tool_name)

# ä½¿ç”¨ç¤ºä¾‹
# ä¸ºç°æœ‰å·¥å…·æ·»åŠ æ€§èƒ½ç›‘æ§
monitored_calculator = monitor_performance(AdvancedCalculatorTool())
monitored_text_processor = monitor_performance(TextProcessorTool())
performance_report_tool = PerformanceReportTool()

performance_agent = Agent(
    role="æ€§èƒ½ç›‘æ§ä¸“å®¶",
    goal="ç›‘æ§å’Œåˆ†æå·¥å…·æ€§èƒ½ï¼Œæä¾›ä¼˜åŒ–å»ºè®®",
    backstory="ä¸“ä¸šçš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–ä¸“å®¶...",
    tools=[monitored_calculator, monitored_text_processor, performance_report_tool],
    verbose=True
)
```

---

## 5.7 é«˜çº§å·¥å…·å¼€å‘æŠ€å·§ğŸš€

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šæŠ€èƒ½è¿›é˜¶ç³»ç»Ÿ

é«˜çº§å·¥å…·å¼€å‘å°±åƒæ¸¸æˆä¸­çš„æŠ€èƒ½è¿›é˜¶ï¼š

- **ğŸŒŸ æŠ€èƒ½å‡çº§**ï¼šä»åŸºç¡€å·¥å…·åˆ°æ™ºèƒ½å·¥å…·
- **ğŸ”® æŠ€èƒ½èåˆ**ï¼šå¤šç§æŠ€æœ¯çš„ç»„åˆåº”ç”¨
- **âš¡ æŠ€èƒ½ç‰¹åŒ–**ï¼šé’ˆå¯¹ç‰¹å®šåœºæ™¯çš„æ·±åº¦ä¼˜åŒ–
- **ğŸ¯ æŠ€èƒ½ç²¾é€š**ï¼šæŒæ¡å·¥å…·å¼€å‘çš„æœ€ä½³å®è·µ

### ğŸ“Š é«˜çº§æŠ€å·§ä½“ç³»

```mermaid
graph TD
    A[é«˜çº§å·¥å…·å¼€å‘æŠ€å·§] --> B[ğŸ§  æ™ºèƒ½åŒ–æŠ€å·§]
    A --> C[âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§]
    A --> D[ğŸ”§ æ‰©å±•æ€§æŠ€å·§]
    A --> E[ğŸ›¡ï¸ å¯é æ€§æŠ€å·§]

    B --> B1[è‡ªé€‚åº”å‚æ•°è°ƒæ•´]
    B --> B2[æœºå™¨å­¦ä¹ é›†æˆ]
    B --> B3[ä¸Šä¸‹æ–‡æ„ŸçŸ¥]
    B --> B4[æ™ºèƒ½ç¼“å­˜ç­–ç•¥]

    C --> C1[å¼‚æ­¥å¹¶å‘å¤„ç†]
    C --> C2[å†…å­˜ä¼˜åŒ–]
    C --> C3[è®¡ç®—ä¼˜åŒ–]
    C --> C4[ç½‘ç»œä¼˜åŒ–]

    D --> D1[æ’ä»¶åŒ–æ¶æ„]
    D --> D2[é…ç½®é©±åŠ¨è®¾è®¡]
    D --> D3[ç‰ˆæœ¬å…¼å®¹æ€§]
    D --> D4[APIè®¾è®¡åŸåˆ™]

    E --> E1[é”™è¯¯æ¢å¤æœºåˆ¶]
    E --> E2[è¶…æ—¶å’Œé‡è¯•]
    E --> E3[èµ„æºæ¸…ç†]
    E --> E4[çŠ¶æ€ä¸€è‡´æ€§]
```

### ğŸ§  æ™ºèƒ½åŒ–å·¥å…·å¼€å‘

#### 1. è‡ªé€‚åº”å·¥å…·

```python
# ğŸ§  è‡ªé€‚åº”æ™ºèƒ½å·¥å…·
from typing import Any, Dict, List, Tuple
import pickle
import os

class AdaptiveToolInput(BaseModel):
    """è‡ªé€‚åº”å·¥å…·è¾“å…¥"""
    data: Any = Field(description="è¾“å…¥æ•°æ®")
    context: Dict[str, Any] = Field(description="ä¸Šä¸‹æ–‡ä¿¡æ¯", default={})
    learning_mode: bool = Field(description="æ˜¯å¦å¯ç”¨å­¦ä¹ æ¨¡å¼", default=True)

class AdaptiveProcessingTool(BaseTool):
    """è‡ªé€‚åº”å¤„ç†å·¥å…·"""
    name: str = "è‡ªé€‚åº”å¤„ç†å·¥å…·"
    description: str = "æ ¹æ®å†å²æ•°æ®å’Œä¸Šä¸‹æ–‡è‡ªåŠ¨è°ƒæ•´å¤„ç†ç­–ç•¥"
    args_schema: Type[BaseModel] = AdaptiveToolInput

    def __init__(self, model_path: str = "adaptive_model.pkl"):
        super().__init__()
        self.model_path = model_path
        self.performance_history = []
        self.strategy_weights = {
            "fast_processing": 0.3,
            "accurate_processing": 0.4,
            "balanced_processing": 0.3
        }
        self._load_model()

    def _load_model(self):
        """åŠ è½½è‡ªé€‚åº”æ¨¡å‹"""
        if os.path.exists(self.model_path):
            try:
                with open(self.model_path, 'rb') as f:
                    saved_data = pickle.load(f)
                    self.strategy_weights = saved_data.get('weights', self.strategy_weights)
                    self.performance_history = saved_data.get('history', [])
            except Exception:
                pass

    def _save_model(self):
        """ä¿å­˜è‡ªé€‚åº”æ¨¡å‹"""
        try:
            with open(self.model_path, 'wb') as f:
                pickle.dump({
                    'weights': self.strategy_weights,
                    'history': self.performance_history[-100:]  # åªä¿å­˜æœ€è¿‘100æ¡è®°å½•
                }, f)
        except Exception:
            pass

    def _select_strategy(self, data: Any, context: Dict[str, Any]) -> str:
        """é€‰æ‹©å¤„ç†ç­–ç•¥"""
        # åˆ†ææ•°æ®ç‰¹å¾
        data_size = len(str(data))
        complexity = self._estimate_complexity(data)

        # åˆ†æä¸Šä¸‹æ–‡
        time_constraint = context.get('time_limit', 30)  # é»˜è®¤30ç§’
        accuracy_requirement = context.get('accuracy_level', 'medium')

        # è®¡ç®—ç­–ç•¥å¾—åˆ†
        scores = {}

        # å¿«é€Ÿå¤„ç†ç­–ç•¥
        scores['fast_processing'] = (
            self.strategy_weights['fast_processing'] *
            (1.0 if time_constraint < 10 else 0.5) *
            (1.0 if data_size < 1000 else 0.3)
        )

        # ç²¾ç¡®å¤„ç†ç­–ç•¥
        scores['accurate_processing'] = (
            self.strategy_weights['accurate_processing'] *
            (1.0 if accuracy_requirement == 'high' else 0.6) *
            (1.0 if complexity > 0.7 else 0.4)
        )

        # å¹³è¡¡å¤„ç†ç­–ç•¥
        scores['balanced_processing'] = (
            self.strategy_weights['balanced_processing'] *
            (0.8 if accuracy_requirement == 'medium' else 0.5) *
            (0.8 if 10 <= time_constraint <= 60 else 0.4)
        )

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç­–ç•¥
        return max(scores, key=scores.get)

    def _estimate_complexity(self, data: Any) -> float:
        """ä¼°ç®—æ•°æ®å¤æ‚åº¦"""
        if isinstance(data, str):
            # æ–‡æœ¬å¤æ‚åº¦ï¼šåŸºäºé•¿åº¦å’Œç‰¹æ®Šå­—ç¬¦
            length_factor = min(len(data) / 1000, 1.0)
            special_chars = sum(1 for c in data if not c.isalnum() and not c.isspace())
            special_factor = min(special_chars / len(data), 0.5) if data else 0
            return length_factor * 0.7 + special_factor * 0.3
        elif isinstance(data, (list, dict)):
            # ç»“æ„åŒ–æ•°æ®å¤æ‚åº¦
            return min(len(str(data)) / 5000, 1.0)
        else:
            return 0.5  # é»˜è®¤ä¸­ç­‰å¤æ‚åº¦

    def _process_fast(self, data: Any) -> str:
        """å¿«é€Ÿå¤„ç†ç­–ç•¥"""
        # ç®€åŒ–å¤„ç†é€»è¾‘
        return f"å¿«é€Ÿå¤„ç†ç»“æœ: {str(data)[:100]}..."

    def _process_accurate(self, data: Any) -> str:
        """ç²¾ç¡®å¤„ç†ç­–ç•¥"""
        # è¯¦ç»†å¤„ç†é€»è¾‘
        time.sleep(0.5)  # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
        return f"ç²¾ç¡®å¤„ç†ç»“æœ: è¯¦ç»†åˆ†æäº† {len(str(data))} å­—ç¬¦çš„æ•°æ®"

    def _process_balanced(self, data: Any) -> str:
        """å¹³è¡¡å¤„ç†ç­–ç•¥"""
        # å¹³è¡¡å¤„ç†é€»è¾‘
        time.sleep(0.2)  # æ¨¡æ‹Ÿä¸­ç­‰å¤æ‚åº¦è®¡ç®—
        return f"å¹³è¡¡å¤„ç†ç»“æœ: é«˜æ•ˆåˆ†æäº†æ•°æ®ï¼Œå¤æ‚åº¦è¯„ä¼°ä¸ºä¸­ç­‰"

    def _update_strategy_weights(self, strategy: str, performance: float):
        """æ›´æ–°ç­–ç•¥æƒé‡"""
        # ç®€å•çš„å¼ºåŒ–å­¦ä¹ æ›´æ–°
        learning_rate = 0.1
        reward = performance  # æ€§èƒ½ä½œä¸ºå¥–åŠ±

        # æ›´æ–°é€‰ä¸­ç­–ç•¥çš„æƒé‡
        self.strategy_weights[strategy] += learning_rate * reward

        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.strategy_weights.values())
        for key in self.strategy_weights:
            self.strategy_weights[key] /= total_weight

    def _run(self, data: Any, context: Dict[str, Any] = None, learning_mode: bool = True) -> str:
        """æ‰§è¡Œè‡ªé€‚åº”å¤„ç†"""
        if context is None:
            context = {}

        start_time = time.time()

        # é€‰æ‹©å¤„ç†ç­–ç•¥
        strategy = self._select_strategy(data, context)

        # æ‰§è¡Œå¤„ç†
        try:
            if strategy == "fast_processing":
                result = self._process_fast(data)
            elif strategy == "accurate_processing":
                result = self._process_accurate(data)
            else:
                result = self._process_balanced(data)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            execution_time = time.time() - start_time
            performance = 1.0 / (1.0 + execution_time)  # æ—¶é—´è¶ŠçŸ­æ€§èƒ½è¶Šå¥½

            # å­¦ä¹ æ¨¡å¼ä¸‹æ›´æ–°ç­–ç•¥
            if learning_mode:
                self.performance_history.append({
                    'strategy': strategy,
                    'performance': performance,
                    'execution_time': execution_time,
                    'data_size': len(str(data))
                })

                self._update_strategy_weights(strategy, performance)
                self._save_model()

            return f"ç­–ç•¥: {strategy}\nç»“æœ: {result}\næ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’"

        except Exception as e:
            return f"å¤„ç†å¤±è´¥: {str(e)}"

# ä½¿ç”¨ç¤ºä¾‹
adaptive_tool = AdaptiveProcessingTool()

adaptive_agent = Agent(
    role="è‡ªé€‚åº”å¤„ç†ä¸“å®¶",
    goal="æ ¹æ®æ•°æ®ç‰¹å¾å’Œä¸Šä¸‹æ–‡è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¤„ç†ç­–ç•¥",
    backstory="å…·æœ‰æœºå™¨å­¦ä¹ èƒ½åŠ›çš„æ™ºèƒ½å¤„ç†ä¸“å®¶...",
    tools=[adaptive_tool],
    verbose=True
)
```

#### 2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·

```python
# ğŸ”® ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·
class ContextAwareInput(BaseModel):
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¾“å…¥"""
    query: str = Field(description="æŸ¥è¯¢å†…å®¹")
    context_type: str = Field(description="ä¸Šä¸‹æ–‡ç±»å‹", default="general")
    previous_results: List[str] = Field(description="ä¹‹å‰çš„ç»“æœ", default=[])

class ContextAwareTool(BaseTool):
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·"""
    name: str = "ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·"
    description: str = "æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›æ™ºèƒ½åŒ–çš„å¤„ç†ç»“æœ"
    args_schema: Type[BaseModel] = ContextAwareInput

    def __init__(self):
        super().__init__()
        self.context_memory = {}
        self.session_history = []

    def _analyze_context(self, query: str, context_type: str, previous_results: List[str]) -> Dict[str, Any]:
        """åˆ†æä¸Šä¸‹æ–‡"""
        context_info = {
            "query_intent": self._detect_intent(query),
            "context_type": context_type,
            "has_history": len(previous_results) > 0,
            "complexity_level": self._assess_complexity(query),
            "domain": self._detect_domain(query)
        }

        # åˆ†æå†å²ç»“æœçš„æ¨¡å¼
        if previous_results:
            context_info["result_pattern"] = self._analyze_result_pattern(previous_results)

        return context_info

    def _detect_intent(self, query: str) -> str:
        """æ£€æµ‹æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()

        if any(word in query_lower for word in ['è®¡ç®—', 'ç®—', 'æ•°å­¦', 'å…¬å¼']):
            return "calculation"
        elif any(word in query_lower for word in ['åˆ†æ', 'ç»Ÿè®¡', 'æ•°æ®']):
            return "analysis"
        elif any(word in query_lower for word in ['æœç´¢', 'æŸ¥æ‰¾', 'å¯»æ‰¾']):
            return "search"
        elif any(word in query_lower for word in ['åˆ›å»º', 'ç”Ÿæˆ', 'åˆ¶ä½œ']):
            return "creation"
        else:
            return "general"

    def _detect_domain(self, query: str) -> str:
        """æ£€æµ‹é¢†åŸŸ"""
        query_lower = query.lower()

        if any(word in query_lower for word in ['é‡‘è', 'æŠ•èµ„', 'è‚¡ç¥¨', 'è´¢åŠ¡']):
            return "finance"
        elif any(word in query_lower for word in ['æŠ€æœ¯', 'ç¼–ç¨‹', 'ä»£ç ', 'å¼€å‘']):
            return "technology"
        elif any(word in query_lower for word in ['åŒ»ç–—', 'å¥åº·', 'åŒ»å­¦']):
            return "healthcare"
        elif any(word in query_lower for word in ['æ•™è‚²', 'å­¦ä¹ ', 'åŸ¹è®­']):
            return "education"
        else:
            return "general"

    def _assess_complexity(self, query: str) -> str:
        """è¯„ä¼°å¤æ‚åº¦"""
        word_count = len(query.split())

        if word_count < 5:
            return "simple"
        elif word_count < 15:
            return "medium"
        else:
            return "complex"

    def _analyze_result_pattern(self, previous_results: List[str]) -> Dict[str, Any]:
        """åˆ†æç»“æœæ¨¡å¼"""
        if not previous_results:
            return {}

        # åˆ†æç»“æœé•¿åº¦è¶‹åŠ¿
        lengths = [len(result) for result in previous_results]
        avg_length = sum(lengths) / len(lengths)

        # åˆ†æç»“æœç±»å‹
        result_types = []
        for result in previous_results:
            if result.startswith("è®¡ç®—ç»“æœ"):
                result_types.append("calculation")
            elif "åˆ†æ" in result:
                result_types.append("analysis")
            else:
                result_types.append("general")

        return {
            "avg_length": avg_length,
            "result_types": result_types,
            "trend": "increasing" if lengths[-1] > lengths[0] else "decreasing"
        }

    def _generate_contextual_response(self, query: str, context_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å“åº”"""
        intent = context_info["query_intent"]
        domain = context_info["domain"]
        complexity = context_info["complexity_level"]

        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´å“åº”ç­–ç•¥
        if intent == "calculation":
            if complexity == "simple":
                return f"ç®€å•è®¡ç®—: {query} çš„ç»“æœæ˜¯..."
            else:
                return f"å¤æ‚è®¡ç®—åˆ†æ: å¯¹äº {query}ï¼Œéœ€è¦è€ƒè™‘å¤šä¸ªå› ç´ ..."

        elif intent == "analysis":
            if domain == "finance":
                return f"é‡‘èåˆ†æ: åŸºäº {query} çš„è´¢åŠ¡æ•°æ®åˆ†ææ˜¾ç¤º..."
            elif domain == "technology":
                return f"æŠ€æœ¯åˆ†æ: å…³äº {query} çš„æŠ€æœ¯è¯„ä¼°ç»“æœ..."
            else:
                return f"æ•°æ®åˆ†æ: {query} çš„åˆ†æç»“æœ..."

        elif intent == "search":
            return f"æœç´¢ç»“æœ: å…³äº {query} æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯..."

        else:
            return f"åŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½å›å¤: {query}"

    def _run(self, query: str, context_type: str = "general", previous_results: List[str] = None) -> str:
        """æ‰§è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤„ç†"""
        if previous_results is None:
            previous_results = []

        # åˆ†æä¸Šä¸‹æ–‡
        context_info = self._analyze_context(query, context_type, previous_results)

        # ç”Ÿæˆå“åº”
        response = self._generate_contextual_response(query, context_info)

        # æ›´æ–°ä¼šè¯å†å²
        self.session_history.append({
            "query": query,
            "context_info": context_info,
            "response": response,
            "timestamp": time.time()
        })

        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.session_history) > 50:
            self.session_history = self.session_history[-50:]

        return f"""
ä¸Šä¸‹æ–‡åˆ†æ:
- æŸ¥è¯¢æ„å›¾: {context_info['query_intent']}
- é¢†åŸŸ: {context_info['domain']}
- å¤æ‚åº¦: {context_info['complexity_level']}
- æœ‰å†å²è®°å½•: {context_info['has_history']}

æ™ºèƒ½å“åº”:
{response}
"""

# ä½¿ç”¨ç¤ºä¾‹
context_aware_tool = ContextAwareTool()

context_agent = Agent(
    role="ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¸“å®¶",
    goal="åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›æ™ºèƒ½åŒ–çš„ä¸ªæ€§åŒ–æœåŠ¡",
    backstory="å…·æœ‰å¼ºå¤§ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›çš„æ™ºèƒ½åŠ©æ‰‹...",
    tools=[context_aware_tool],
    verbose=True
)
```

---

## 5.8 å®æˆ˜æ¡ˆä¾‹åˆ†æğŸª

### ğŸ® æ¸¸æˆåŒ–ç†è§£ï¼šå‰¯æœ¬æŒ‘æˆ˜

å®æˆ˜æ¡ˆä¾‹å°±åƒæ¸¸æˆä¸­çš„å‰¯æœ¬æŒ‘æˆ˜ï¼š

- **ğŸ° æ–°æ‰‹å‰¯æœ¬**ï¼šåŸºç¡€å·¥å…·é›†æˆæ¡ˆä¾‹
- **âš”ï¸ è¿›é˜¶å‰¯æœ¬**ï¼šå¤æ‚å·¥å…·é“¾è®¾è®¡æ¡ˆä¾‹
- **ğŸ‰ ä¸“å®¶å‰¯æœ¬**ï¼šä¼ä¸šçº§å·¥å…·ç³»ç»Ÿæ¡ˆä¾‹
- **ğŸ‘‘ ä¼ è¯´å‰¯æœ¬**ï¼šåˆ›æ–°å·¥å…·å¼€å‘æ¡ˆä¾‹

### ğŸ“Š æ¡ˆä¾‹åˆ†ææ¡†æ¶

```mermaid
graph TD
    A[å®æˆ˜æ¡ˆä¾‹åˆ†æ] --> B[ğŸ“‹ éœ€æ±‚åˆ†æ]
    A --> C[ğŸ¯ è§£å†³æ–¹æ¡ˆè®¾è®¡]
    A --> D[ğŸ”§ å®ç°è¿‡ç¨‹]
    A --> E[ğŸ“ˆ æ•ˆæœè¯„ä¼°]
    A --> F[ğŸ’¡ ç»éªŒæ€»ç»“]

    B --> B1[ä¸šåŠ¡éœ€æ±‚]
    B --> B2[æŠ€æœ¯éœ€æ±‚]
    B --> B3[æ€§èƒ½éœ€æ±‚]
    B --> B4[å®‰å…¨éœ€æ±‚]

    C --> C1[æ¶æ„è®¾è®¡]
    C --> C2[å·¥å…·é€‰æ‹©]
    C --> C3[é›†æˆç­–ç•¥]
    C --> C4[ä¼˜åŒ–æ–¹æ¡ˆ]

    D --> D1[å¼€å‘é˜¶æ®µ]
    D --> D2[æµ‹è¯•é˜¶æ®µ]
    D --> D3[éƒ¨ç½²é˜¶æ®µ]
    D --> D4[ç»´æŠ¤é˜¶æ®µ]

    E --> E1[æ€§èƒ½æŒ‡æ ‡]
    E --> E2[ç”¨æˆ·åé¦ˆ]
    E --> E3[ä¸šåŠ¡ä»·å€¼]
    E --> E4[æŠ€æœ¯æ”¶ç›Š]
```

### ğŸ° æ¡ˆä¾‹ä¸€ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

#### éœ€æ±‚åˆ†æ
æ„å»ºä¸€ä¸ªæ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š
- ç†è§£ç”¨æˆ·é—®é¢˜å¹¶æä¾›å‡†ç¡®å›ç­”
- å¤„ç†å¤šç§ç±»å‹çš„æŸ¥è¯¢ï¼ˆäº§å“ä¿¡æ¯ã€æŠ€æœ¯æ”¯æŒã€æŠ•è¯‰å¤„ç†ï¼‰
- ä¸ç°æœ‰ç³»ç»Ÿé›†æˆï¼ˆCRMã€çŸ¥è¯†åº“ã€å·¥å•ç³»ç»Ÿï¼‰
- æä¾›å¤šè¯­è¨€æ”¯æŒ

#### è§£å†³æ–¹æ¡ˆè®¾è®¡

```python
# ğŸ¤– æ™ºèƒ½å®¢æœç³»ç»Ÿå®ç°
class CustomerServiceInput(BaseModel):
    """å®¢æœè¾“å…¥æ¨¡å‹"""
    user_message: str = Field(description="ç”¨æˆ·æ¶ˆæ¯")
    user_id: str = Field(description="ç”¨æˆ·ID")
    session_id: str = Field(description="ä¼šè¯ID")
    language: str = Field(description="è¯­è¨€", default="zh")

class IntelligentCustomerServiceTool(BaseTool):
    """æ™ºèƒ½å®¢æœå·¥å…·"""
    name: str = "æ™ºèƒ½å®¢æœç³»ç»Ÿ"
    description: str = "æä¾›æ™ºèƒ½å®¢æœæœåŠ¡ï¼ŒåŒ…æ‹¬é—®é¢˜ç†è§£ã€çŸ¥è¯†æ£€ç´¢ã€å›ç­”ç”Ÿæˆ"
    args_schema: Type[BaseModel] = CustomerServiceInput

    def __init__(self):
        super().__init__()
        # é›†æˆå¤šä¸ªå·¥å…·
        self.text_processor = TextProcessorTool()
        self.search_tool = SerperDevTool()
        self.context_tool = ContextAwareTool()

        # çŸ¥è¯†åº“
        self.knowledge_base = {
            "äº§å“ä¿¡æ¯": {
                "ä»·æ ¼": "æˆ‘ä»¬çš„äº§å“ä»·æ ¼ä»99å…ƒåˆ°999å…ƒä¸ç­‰ï¼Œå…·ä½“ä»·æ ¼è¯·æŸ¥çœ‹å®˜ç½‘ã€‚",
                "åŠŸèƒ½": "æˆ‘ä»¬çš„äº§å“å…·æœ‰AIæ™ºèƒ½åˆ†æã€æ•°æ®å¯è§†åŒ–ã€è‡ªåŠ¨æŠ¥å‘Šç­‰åŠŸèƒ½ã€‚",
                "ä½¿ç”¨æ–¹æ³•": "äº§å“ä½¿ç”¨éå¸¸ç®€å•ï¼Œåªéœ€ä¸‰æ­¥ï¼šæ³¨å†Œè´¦å·ã€å¯¼å…¥æ•°æ®ã€ç”ŸæˆæŠ¥å‘Šã€‚"
            },
            "æŠ€æœ¯æ”¯æŒ": {
                "å®‰è£…é—®é¢˜": "å¦‚æœé‡åˆ°å®‰è£…é—®é¢˜ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿæ»¡è¶³æœ€ä½è¦æ±‚ï¼Œå¹¶ä»¥ç®¡ç†å‘˜æƒé™è¿è¡Œã€‚",
                "ä½¿ç”¨é—®é¢˜": "ä½¿ç”¨è¿‡ç¨‹ä¸­å¦‚æœ‰é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹å¸®åŠ©æ–‡æ¡£æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚",
                "æ•…éšœæ’é™¤": "å¸¸è§æ•…éšœå¯ä»¥é€šè¿‡é‡å¯åº”ç”¨ã€æ¸…é™¤ç¼“å­˜ã€æ›´æ–°ç‰ˆæœ¬æ¥è§£å†³ã€‚"
            },
            "æŠ•è¯‰å¤„ç†": {
                "æœåŠ¡æŠ•è¯‰": "æˆ‘ä»¬éå¸¸é‡è§†æ‚¨çš„åé¦ˆï¼Œä¼šåœ¨24å°æ—¶å†…å®‰æ’ä¸“äººå¤„ç†æ‚¨çš„æŠ•è¯‰ã€‚",
                "äº§å“æŠ•è¯‰": "å¯¹äºäº§å“é—®é¢˜ï¼Œæˆ‘ä»¬æä¾›7å¤©æ— ç†ç”±é€€æ¢è´§æœåŠ¡ã€‚",
                "å…¶ä»–æŠ•è¯‰": "å…¶ä»–é—®é¢˜è¯·è¯¦ç»†æè¿°ï¼Œæˆ‘ä»¬ä¼šè®¤çœŸå¯¹å¾…å¹¶åŠæ—¶å›å¤ã€‚"
            }
        }

        # ä¼šè¯å†å²
        self.session_history = {}

    def _classify_intent(self, message: str) -> Tuple[str, str]:
        """åˆ†ç±»ç”¨æˆ·æ„å›¾"""
        message_lower = message.lower()

        # äº§å“ç›¸å…³
        if any(word in message_lower for word in ['ä»·æ ¼', 'å¤šå°‘é’±', 'è´¹ç”¨', 'æ”¶è´¹']):
            return "äº§å“ä¿¡æ¯", "ä»·æ ¼"
        elif any(word in message_lower for word in ['åŠŸèƒ½', 'ç‰¹ç‚¹', 'èƒ½åšä»€ä¹ˆ']):
            return "äº§å“ä¿¡æ¯", "åŠŸèƒ½"
        elif any(word in message_lower for word in ['æ€ä¹ˆç”¨', 'å¦‚ä½•ä½¿ç”¨', 'ä½¿ç”¨æ–¹æ³•']):
            return "äº§å“ä¿¡æ¯", "ä½¿ç”¨æ–¹æ³•"

        # æŠ€æœ¯æ”¯æŒ
        elif any(word in message_lower for word in ['å®‰è£…', 'å®‰è£…ä¸äº†', 'è£…ä¸ä¸Š']):
            return "æŠ€æœ¯æ”¯æŒ", "å®‰è£…é—®é¢˜"
        elif any(word in message_lower for word in ['ä¸ä¼šç”¨', 'æ€ä¹ˆæ“ä½œ', 'ä½¿ç”¨é—®é¢˜']):
            return "æŠ€æœ¯æ”¯æŒ", "ä½¿ç”¨é—®é¢˜"
        elif any(word in message_lower for word in ['æ•…éšœ', 'é”™è¯¯', 'ä¸å·¥ä½œ', 'åäº†']):
            return "æŠ€æœ¯æ”¯æŒ", "æ•…éšœæ’é™¤"

        # æŠ•è¯‰å¤„ç†
        elif any(word in message_lower for word in ['æŠ•è¯‰', 'ä¸æ»¡æ„', 'å·®è¯„']):
            if any(word in message_lower for word in ['æœåŠ¡', 'æ€åº¦', 'å®¢æœ']):
                return "æŠ•è¯‰å¤„ç†", "æœåŠ¡æŠ•è¯‰"
            elif any(word in message_lower for word in ['äº§å“', 'è´¨é‡', 'åŠŸèƒ½']):
                return "æŠ•è¯‰å¤„ç†", "äº§å“æŠ•è¯‰"
            else:
                return "æŠ•è¯‰å¤„ç†", "å…¶ä»–æŠ•è¯‰"

        return "å…¶ä»–", "é€šç”¨"

    def _get_knowledge_answer(self, category: str, subcategory: str) -> str:
        """ä»çŸ¥è¯†åº“è·å–ç­”æ¡ˆ"""
        if category in self.knowledge_base and subcategory in self.knowledge_base[category]:
            return self.knowledge_base[category][subcategory]
        return None

    def _generate_personalized_response(self, base_answer: str, user_id: str, context: Dict) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–å›å¤"""
        # æ ¹æ®ç”¨æˆ·å†å²å’Œä¸Šä¸‹æ–‡ä¸ªæ€§åŒ–å›å¤
        if user_id in self.session_history:
            history = self.session_history[user_id]
            if len(history) > 0:
                base_answer += f"\n\næ ¹æ®æ‚¨ä¹‹å‰çš„å’¨è¯¢è®°å½•ï¼Œæˆ‘è¿˜æƒ³æé†’æ‚¨..."

        return base_answer

    def _escalate_to_human(self, message: str, user_id: str) -> str:
        """å‡çº§åˆ°äººå·¥å®¢æœ"""
        return f"æ‚¨çš„é—®é¢˜æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘å·²ç»ä¸ºæ‚¨è½¬æ¥åˆ°äººå·¥å®¢æœï¼Œå·¥å•å·ï¼šCS{int(time.time())}"

    def _run(self, user_message: str, user_id: str, session_id: str, language: str = "zh") -> str:
        """å¤„ç†å®¢æœè¯·æ±‚"""
        try:
            # åˆå§‹åŒ–ä¼šè¯å†å²
            if user_id not in self.session_history:
                self.session_history[user_id] = []

            # åˆ†ç±»ç”¨æˆ·æ„å›¾
            category, subcategory = self._classify_intent(user_message)

            # ä»çŸ¥è¯†åº“è·å–ç­”æ¡ˆ
            knowledge_answer = self._get_knowledge_answer(category, subcategory)

            if knowledge_answer:
                # ç”Ÿæˆä¸ªæ€§åŒ–å›å¤
                response = self._generate_personalized_response(
                    knowledge_answer, user_id, {"category": category}
                )
            else:
                # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·å¤„ç†å¤æ‚é—®é¢˜
                context_response = self.context_tool._run(
                    user_message,
                    context_type="customer_service",
                    previous_results=[item["response"] for item in self.session_history[user_id][-3:]]
                )

                if "å¤æ‚" in context_response or "ä¸ç¡®å®š" in context_response:
                    response = self._escalate_to_human(user_message, user_id)
                else:
                    response = f"åŸºäºæ™ºèƒ½åˆ†æï¼š{context_response}"

            # è®°å½•ä¼šè¯å†å²
            self.session_history[user_id].append({
                "message": user_message,
                "response": response,
                "category": category,
                "subcategory": subcategory,
                "timestamp": time.time()
            })

            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            if len(self.session_history[user_id]) > 20:
                self.session_history[user_id] = self.session_history[user_id][-20:]

            return f"""
ğŸ¤– æ™ºèƒ½å®¢æœå›å¤ï¼š

åˆ†ç±»ï¼š{category} - {subcategory}
å›å¤ï¼š{response}

å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ï¼
"""

        except Exception as e:
            return f"å®¢æœç³»ç»Ÿæš‚æ—¶é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚é”™è¯¯ï¼š{str(e)}"

# å®¢æœç³»ç»Ÿé›†æˆç¤ºä¾‹
customer_service_tool = IntelligentCustomerServiceTool()

customer_service_agent = Agent(
    role="æ™ºèƒ½å®¢æœä¸“å®¶",
    goal="æä¾›é«˜è´¨é‡çš„å®¢æˆ·æœåŠ¡ï¼Œè§£å†³ç”¨æˆ·é—®é¢˜",
    backstory="ç»éªŒä¸°å¯Œçš„å®¢æœä¸“å®¶ï¼Œå…·å¤‡å¼ºå¤§çš„é—®é¢˜è§£å†³èƒ½åŠ›...",
    tools=[customer_service_tool],
    verbose=True
)
```

### âš”ï¸ æ¡ˆä¾‹äºŒï¼šæ•°æ®åˆ†æå·¥ä½œæµ

#### éœ€æ±‚åˆ†æ
æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–æ•°æ®åˆ†æå·¥ä½œæµï¼Œèƒ½å¤Ÿï¼š
- ä»å¤šä¸ªæ•°æ®æºè·å–æ•°æ®
- è‡ªåŠ¨æ¸…æ´—å’Œé¢„å¤„ç†æ•°æ®
- æ‰§è¡Œç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–
- ç”Ÿæˆåˆ†ææŠ¥å‘Š

```python
# ğŸ“Š æ•°æ®åˆ†æå·¥ä½œæµå®ç°
class DataAnalysisWorkflow:
    """æ•°æ®åˆ†æå·¥ä½œæµ"""

    def __init__(self):
        # é›†æˆå¤šä¸ªå·¥å…·
        self.file_reader = FileReadTool()
        self.csv_search = CSVSearchTool("data/sample.csv")
        self.code_interpreter = CodeInterpreterTool()
        self.text_processor = TextProcessorTool()
        self.stateful_data = StatefulDataTool()

        # åˆ›å»ºå·¥ä½œæµç®¡é“
        self.analysis_pipeline = ToolPipeline([
            self.file_reader,
            self.code_interpreter,
            self.text_processor
        ], name="æ•°æ®åˆ†æç®¡é“")

    def create_comprehensive_analysis_agent(self) -> Agent:
        """åˆ›å»ºç»¼åˆåˆ†æAgent"""
        return Agent(
            role="æ•°æ®åˆ†æä¸“å®¶",
            goal="æ‰§è¡Œå…¨é¢çš„æ•°æ®åˆ†æï¼Œä»æ•°æ®è·å–åˆ°æŠ¥å‘Šç”Ÿæˆ",
            backstory="èµ„æ·±çš„æ•°æ®ç§‘å­¦å®¶ï¼Œæ“…é•¿ç«¯åˆ°ç«¯çš„æ•°æ®åˆ†ææµç¨‹...",
            tools=[
                self.analysis_pipeline,
                self.csv_search,
                self.stateful_data,
                monitor_performance(self.code_interpreter)  # æ·»åŠ æ€§èƒ½ç›‘æ§
            ],
            verbose=True
        )

# ä½¿ç”¨ç¤ºä¾‹
workflow = DataAnalysisWorkflow()
analysis_agent = workflow.create_comprehensive_analysis_agent()
```

### ğŸ’¡ ç»éªŒæ€»ç»“å’Œæœ€ä½³å®è·µ

#### ğŸ¯ å·¥å…·å¼€å‘æœ€ä½³å®è·µ

1. **è®¾è®¡åŸåˆ™**
   - å•ä¸€èŒè´£ï¼šæ¯ä¸ªå·¥å…·ä¸“æ³¨ä¸€ä¸ªåŠŸèƒ½
   - æ¥å£ä¸€è‡´ï¼šç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ ¼å¼
   - é”™è¯¯å¤„ç†ï¼šä¼˜é›…çš„é”™è¯¯å¤„ç†å’Œæ¢å¤
   - æ€§èƒ½ä¼˜åŒ–ï¼šè€ƒè™‘ç¼“å­˜ã€å¼‚æ­¥ã€å¹¶å‘

2. **å®‰å…¨è€ƒè™‘**
   - è¾“å…¥éªŒè¯ï¼šä¸¥æ ¼éªŒè¯æ‰€æœ‰è¾“å…¥å‚æ•°
   - æƒé™æ§åˆ¶ï¼šå®ç°ç»†ç²’åº¦çš„æƒé™ç®¡ç†
   - å®¡è®¡æ—¥å¿—ï¼šè®°å½•æ‰€æœ‰é‡è¦æ“ä½œ
   - èµ„æºé™åˆ¶ï¼šé˜²æ­¢èµ„æºæ»¥ç”¨

3. **å¯ç»´æŠ¤æ€§**
   - ä»£ç è§„èŒƒï¼šéµå¾ªç¼–ç æ ‡å‡†å’Œæœ€ä½³å®è·µ
   - æ–‡æ¡£å®Œå–„ï¼šæä¾›è¯¦ç»†çš„APIæ–‡æ¡£
   - æµ‹è¯•è¦†ç›–ï¼šç¼–å†™å…¨é¢çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
   - ç‰ˆæœ¬ç®¡ç†ï¼šåˆç†çš„ç‰ˆæœ¬æ§åˆ¶ç­–ç•¥

4. **æ‰©å±•æ€§**
   - æ’ä»¶åŒ–ï¼šæ”¯æŒæ’ä»¶å¼æ‰©å±•
   - é…ç½®é©±åŠ¨ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶è¡Œä¸º
   - æ¥å£æŠ½è±¡ï¼šå®šä¹‰æ¸…æ™°çš„æŠ½è±¡æ¥å£
   - å‘åå…¼å®¹ï¼šä¿æŒAPIçš„å‘åå…¼å®¹æ€§

---

## ğŸ¯ ç¬¬5ç« æ€»ç»“

### ğŸ† å­¦ä¹ æˆæœ

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†ï¼š

âœ… **å·¥å…·ç”Ÿæ€ç³»ç»Ÿ**ï¼šæ·±å…¥äº†è§£CrewAIå†…ç½®å·¥å…·å’Œç¬¬ä¸‰æ–¹å·¥å…·é›†æˆ
âœ… **è‡ªå®šä¹‰å¼€å‘**ï¼šèƒ½å¤Ÿå¼€å‘æ»¡è¶³ç‰¹å®šéœ€æ±‚çš„è‡ªå®šä¹‰å·¥å…·
âœ… **å·¥å…·é“¾è®¾è®¡**ï¼šæŒæ¡å·¥å…·é“¾çš„è®¾è®¡æ¨¡å¼å’Œä¼˜åŒ–ç­–ç•¥
âœ… **å®‰å…¨ç®¡ç†**ï¼šå®ç°å·¥å…·çš„å®‰å…¨æ§åˆ¶å’Œæƒé™ç®¡ç†
âœ… **æ€§èƒ½ç›‘æ§**ï¼šå»ºç«‹å®Œå–„çš„å·¥å…·æ€§èƒ½ç›‘æ§ä½“ç³»
âœ… **é«˜çº§æŠ€å·§**ï¼šæŒæ¡æ™ºèƒ½åŒ–ã€è‡ªé€‚åº”çš„é«˜çº§å·¥å…·å¼€å‘æŠ€å·§
âœ… **å®æˆ˜åº”ç”¨**ï¼šé€šè¿‡å®é™…æ¡ˆä¾‹å­¦ä¼šè§£å†³å¤æ‚çš„ä¸šåŠ¡é—®é¢˜

### ğŸš€ è¿›é˜¶æ–¹å‘

1. **æ·±åº¦é›†æˆ**ï¼šæ¢ç´¢æ›´å¤šç¬¬ä¸‰æ–¹æœåŠ¡å’ŒAPIçš„é›†æˆ
2. **AIå¢å¼º**ï¼šå°†æœºå™¨å­¦ä¹ èƒ½åŠ›é›†æˆåˆ°å·¥å…·ä¸­
3. **äº‘åŸç”Ÿ**ï¼šå¼€å‘æ”¯æŒäº‘åŸç”Ÿæ¶æ„çš„å·¥å…·
4. **å¾®æœåŠ¡**ï¼šå°†å·¥å…·è®¾è®¡ä¸ºå¾®æœåŠ¡æ¶æ„
5. **å®æ—¶å¤„ç†**ï¼šå¼€å‘æ”¯æŒå®æ—¶æ•°æ®å¤„ç†çš„å·¥å…·

### ğŸª å®è·µç»ƒä¹ 

1. **åŸºç¡€ç»ƒä¹ **ï¼šå¼€å‘ä¸€ä¸ªç®€å•çš„æ•°æ®è½¬æ¢å·¥å…·
2. **è¿›é˜¶ç»ƒä¹ **ï¼šåˆ›å»ºä¸€ä¸ªå¸¦ç¼“å­˜æœºåˆ¶çš„APIè°ƒç”¨å·¥å…·
3. **é«˜çº§ç»ƒä¹ **ï¼šè®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”çš„æ™ºèƒ½æ¨èå·¥å…·
4. **ç»¼åˆç»ƒä¹ **ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–å·¥å…·é“¾

### ğŸ“š å»¶ä¼¸é˜…è¯»

- CrewAI Toolså®˜æ–¹æ–‡æ¡£
- LangChainå·¥å…·å¼€å‘æŒ‡å—
- å¾®æœåŠ¡æ¶æ„è®¾è®¡æ¨¡å¼
- APIè®¾è®¡æœ€ä½³å®è·µ
- æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–æŠ€æœ¯

---

**ä¸‹ä¸€ç« é¢„å‘Š**ï¼šç¬¬6ç« å°†æ·±å…¥æ¢è®¨Flowå·¥ä½œæµçš„é«˜çº§åº”ç”¨ï¼ŒåŒ…æ‹¬äº‹ä»¶é©±åŠ¨ã€æ¡ä»¶åˆ†æ”¯ã€çŠ¶æ€ç®¡ç†ç­‰ä¼ä¸šçº§åŠŸèƒ½ã€‚è®©æˆ‘ä»¬ç»§ç»­è¿™ä¸ªç²¾å½©çš„CrewAIå­¦ä¹ ä¹‹æ—…ï¼ ğŸš€
